<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Prometheus入门]]></title>
    <url>%2Fblog%2F%E7%9B%91%E6%8E%A7%2FPrometheus%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Prometheus安装和基础配置 安装Prometheus数据存放路径：/home/data/prometheus 配置文件：prometheus.yml 12345678910111213version: '3'services: prometheus: privileged: true image: prom/prometheus container_name: prometheus user: root volumes: - /etc/hosts:/etc/hosts - /home/data/prometheus:/prometheus - $PWD/prometheus.yml:/etc/prometheus/prometheus.yml ports: - 9090:9090 因为发现容器内无法访问本地文件，所以添加user: root node-exporter1234567891011version: '3'services: nodeexporter: image: prom/node-exporter container_name: nodeexporter volumes: - /proc:/host/proc:ro - /sys:/host/sys:ro - /:/rootfs:ro ports: - 9100:9100 pushgateway123456789version: '3'services: pushgateway: image: prom/pushgateway container_name: pushgateway volumes: - /etc/hosts:/etc/hosts ports: - 9091:9091 通过node-exporter获取数据配置prometheus.yml添加 12345- job_name: linux static_configs: - targets: ['myos:9100'] labels: instance: myos myos:9100为node-exporter的访问地址 测试输入地址：http://myos:9090/graph 通过以下公式得到cpu占用百分比1(1-(sum(increase(node_cpu_seconds_total&#123;mode="idle"&#125;[5m])) by (instance) )/(sum(increase(node_cpu_seconds_total[5m])) by (instance) ))*100 通过pushgateway获取数据配置prometheus.yml添加 12345- job_name: pushgateway static_configs: - targets: ['myos:9091'] labels: instance: pushgateway 测试添加单条1echo "some_metric 3.14" | curl --data-binary @- http://myos:9091/metrics/job/myjob/instance/myinstance 添加多条通过postman发送post 成功在prometheus里就会出现相应的数据 数据会自动生成一些标签exported_instance和exported_job根据url里的内容生成host和url是发送数据时自己写的标签 1http_request&#123;exported_instance="myinstance",exported_job="myjob",host="web1",instance="pushgateway",job="pushgateway",url="/book/select"&#125; grafana安装数据存放路径：/home/data/grafana 123456789101112version: '3'services: grafana: privileged: true image: grafana/grafana:4.0.2 container_name: grafana user: root volumes: - /home/data/grafana:/var/lib/grafana - /etc/hosts:/etc/hosts ports: - 3000:3000 访问地址 http://myos:3000 用户名密码 admin/admin 添加数据源url填写prometheus的访问路径：http://myos:9090 配置报警接收器 如果用webhook接收报警信息，点击测试可以在post的body里收到如下信息 12345678910111213141516171819&#123; "imageUrl":"http://grafana.org/assets/img/blog/mixed_styles.png", "ruleName":"Test notification", "state":"alerting", "message":"Someone is testing the alert notification within grafana.", "ruleId":0, "title":"[Alerting] Test notification", "ruleUrl":"http://localhost:3000/", "evalMatches":[ &#123; "metric":"High value", "value":100 &#125;, &#123; "metric":"Higher Value", "value":200 &#125; ]&#125; 添加监控图新增dashboard–&gt;选择graph–&gt;点击panel title–&gt;选择edit query输入内容和Prometheus里的相同 数据源选择刚才添加的数据源 alert配置，每分钟检查1此如果最大值大于50就报警 send to选择刚才配置的报警接收器 最终显示效果 实际收到的报警信息，state=alerting，当cpu恢复正常后会收到一条相同的信息，但state=ok 1234567891011121314151617181920212223242526//报警&#123; "ruleName":"cpu使用率报警", "state":"alerting", "message":"cpu占用过高", "ruleId":1, "title":"[Alerting] cpu使用率报警", "ruleUrl":"http://localhost:3000/dashboard/db/cpushi-yong-lu?fullscreen&amp;edit&amp;tab=alert&amp;panelId=1", "evalMatches":[ &#123; "metric":"myos", "value":67.42521121150497 &#125; ] &#125;//恢复&#123; "ruleName":"cpu使用率报警", "state":"ok", "message":"cpu占用过高", "ruleId":1, "title":"[OK] cpu使用率报警", "ruleUrl":"http://localhost:3000/dashboard/db/cpushi-yong-lu?fullscreen&amp;edit&amp;tab=alert&amp;panelId=1", "evalMatches":[] &#125;]]></content>
      <categories>
        <category>监控</category>
      </categories>
      <tags>
        <tag>Prometheus</tag>
        <tag>grafana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud示例]]></title>
    <url>%2Fblog%2Fspringcloud%2Fspringclould%E7%BC%96%E7%A0%81%2F</url>
    <content type="text"><![CDATA[在搭建好的springcloud环境下编写微服务，主要是feign和hystrix的使用 spring版本号：2.1.9.RELEASE clould版本号：Greenwich.SR3 系统共有包含3个模块 bookstore-api：公共接口bookstore-consumer：消费者bookstore-provider：服务提供者 消费者和服务提供者都需要引入公共包 公共接口引入feign1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 编写接口类12345@FeignClient(value="BOOKSTORE-PROVIDER",fallbackFactory = BookstoreApiFallback.class)public interface BookstoreApi &#123; @RequestMapping("/bookInfo/getBook") BookInfo getBook(@RequestParam("id") Long id);&#125; BOOKSTORE-PROVIDER是服务提供方在eureka里显示的名称 fallbackFactory为异常处理类，当出现异常的时候会调用这个类返回的接口实现类进行处理 123456789101112@Componentpublic class BookstoreApiFallback implements FallbackFactory&lt;BookstoreApi&gt; &#123; @Override public BookstoreApi create(Throwable throwable) &#123; return new BookstoreApi() &#123; @Override public BookInfo getBook(Long id) &#123; throw new RuntimeException("未知异常",throwable); &#125; &#125;; &#125;&#125; 服务提供方引入eureka和Hystrix的jar包123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; app.java需要开启Hystrix并配置Hystrix相关的servlet 12345678910111213141516@SpringBootApplication@EnableHystrixpublic class BookstoreProviderApp &#123; public static void main(String args[])&#123; SpringApplication.run(BookstoreProviderApp.class, args); @Bean public ServletRegistrationBean getServlet() &#123; HystrixMetricsStreamServlet streamServlet = new HystrixMetricsStreamServlet(); ServletRegistrationBean registrationBean = new ServletRegistrationBean(streamServlet); registrationBean.setLoadOnStartup(1); registrationBean.addUrlMappings("/actuator/hystrix.stream"); registrationBean.setName("HystrixMetricsStreamServlet"); return registrationBean; &#125;&#125; 实现公共部分里定义的接口 1）设置requestMapping保证最终生成url要和接口里定义的一样 2）在需要熔断方法上加上HystrixCommand，可以设置fallbackMethod失败后的回调方法 12345678910111213141516@RequestMapping("/bookInfo")public class BookInfoController extends BaseController implements BookstoreApi &#123; .... @RequestMapping("/getBook") @HystrixCommand(fallbackMethod = "getBookFail") public BookInfo getBook(Long id) &#123; if(id==1)&#123; throw new RuntimeException("未知异常"); &#125; BookInfo bk=new BookInfo(); bk.setBookId(id); bk.setBookName("调用成功,当前服务器:"+instanceId); return bk; &#125;&#125; 消费者需要eureka客户端和netflix123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;&lt;/dependency&gt; app.java12345678@SpringBootApplication@EnableDiscoveryClient@EnableFeignClients(basePackages = "wang.wangby.bookstore")public class BookstoreConsumerApp &#123; public static void main(String[] args) &#123; SpringApplication.run(BookstoreConsumerApp.class, args); &#125;&#125; 使用当需要调用接口的时候直接注入接口类就可以了 12@AutowiredBookstoreApi bookstoreApi;]]></content>
      <categories>
        <category>springcloud</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java调用restfull]]></title>
    <url>%2Fblog%2Fjava%2Fjava%E8%B0%83%E7%94%A8restfull%2F</url>
    <content type="text"><![CDATA[java调用restfull api操作的工具包 主要功能 根据dao的方法名和参数自动拼接url并根据相应的requestMapping调用具体的httprequest 将返回的json转为对应的java对象 示例对图书的curd操作 编写dao1234567891011121314151617181920//配置此dao所使用的工厂类,不同的工厂类访问的基地址不同@RestDao(TestConfig.BookstoreApiDaoFactory.class)public interface BookDao &#123; //新增或修改 @PutMapping("/book/$&#123;book.id&#125;") Book add(Book book); //删除 @DeleteMapping("book/$&#123;id&#125;") Book delete(String id); //通过id查询 @GetMapping("/book/$&#123;id&#125;") Book get(String id); //获取全部 @GetMapping("/book/getAll") List&lt;Book&gt; getAll();&#125; spring配置类123456789101112131415161718192021@Configuration//RestfullDaoDefinitionRegistrar自动注册标记了RestDao的接口@Import( &#123;VelocityAutoConfiguration.class, JsonAutoConfiguration.class, RestfullDaoDefinitionRegistrar.class&#125;)@ComponentScan("wang.wangby.bookstore")//扫描的包public class TestConfig &#123; public class BookstoreApiDaoFactory extends RestDaoFactory &#123; public BookstoreApiDaoFactory(RestMethodInterceptor restMethodInterceptor) &#123; super(restMethodInterceptor); &#125; &#125; //创建仓库dao @Bean public BookstoreApiDaoFactory registryDaoFactory(TemplateUtil templateUtil, JsonUtil jsonUtil) &#123; SpecificRemoteHttpClient client=new SpecificRemoteHttpClient("http://myos:8080",new HttpConfig()); RestMethodInterceptor interceptor=new RestMethodInterceptor(client,templateUtil,jsonUtil); return new BookstoreApiDaoFactory(interceptor); &#125;&#125; 实际调用123ApplicationContext context = new AnnotationConfigApplicationContext(TestConfig.class);BookDao dao=context.getBean(BookDao.class);Book book=dao.get("123");//执行这行代码的时会自动访问url:http://xxx/book/123,并将返回的json自动转为book对象 实现原理注册RestDao1234//自动扫描带有RestDao的类并注册public class RestfullDaoDefinitionRegistrar implements ImportBeanDefinitionRegistrar&#123; ...&#125; 实现ImportBeanDefinitionRegistrar接口的类可以手动往spring容器中添加类，RestfullDaoDefinitionRegistrar 扫描系统所有类,找到类标签上标记了RestDao的类,将其添加到容器中 动态代理RestDao用ProxyFactory实现动态代理123456789101112131415161718public class RestDaoFactory implements InstantiationAwareBeanPostProcessor &#123; //代理所有标记了RestDao的接口 public Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; RestDao restDao = AnnotationUtils.getAnnotation(beanClass, RestDao.class); if (restDao==null) &#123; return null; &#125; Class daofactroy=restDao.daoFactory(); if(!this.getClass().getName().equals(daofactroy.getName()))&#123; return null; &#125; log.debug("找到bean&#123;&#125;-&gt;&#123;&#125;,restDao=&#123;&#125;" , beanName ,beanClass.getName(),restDao); ProxyFactory pf = new ProxyFactory(); pf.setInterfaces(beanClass); pf.addAdvice(restMethodInterceptor); return pf.getProxy(); &#125;&#125; spring容器启动创建bean的时候会查找所有实现InstantiationAwareBeanPostProcessor接口的类，然后调用postProcessBeforeInstantiation方法，如果该方法返回值不为null，就直接返回不走后面的创建过程了 spring源码位置org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#applyBeanPostProcessorsBeforeInstantiation 12345678910111213@Nullableprotected Object applyBeanPostProcessorsBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; Object result = ibp.postProcessBeforeInstantiation(beanClass, beanName); if (result != null) &#123; return result; &#125; &#125; &#125; return null;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>restfull</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux磁盘分区]]></title>
    <url>%2Fblog%2Flinux%2Ffdisk%2F</url>
    <content type="text"><![CDATA[linux磁盘分区 查看为分配的磁盘 1fdisk -l /dev/sdb 在文件系统里没有,说明未初始化 1234567#开始分区fdisk /dev/sdb#依次输入n p1w 查看新创建的磁盘 12ls /dev/sd*#多出2个/dev/sdb和/dev/sdb1 挂载 123456#格式化mkfs.ext4 /dev/sdb1 #创建目标目录mkdir /common#mount -t 表示文件系统mount -t ext4 /dev/sdb1 /common 开机挂载 12vim /etc/fstab /dev/sdb1 /common ext4 errors=remount-ro 0 1]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>fdisk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker初始化]]></title>
    <url>%2Fblog%2Fdocker%2Fdocker%E5%88%9D%E5%A7%8B%E5%8C%96%2F</url>
    <content type="text"><![CDATA[docker初始化 安装1yum install docker -y 修改docker目录 1docker info |grep Dir 12345678910#停止服务#将文件复制到目标目录#删除源文件#创建软链#重启systemctl stop dockercp -rf /var/lib/docker/ /home/docker/rm -rf /var/lib/docker/ln -sd /home/docker/ /var/lib/dockersystemctl start docker 镜像加速器123456mkdir -p /etc/dockertee /etc/docker/daemon.json &lt;&lt;-'EOF'&#123; "registry-mirrors": ["https://jyvpxfwu.mirror.aliyuncs.com"]&#125;EOF 重启12systemctl daemon-reloadsystemctl restart docker 测试12docker pull busyboxdocker run --rm -it busybox 管理界面1234567docker pulldocker run -d -p 9000:9000 \ --restart=always \ -v /var/run/docker.sock:/var/run/docker.sock \ --name prtainer-test \ --privileged=true \ portainer/portainer 安装docker-compose安装python31yum install python3 关联包123456正在安装: python3 x86_64 3.6.8-10.el7 base 69 k为依赖而安装: python3-libs x86_64 3.6.8-10.el7 base 7.0 M python3-pip noarch 9.0.3-5.el7 base 1.8 M python3-setuptools noarch 39.2.0-10.el7 base 629 k 修改python的软链为python312rm -rf /usr/bin/pythonln -s /usr/bin/python3.4 /usr/bin/python yum无法使用修改以下两个文件的python声明为2.7 123#!/usr/bin/python2.7vim /usr/bin/yum vim /usr/libexec/urlgrabber-ext-down 安装docker-compose12pip3.4 install --upgrade pippip3.4 install docker-compose 监控cadvisor运行容器1docker run --privileged -v /var/run:/var/run:rw -v /sys:/sys:ro -v /var/lib/docker:/var/lib/docker:ro -p 8080:8080 -d --name cadvisor google/cadvisor 可能报错12Failed to start container manager: inotify_add_watch/sys/fs/cgroup/cpuacct,cpu: no such file or directory 解决办法12mount -o remount,rw '/sys/fs/cgroup'ln -s /sys/fs/cgroup/cpu,cpuacct /sys/fs/cgroup/cpuacct,cpu]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机]]></title>
    <url>%2Fblog%2F%E5%88%9D%E5%A7%8B%E5%8C%96%2Fcentos%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[visualbox安装 目录 1234#虚拟机根目录E:\visualbox#最小化centos备份E:\visualbox\centosmin.bak 初始化账号root:root ming:ming 远程登录1ip addr|grep 192.168 设置yum源12345678#直接删除,不备份了rm -rf /etc/yum.repos.d/*cp /media/sf_linux/etc/yum.repos.d/* /etc/yum.repos.d/#修改内容为E:\linux\Centos-7.repo#更新 yum update 可能比较久yum clean all yum makecache yum update -y 安装visualbox增强工具更新内核 123456789101112#安装一些该工具包yum -y install vimyum -y install lrzsz yum -y install net-toolsyum -y install lsof#根据/media/VBoxLinuxAdditions.run的执行结果提示,安装所需部件yum -y install gccyum install kernel-devel gcc -yyum install bzip2 -y#重启reboot 安装VBoxGuestAdditions 123456#将E:\linux\VBoxGuestAdditions.iso拖到/root/下#挂载mount /root/VBoxGuestAdditions.iso /media/#mount: /dev/loop0 写保护，将以只读方式挂载#安装增强工具/media/VBoxLinuxAdditions.run 分配共享目录 挂载共享目录 12345#重启后自动挂载到/media/sf_linux#创建目标目录#mkdir /win#-t 文件系统#mount -t vboxsf linux /win 复制将E:\visualbox\bak\centosmin.vdi复制到E:\visualbox ,改名node01.kube.wang.vdi 新建时选择刚才复制的文件 设置网络为桥接 远程登录 1234#重启网络systemctl restart network#查看ipip addr|grep 192.168 命令行启动 1systemctl set-default multi-user.target 设置hostname 1hostnamectl set-hostname node2 修改为静态ip 12345#192.168.1.201为要设置的ip#需确认网络已经设置为桥接，网卡名称如果不是enp0s3，需要删除原来配置，并修改文件里的NAME和DEVICE#重启cat /media/sf_linux/etc/sysconfig/network-scripts/ifcfg-enp0s3 | sed "s/192.168.1.200/192.168.1.114/" &gt; /etc/sysconfig/network-scripts/ifcfg-enp0s3systemctl restart network 修改启动命令 1vim ~/.bashrc ifcfg-enp0s3内容 12345678910111213141516171819202122TYPE=&quot;Ethernet&quot;PROXY_METHOD=&quot;none&quot;BROWSER_ONLY=&quot;no&quot;#$BOOTPROTO=&quot;dhcp&quot;BOOTPROTO=&quot;static&quot;IPADDR=192.168.1.200NETMASK=255.255.255.0GATEWAY=192.168.1.1DNS1=8.8.8.8DEFROUTE=&quot;yes&quot;IPV4_FAILURE_FATAL=&quot;no&quot;IPV6INIT=&quot;yes&quot;IPV6_AUTOCONF=&quot;yes&quot;IPV6_DEFROUTE=&quot;yes&quot;IPV6_FAILURE_FATAL=&quot;no&quot;IPV6_ADDR_GEN_MODE=&quot;stable-privacy&quot;NAME=&quot;enp0s3&quot;UUID=&quot;b6317c3a-28b1-4d40-a097-d8e63f285948&quot;DEVICE=&quot;enp0s3&quot;ONBOOT=&quot;yes&quot;]]></content>
      <categories>
        <category>初始化</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>centos</tag>
        <tag>visualbox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes安装]]></title>
    <url>%2Fblog%2Fkubernets%2Fkubernets%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[kuberneteskubernetes 准备工作 master01:192.168.1.110 node01:192.168.1.106 关闭防火墙 12systemctl disable firewalldiptables -F yum安装 master 192.168.1.110 1yum install kubernetes-master etcd -y 配置 vim /etc/etcd/etcd.conf 1234567ETCD_DATA_DIR=&quot;/var/lib/etcd/abc&quot;ETCD_LISTEN_PEER_URLS=&quot;http://192.168.1.110:2380&quot;ETCD_LISTEN_CLIENT_URLS=&quot;http://192.168.1.110:2379&quot;ETCD_NAME=&quot;etcd1&quot;ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;http://192.168.1.110:2380&quot;ETCD_ADVERTISE_CLIENT_URLS=&quot;http://192.168.1.110:2379&quot;ETCD_INITIAL_CLUSTER=&quot;etcd1=http://192.168.1.110:2380,etcd2=http://192.168.1.106:2380&quot; vim /etc/kubernetes/apiserver 1234KUBE_API_ADDRESS=&quot;--insecure-bind-address=127.0.0.1&quot;KUBE_ETCD_SERVERS=&quot;--etcd-servers=http://192.168.1.110:2379,http://192.168.1.106:2379&quot;KUBE_SERVICE_ADDRESSES=&quot;--service-cluster-ip-range=10.254.0.0/16&quot;KUBE_API_ARGS=&quot;&quot; vim /etc/kubernetes/config 1234KUBE_LOGTOSTDERR=&quot;--logtostderr=true&quot;KUBE_LOG_LEVEL=&quot;--v=0&quot;KUBE_ALLOW_PRIV=&quot;--allow-privileged=false&quot;KUBE_MASTER=&quot;--master=http://192.168.1.110:8080&quot; 重启 1234567891011#停止systemctl stop etcdsystemctl stop kube-apiserversystemctl stop kube-controller-managersystemctl stop kube-scheduler#启动systemctl daemon-reloadsystemctl restart etcdsystemctl restart kube-apiserversystemctl restart kube-controller-managersystemctl restart kube-scheduler 查看 1kubectl get nodes --insecure-skip-tls-verify=true node 192.168.1.105 安装 1yum install kubernetes-node etcd flannel -y 配置 vim /etc/etcd/etcd.conf 1234567ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;ETCD_LISTEN_PEER_URLS=&quot;http://192.168.1.106:2380&quot;ETCD_LISTEN_CLIENT_URLS=&quot;http://192.168.1.106:2379,http://127.0.0.1:2379&quot;ETCD_NAME=&quot;etcd2&quot;ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;http://192.168.1.106:2380&quot;ETCD_ADVERTISE_CLIENT_URLS=&quot;http://192.168.1.106:2379&quot;ETCD_INITIAL_CLUSTER=&quot;etcd1=http://192.168.1.110:2380,etcd2=http://192.168.1.106:2380&quot; vim /etc/kubernetes/kubelet 12345KUBELET_ADDRESS=&quot;--address=0.0.0.0&quot;KUBELET_HOSTNAME=&quot;--hostname-override=node01.kube.wang&quot;KUBELET_API_SERVER=&quot;--api-servers=http://192.168.1.110:8080&quot;KUBELET_POD_INFRA_CONTAINER=&quot;--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest&quot;KUBELET_ARGS=&quot;&quot; 启动 123systemctl daemon-reloadsystemctl restart kube-proxysystemctl restart kubelet 客户端设置kubectl 123kubectl config set-cluster kubernetes --server=http://192.168.1.110:8080kubectl config set-context kubernetes --cluster=kuberneteskubectl config use-context kubernetes dashboard 12docker pull docker.io/mirrorgooglecontainers/kubernetes-dashboard-amd64:v1.10.1docker tag docker.io/mirrorgooglecontainers/kubernetes-dashboard-amd64:v1.10.1 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1 etcd 启动慢 ​ 确认防火墙是否关闭 ​ 确认ETCD_INITIAL_CLUSTER里所有机器都启动 member 73079f127bc11ea8 has already been bootstrapped 错误 1Error syncing pod, skipping: failed to "StartContainer" for "POD" with ErrImagePull: "image pull failed for registry.access.redhat.com/rhel7/pod-infrastructure:latest, this may be because there are no credentials on this request. details: (open /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crt: no such file or directory)" 解决办法 123wget http://mirror.centos.org/centos/7/os/x86_64/Packages/python-rhsm-certificates-1.19.10-1.el7_4.x86_64.rpmrpm2cpio python-rhsm-certificates-1.19.10-1.el7_4.x86_64.rpm | cpio -iv --to-stdout ./etc/rhsm/ca/redhat-uep.pem | tee /etc/rhsm/ca/redhat-uep.pem docker pull registry.access.redhat.com/rhel7/pod-infrastructure:latest]]></content>
      <categories>
        <category>kubernets</category>
      </categories>
      <tags>
        <tag>kubernets</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis配置]]></title>
    <url>%2Fblog%2Fredis%2Fredis%2F</url>
    <content type="text"><![CDATA[规划共6个应用 1个master,2个slave,3个sentinel master : 192.168.1.110 6379 slave1: 192.168.1.110 6380 slave2: 192.168.1.110 6381 sentinel1: 192.168.1.110 26379 sentinel2: 192.168.1.110 26380 sentinel3: 192.168.1.110 26381 目录redis目录 /usr/local/bin/ 配置文件目录 /media/sf_linux/soft/redis 该目录下新建6个conf文件 123456789101112[root@centos7 redis]# pwd/media/sf_linux/soft/redis[root@centos7 redis]# lltotal 89drwxrwx---. 1 root vboxsf 4096 Jan 31 14:15 logs-rwxrwx---. 1 root vboxsf 327 Jan 31 14:14 redis6379.conf-rwxrwx---. 1 root vboxsf 177 Jan 31 14:47 redis6380.conf-rwxrwx---. 1 root vboxsf 203 Jan 31 14:47 redis6381.conf-rwxrwx---. 1 root vboxsf 62155 Nov 22 18:26 redis.conf.bak-rwxrwx---. 1 root vboxsf 803 Jan 31 14:18 sentinel26379.conf-rwxrwx---. 1 root vboxsf 708 Jan 31 14:47 sentinel26380.conf-rwxrwx---. 1 root vboxsf 708 Jan 31 14:47 sentinel26381.conf 日志目录 /media/sf_linux/soft/redis/logs 数据目录 /opt/redis/data/ 临时目录 /opt/redis/data/ 创建目录 1234mkdir /opt/redis/data/mkdir /opt/redis/data/tempmkdir /media/sf_linux/soft/redis/logsmkdir /media/sf_linux/soft/redis 配置masterredis6379.conf 12345678910111213#访问ipbind 192.168.1.110#工作目录#不知道什么原因如果目录配置在/media/sf_linux下,sentinel无法生成文件,所以换个目录,可能是因为/media/sf_linux是windows的映射目录dir &quot;/opt/redis/data&quot;#dump文件名dbfilename &quot;dump6379.rdb&quot;#端口port 6379#日志文件logfile &quot;/media/sf_linux/soft/redis/logs/6379.log&quot;#后台方式启动daemonize yes slave1redis6380.conf 12345678bind 192.168.1.110dir &quot;/opt/redis/data&quot;daemonize yes#dump文件名,端口,日志文件改为6380dbfilename &quot;dump6380.rdb&quot;port 6380logfile &quot;/media/sf_linux/soft/redis/logs/6380.log&quot;slaveof 192.168.1.110 6379 slave2redis6381.conf 12345678bind 192.168.1.110dir &quot;/opt/redis/data&quot;daemonize yes#dump文件名,端口,日志文件改为6381dbfilename &quot;dump6381.rdb&quot;port 6381logfile &quot;/media/sf_linux/soft/redis/logs/6381.log&quot;slaveof 192.168.1.110 6379 sentinel1sentinel26379.conf 12345678910bind 192.168.1.110port 26379daemonize yeslogfile &quot;/media/sf_linux/soft/redis/logs/sentia26379.log&quot;dir &quot;/opt/redis/data/temp&quot;#master名称叫mymaster,java应用里需要用到这个名字#1只要有1个sentinel认为服务器挂了就切换sentinel monitor mymaster 192.168.1.110 6379 1#10000,服务器挂掉10秒后切换sentinel down-after-milliseconds mymaster 10000 sentinel2sentinel26380.conf 12345678bind 192.168.1.110daemonize yesdir &quot;/opt/redis/data/temp&quot;sentinel monitor mymaster 192.168.1.110 6379 1sentinel down-after-milliseconds mymaster 10000#端口和日志改为26380port 26380logfile &quot;/media/sf_linux/soft/redis/logs/sential26380.log&quot; sentinel3sentinel26381.conf 12345678bind 192.168.1.110daemonize yesdir &quot;/opt/redis/data/temp&quot;sentinel monitor mymaster 192.168.1.110 6379 1sentinel down-after-milliseconds mymaster 10000#端口和日志改为26381port 26381logfile &quot;/media/sf_linux/soft/redis/logs/sential26381.log&quot; 启动redis123/usr/local/bin/redis-server /media/sf_linux/soft/redis/redis6379.conf /usr/local/bin/redis-server /media/sf_linux/soft/redis/redis6380.conf /usr/local/bin/redis-server /media/sf_linux/soft/redis/redis6381.conf sentinel123/usr/local/bin/redis-sentinel /media/sf_linux/soft/redis/sentinel26379.conf /usr/local/bin/redis-sentinel /media/sf_linux/soft/redis/sentinel26380.conf /usr/local/bin/redis-sentinel /media/sf_linux/soft/redis/sentinel26381.conf 查看ps -ef|grep redis 12345678[root@centos7 ~]# ps -ef|grep redisroot 13041 1 0 14:14 ? 00:00:00 /usr/local/bin/redis-server 192.168.1.110:6379root 13054 1 0 14:14 ? 00:00:00 /usr/local/bin/redis-server 192.168.1.110:6380root 13063 1 0 14:14 ? 00:00:00 /usr/local/bin/redis-server 192.168.1.110:6381root 13270 1 0 14:17 ? 00:00:00 /usr/local/bin/redis-sentinel 192.168.1.110:26379 [sentinel]root 13278 1 0 14:18 ? 00:00:00 /usr/local/bin/redis-sentinel 192.168.1.110:26380 [sentinel]root 13285 1 0 14:18 ? 00:00:00 /usr/local/bin/redis-sentinel 192.168.1.110:26381 [sentinel]root 13350 11045 0 14:19 pts/0 00:00:00 grep --color=auto redis java所需jar包12345 &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.7.2&lt;/version&gt;&lt;/dependency&gt; 测试redis12345678910111213141516171819package xxx.xxx;import redis.clients.jedis.Jedis;public class RedisTest &#123; public static void main(String args[])&#123; System.out.println("--------master-----------"); Jedis master=new Jedis("192.168.1.110",6379); master.set("hello","redis"); String message=master.get("hello"); System.out.println("hello "+message); System.out.println("--------slave-----------"); Jedis slave1=new Jedis("192.168.1.110",6380); slave1.set("hello","redis");//这里报错 message=slave1.get("hello"); System.out.println("hello "+message); &#125;&#125; 运行结果 1234567891011--------master-----------hello redis--------slave-----------Exception in thread &quot;main&quot; redis.clients.jedis.exceptions.JedisDataException: READONLY You can&apos;t write against a read only slave. at redis.clients.jedis.Protocol.processError(Protocol.java:117) at redis.clients.jedis.Protocol.process(Protocol.java:142) at redis.clients.jedis.Protocol.read(Protocol.java:196) at redis.clients.jedis.Connection.readProtocolWithCheckingBroken(Connection.java:288) at redis.clients.jedis.Connection.getStatusCodeReply(Connection.java:187) at redis.clients.jedis.Jedis.set(Jedis.java:66) at wang.wangby.redis.RedisTest.main(RedisTest.java:14) 测试集群正常访问每1秒访问一次redis集群，get and set 1个变量（no）的值，然后将这个值+1 12345678910111213141516171819202122232425262728293031323334353637package wang.wangby.redis;import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPoolConfig;import redis.clients.jedis.JedisSentinelPool;import java.util.HashSet;import java.util.Set;public class SentinelsTest &#123; public static void main(String args[]) &#123; JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(100);//最大连接数 config.setMaxWaitMillis(60000);// 设置最大阻塞时间， config.setMaxIdle(10);// 设置空间连接 Set&lt;String&gt; sentinels = new HashSet&lt;String&gt;(); sentinels.add("192.168.1.110:26379"); sentinels.add("192.168.1.110:26380"); sentinels.add("192.168.1.110:26381"); JedisSentinelPool pool = new JedisSentinelPool("mymaster", sentinels, config); int no=0; while (true) &#123; try &#123; Jedis jedis = pool.getResource(); no++; jedis.set("count", no+""); jedis.close(); System.out.println("count: "+jedis.get("count")); Thread.sleep(1000); &#125; catch (Exception ex) &#123; System.out.println(ex.getMessage()); &#125; &#125; &#125;&#125; 输出 12345count: 1count: 2count: 3count: 4... 模拟sentinel挂掉kill 123[root@centos7 ~]# lsof -i:26379|awk 'NR==2&#123;print $2&#125;' 13270[root@centos7 ~]# kill 13270 控制台报出警告，但数据仍能正常访问 123456789count: 338count: 339count: 340count: 341一月 31, 2019 2:44:59 下午 redis.clients.jedis.JedisSentinelPool$MasterListener run严重: Lost connection to Sentinel at 192.168.1.110:26379. Sleeping 5000ms and retrying.count: 342count: 343count: 344 模拟master挂掉kill 1234[root@centos7 ~]# lsof -i:6379|awk 'NR==2&#123;print $2&#125;' 13041[root@centos7 ~]# kill 13041[root@centos7 ~]# 控制台有10秒钟无法访问redis(Could not get a resource from the pool)，10秒后恢复正常 123456789101112131415161718192021222324252627count: 482count: 483Unexpected end of stream.Could not get a resource from the pool一月 31, 2019 2:47:24 下午 redis.clients.jedis.JedisSentinelPool$MasterListener run严重: Lost connection to Sentinel at 192.168.1.110:26379. Sleeping 5000ms and retrying.Could not get a resource from the poolCould not get a resource from the poolCould not get a resource from the poolCould not get a resource from the poolCould not get a resource from the poolCould not get a resource from the pool一月 31, 2019 2:47:30 下午 redis.clients.jedis.JedisSentinelPool$MasterListener run严重: Lost connection to Sentinel at 192.168.1.110:26379. Sleeping 5000ms and retrying.Could not get a resource from the poolCould not get a resource from the poolCould not get a resource from the pool一月 31, 2019 2:47:33 下午 redis.clients.jedis.JedisSentinelPool initPool信息: Created JedisPool to master at 192.168.1.110:6380Could not get a resource from the poolcount: 485count: 486count: 487一月 31, 2019 2:47:36 下午 redis.clients.jedis.JedisSentinelPool$MasterListener run严重: Lost connection to Sentinel at 192.168.1.110:26379. Sleeping 5000ms and retrying.count: 488count: 489 配置文件redis6381.conf的最后一行slaveof从6379变更为6380 1slaveof 192.168.1.110 6380 redis6381.conf文件后面的slaveof被删掉了 所有sentinel的monitor自动变更为6380 1sentinel monitor mymaster 192.168.1.110 6380 1 重启6379后 redis6381.conf文件末尾自动加上 12# Generated by CONFIG REWRITEslaveof 192.168.1.110 6380 监控日志jedis 使用java.util.logging，日志格式和现有监控系统不一样，需要手动修改一下 日志级别 java.util.logging.Level SEVERE WARNING INFO CONFIG FINE FINER FINEST 严重 警告 信息 —— —- —– —— 在根目录创建logging.propertie 123handlers= java.util.logging.ConsoleHandlerjava.util.logging.ConsoleHandler.level = INFOjava.util.logging.ConsoleHandler.formatter =wang.wangby.redis.MyFormat 程序启动的时候加载 123java.util.logging.LogManager logManager = java.util.logging.LogManager.getLogManager();InputStream input=LogTest.class.getResourceAsStream("/logging.properties");logManager.readConfiguration(input); 自定义format类（继承java.util.logging.Formatter实现format方法） 1234567891011121314151617181920212223242526272829303132333435 // @see java.util.logging.SimpleFormatter#format;public class MyFormat extends Formatter &#123; @Override public String format(LogRecord record) &#123; String source; if (record.getSourceClassName() != null) &#123; String fullName = record.getSourceClassName(); int point = fullName.lastIndexOf("."); if (point != -1) &#123; source = fullName.substring(point + 1); &#125; else &#123; source = fullName; &#125; if (record.getSourceMethodName() != null) &#123; source += "." + record.getSourceMethodName(); &#125; &#125; else &#123; source = record.getLoggerName(); &#125; String message = formatMessage(record); String throwable = ""; if (record.getThrown() != null) &#123; StringWriter sw = new StringWriter(); PrintWriter pw = new PrintWriter(sw); pw.println(); record.getThrown().printStackTrace(pw); pw.close(); throwable = sw.toString(); &#125; String data = DateTime.current(DateTime.YEAR_TO_MILLISECOND).toString(); return data + " " + record.getLevel() + " " + source + " " + message + " " + throwable + "\n"; &#125;&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[页面代码模板]]></title>
    <url>%2Fblog%2Fcode%2F%E9%A1%B5%E9%9D%A2%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF%2F</url>
    <content type="text"><![CDATA[页面代码模板 bootstrap页签三个页签的页面 nav nav-tabs：页签的头 tab-content：每个页签显示的内容 tab-pane：固定的内容 $(‘#myTabs a[href=”#tab1”]’).tab(‘show’); 页面加载完毕显示第一个页签 123456789101112131415161718192021222324252627282930&lt;div&gt; &lt;!-- Nav tabs --&gt; &lt;ul class="nav nav-tabs" id="myTabs"&gt; &lt;li&gt;&lt;a href="#tab1" data-toggle="tab"&gt;tab1 titile&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#tab2" data-toggle="tab"&gt;tab2 title&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#tab3" data-toggle="tab"&gt;tab3 title&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;div class="tab-content"&gt; &lt;div class="tab-pane " id="tab1"&gt; tab1的内容 &lt;/div&gt; &lt;div class="tab-pane " id="tab2"&gt; tab2的内容 &lt;/div&gt; &lt;div class="tab-pane " id="tab3"&gt; tab3的内容 &lt;/div&gt; &lt;/div&gt; &lt;div class="tab-pane"&gt; &lt;button type="button" class="btn-sm btn-primary"&gt;测试按钮&lt;/button&gt; &lt;/div&gt;&lt;/div&gt;&lt;script&gt; $('#myTabs a[href="#tab1"]').tab('show');&lt;/script&gt; select12345678910 &lt;select class="selectpicker" name="mySelect"&gt; &lt;option value="1"&gt;text1&lt;/option&gt; &lt;option value="2"&gt;text2&lt;/option&gt; &lt;/select&gt;&lt;script&gt;$('.selectpicker').selectpicker(&#123; "width":"100px"&#125;);&lt;/script&gt; 动态修改表格表格必须设置id 第一个tr也要设置id，并且隐藏 表格内容12345678910111213141516171819202122 &lt;table class="list" id="formatTable"&gt; &lt;tr&gt; &lt;th&gt;aaa&lt;/th&gt; &lt;th&gt; &lt;!--加号--&gt; &lt;button onclick="addColumn()" type="button" class="btn btn-default"&gt; &lt;span class="glyphicon glyphicon-plus" aria-hidden="true"&gt;&lt;/span&gt; &lt;/button&gt; &lt;/th&gt; &lt;/tr&gt; &lt;!--第一行作为模板,动态添加时复制这行--&gt; &lt;tr id="columnTr" style="display: none"&gt; &lt;td&gt; &lt;input title="insertRow" class="form-control"/&gt; &lt;/td&gt; &lt;td&gt; &lt;button onclick="delColumn(this)" type="button" class="btn btn-default"&gt; &lt;span class="glyphicon glyphicon-minus" aria-hidden="true"&gt;&lt;/span&gt; &lt;/button&gt; &lt;/td&gt; &lt;/tr&gt;&lt;/table&gt; 新增行12345function addColumn() &#123; var cloneTr = $("#columnTr").clone(); cloneTr.show(); $("#formatTable").append(cloneTr);&#125; 删除行123function delColumn(el) &#123; $(el).parent().parent().remove();&#125; 操作相邻td12var myInput=$(el).parent().parent().find("input[title='myInput']");myInput.show(); 提交第一行由于一直是隐藏的，所以没值，需要跳过验证，所以input的name在批量提交的时候设置 为了方便定位，给每个需要提交的元素都设置title 1&lt;input title="字段" class="form-control"/&gt; ztree后台返回ztree的节点对象 1234567891011121314151617@RequestMapping("/tree")@ResponseBodypublic Response&lt;List&lt;Ztree&gt;&gt; tree(String zkAddress) &#123; List&lt;CollectorTask&gt; tasks = collectorTaskService.getAll(); List list = Ztree.createTree(tasks, t -&gt; &#123; return nodeToZtree(t); &#125;); return respone(list);&#125;private Ztree nodeToZtree(CollectorTask node)&#123; Ztree view = new Ztree(); view.setParentId(""); view.setId(node.getCollectorTaskId()); view.setName(node.getDir()); return view;&#125; 初始化ztree 新增一个id为detail的div存放详细页面 12345678910111213&lt;div class="panel-body" style="padding:0px; width: 99%"&gt; &lt;div class="panel panel-default" style="margin: 0px"&gt; &lt;div class="panel-heading"&gt;日志收集任务&lt;/div&gt; &lt;div class="panel-body row"&gt; &lt;div class="col-sm-3"&gt; &lt;ul id="zkTree" class="ztree" style="background-color: white;width: 100%;"&gt;&lt;/ul&gt; &lt;/div&gt; &lt;div class="col-sm-9" id="detail"&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt; 用js添加节点 123456789101112131415161718192021222324252627282930313233343536//点击节点function zTreeOnClick(event, treeId, treeNode) &#123; var data="id="+treeNode.id ajaxUtil.html("$path/get", data, function (html) &#123; $("#detail").html(html); &#125;)&#125;;var zTreeObj;var setting = &#123; callback: &#123; onClick: zTreeOnClick &#125;&#125;;//页面加载完毕后调用后台js获取树信息$(function () &#123; dialog.loading(); ajaxUtil.json('$&#123;path&#125;/tree', "", function (resp) &#123; dialog.loading(false); if (!resp.success) &#123; dialog.alert(resp.message); return; &#125; zTreeObj = $.fn.zTree.init($("#zkTree"), setting, resp.data); zTreeObj.expandAll(true);//展开树 //自动调整大小 var menuBar=$("#menuBar").height(); var height=document.documentElement.clientHeight-menuBar var top=$("#zkTree").offset().top; $("#zkTree").css("height", height-top); &#125;)&#125;) boostrap-table显示的列columns是一个数组 123456789101112var columns = [ &#123;checkbox: true&#125;, &#123;field:'bookId',title:'图书信息',formatter:detailLink,events:showDetail&#125;, &#123;field:'bookName',title:'书名'&#125;, &#123;field:'publication',title:'发行日期'&#125;, &#123;field:'price',title:'售价'&#125;, &#123;field:'isbn',title:'ISBN'&#125;, &#123;field:'valid',title:'有效标识'&#125;, &#123;field:'remain',title:'库存'&#125;, &#123;field:'createTime',title:'创建时间'&#125;, &#123;title: "操作", formatter: btnOperate, events: tableEvents , visible: false&#125;,] 显示格式显示checkbox:{checkbox: true} 显示格式:formatter button 123btnOperate = function (value, row, index) &#123; return '&lt;button id="btnOperate" class="btn-small btn-primary"&gt;操作&lt;/button&gt;'&#125;; a 123detailLink=function(value, row, index)&#123; return '&lt;a href="JavaScript:" id="detailLink"&gt;'+value+'&lt;/a&gt;';&#125; 日期 1234567dateToString=function(value, row, index)&#123; if(!value)&#123; return ""; &#125; var d=new Date(value); return d.format("yyyy-MM-dd hh:mm:ss");&#125; 事件显示详情 123456789showDetail= &#123; "click #detailLink": function (e, value, row, index) &#123; var url="$&#123;path&#125;/get"; var data="name="+row.name+"&amp;tag="+row.tag ajaxUtil.html(url,data,function (content) &#123; dialog.createPop("detail","镜像详情",content,3); &#125;) &#125; &#125; 按钮 123456789101112tableEvents = &#123; "click #btnOperate": function (e, value, row, index) &#123; var data = ""; ajaxUtil.json("$path/xxx", data, function (ret) &#123; if (!ret.success) &#123; dialog.alert(ret.message); &#125; else &#123; dialog.alert("操作成功"); &#125; &#125;) &#125;,&#125;; 弹出框 设置link 的format 1234567891011121314151617function createPop(title,value)&#123; return "&lt;tr&gt;&lt;td&gt;"+title+"&lt;/td&gt;&lt;td&gt;"+value+"&lt;/td&gt;&lt;/tr&gt;";&#125;//构造link,设置title和contentnameLink=function(value, row, index)&#123; var content="&lt;table class='table table-condensed'&gt;"; content+=createPop("已经执行次数",row.ran); content+=createPop("成功个数",row.success); content+=createPop("成功平均用时",divide(row.successTime,row.success)); content+=createPop("失败个数",row.failue); content+=createPop("失败平均用时",divide(row.totalTime-row.successTime,row.failue)); content+=createPop("最短耗时ms",row.minTime); content+=createPop("最长用时ms",row.maxTime); content+=createPop("总用时",row.totalTime); content+="&lt;/table&gt;" return '&lt;a href="javascript:" title="执行情况" name="nameLink" content="'+content+'"&gt;'+value+'&lt;/a&gt;'; &#125; 表格加载成功后设置popover 1234567891011$("a[name='nameLink']").each(function (idx,el) &#123; var content=$(el).attr("content"); var title=$(el).attr("title"); $(el).popover(&#123; html:true, placement:'right', trigger:'hover', title:title, content:content &#125;)&#125;) 客户端分页1234567891011//tableDiv表格id,columns列信息//回调函数设置自定义的参数tableUtil.init(tableDiv, columns, '', function (config) &#123; config.uniqueId = 'taskInfoId'; config.height=document.documentElement.clientHeight-60;&#125;);//加载返回的数据(url,param,callback)//callback可以在加载成功后修改页面元素tableUtil.load('$path/getAll','',function () &#123; &#125;)]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>code</tag>
        <tag>javascirpt</tag>
        <tag>html</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UUID生成]]></title>
    <url>%2Fblog%2Fcode%2Fuuid%2F</url>
    <content type="text"><![CDATA[每毫秒最多生成4096个，最多允许机器数1024 起始时间如果设置为2019-1-1，最多可以用到2086-09-06 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102package wang.wangby.utils;import java.nio.charset.Charset;import java.util.Date;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import wang.wangby.annotation.persistence.Id;/** * 主键生成器 0正负标识, 1-40当前毫秒值,41-52同一毫秒可产生的序列号, 53-63机器编号, * 010001101011110010001111000100111011 000000001110 0000000000 */public class IdWorker &#123; private static IdWorker INSTANCE = new IdWorker(0); private Logger log = LoggerFactory.getLogger(this.getClass()); public static final int machineBits = 10;// 机器位数 public static final int seqBits = 12;// 序列号位数 public static final int timeShift = machineBits + seqBits;// 时间往左移动位数 public static final long maxSeq = -1L ^ (-1L &lt;&lt; seqBits);// 最大允许序列号(4095) public static final long maxMachine = -1L ^ (-1L &lt;&lt; machineBits);// 最大允许机器号(1023),最小0 // 为了防止超过long的最大值,时间戳生成后减去这个值 private static final long begin = new DateTime("2019-01-01").getTime(); private int machineCode; private long lastTime; private long sequence = 1;// 因为0无法向左做位移操作,序列号从1开始 /** * @param machineCode 机器编号 */ public IdWorker(int machineCode) &#123; this.machineCode = machineCode; if (machineCode &gt; maxMachine) &#123; throw new RuntimeException("机器编号不能大于" + maxMachine); &#125; if ((currentTimeMillis() - begin) &lt;&lt; timeShift &lt; 0) &#123; long max = (Long.MAX_VALUE &gt;&gt; timeShift) + begin;// 2086-09-06 throw new RuntimeException("当前时间超过" + new DateTime(max) + ",生成器已无法使用"); &#125; if (machineCode != 0) &#123; log.info("主键生成器创建完毕,当前机器号:" + machineCode); &#125; &#125; public synchronized long nextId() &#123; long time = currentTimeMillis() - begin; if (time != lastTime) &#123; lastTime = time; sequence = 1; &#125; else &#123; sequence++; &#125; if (sequence &gt; maxSeq) &#123; throw new RuntimeException("当前不支持同一毫秒内生成主键超过:" + maxSeq); &#125; //时间向左移动22位+机器向左移动12位+机器的10位 return (time &lt;&lt; timeShift) | (sequence &lt;&lt; machineBits) | machineCode; &#125; // 获取当前时间单独弄一个方法,方便测试时覆盖 public long currentTimeMillis() &#123; return System.currentTimeMillis(); &#125; // 通过生成的id获取id生成时间,去掉后面的22位 public static long getTimestamp(long id) &#123; return begin + (id &gt;&gt;&gt; timeShift); &#125; public static long createByTime(long time) &#123; time = time - begin; return (time &lt;&lt; timeShift) | (0 &lt;&lt; machineBits) | 0; &#125; // 通过生成的id获得机器编号,取最后10位 public static int getMachineNo(long id) &#123; StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; machineBits; i++) &#123; sb.append(id &amp; 1); id = id &gt;&gt;&gt; 1; &#125; return Integer.parseInt(sb.reverse().toString(), 2); &#125; public static int getMachineNo(String id) &#123; return getMachineNo(toLong(id)); &#125; public static long nextLong() &#123; return INSTANCE.nextId(); &#125; public static String nextString() &#123; long l = INSTANCE.nextId(); return Long.toString(l,Character.MAX_RADIX); &#125; public static Long toLong(String uuid)&#123; return Long.parseLong(uuid, Character.MAX_RADIX); &#125;&#125;]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>UUID</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Singleton的double check问题]]></title>
    <url>%2Fblog%2Fdesign%2Fsingleton%2F</url>
    <content type="text"><![CDATA[创建单例对象如果用double check方式，会存在不安全的情况，简单说法是给对象加上volatile关键字， 具体原因牵扯到比较多，下面具体说明，先看代码 代码创建10个线程，同时调用getInstance()方法获取单例对象 getInstance方法，创建对象的过程为 1.判断对象是否为null 2.获得锁 3.再次判断对象是否为null 4.创建对象 5.初始化对象内部数据 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package thread;import java.util.ArrayList;import java.util.List;import java.util.concurrent.CountDownLatch;public class Singleton &#123; private static Singleton singleton; private String initThreadName;//记录单例对象是由哪个线程创建的 public static Singleton getInstance() throws InterruptedException &#123; if (singleton != null) &#123;//1 debug("singleton不为null,直接返回"); return singleton; &#125; debug("singleton为null,准备获得锁"); synchronized (Singleton.class) &#123;//2 if (singleton != null) &#123;//3 debug("获得锁后发现singleton已经创建,直接返回"); return singleton; &#125; debug("singleton为null,开始执行创建"); singleton = new Singleton();//4 Thread.sleep(2000);//假装对象创建比较耗时 singleton.initThreadName = Thread.currentThread().getName();//5 debug("-----singleton创建完毕-------"); return singleton; &#125; &#125; //创建10个线程,同时调用getInstance() public static void main(String args[]) throws InterruptedException &#123; List&lt;Thread&gt; list = new ArrayList&lt;&gt;(); CountDownLatch c = new CountDownLatch(1); for (int i = 0; i &lt; 10; i++) &#123; Runnable run = () -&gt; &#123; try &#123; debug("线程创建完毕等待执行"); c.await();//等待线程全部到达 debug("准备获取对象"); Singleton singleton = Singleton.getInstance(); debug("获得单例对象,该对象是由线程" + singleton.initThreadName + "创建的"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;; new Thread(run, "thread" + i).start(); &#125; Thread.sleep(100); c.countDown(); Thread.sleep(5000); Singleton.getInstance(); &#125; static long start = System.currentTimeMillis();//记录启动时间 public static void debug(String msg) &#123; System.out.println(System.currentTimeMillis() - start + "|" + Thread.currentThread().getName() + ":" + msg); &#125;&#125; 执行日志123456789101112131415161718192021222324252627282930313233343536373839404142434445464748|thread0:线程创建完毕等待执行48|thread2:线程创建完毕等待执行48|thread1:线程创建完毕等待执行48|thread3:线程创建完毕等待执行48|thread4:线程创建完毕等待执行48|thread5:线程创建完毕等待执行48|thread6:线程创建完毕等待执行48|thread9:线程创建完毕等待执行49|thread7:线程创建完毕等待执行49|thread8:线程创建完毕等待执行149|thread0:准备获取对象149|thread1:准备获取对象149|thread5:准备获取对象149|thread9:准备获取对象149|thread9:singleton为null,准备获得锁149|thread9:singleton为null,开始执行创建149|thread2:准备获取对象149|thread2:singleton不为null,直接返回149|thread2:获得单例对象,该对象是由线程null创建的149|thread8:准备获取对象149|thread7:准备获取对象149|thread5:singleton为null,准备获得锁149|thread6:准备获取对象150|thread6:singleton不为null,直接返回150|thread6:获得单例对象,该对象是由线程null创建的149|thread1:singleton为null,准备获得锁149|thread4:准备获取对象150|thread4:singleton不为null,直接返回150|thread4:获得单例对象,该对象是由线程null创建的149|thread0:singleton为null,准备获得锁149|thread3:准备获取对象150|thread3:singleton不为null,直接返回149|thread7:singleton不为null,直接返回150|thread7:获得单例对象,该对象是由线程null创建的149|thread8:singleton不为null,直接返回150|thread3:获得单例对象,该对象是由线程null创建的150|thread8:获得单例对象,该对象是由线程null创建的2150|thread9:-----singleton创建完毕-------2150|thread9:获得单例对象,该对象是由线程thread9创建的2150|thread0:获得锁后发现singleton已经创建,直接返回2150|thread0:获得单例对象,该对象是由线程thread9创建的2150|thread1:获得锁后发现singleton已经创建,直接返回2150|thread1:获得单例对象,该对象是由线程thread9创建的2150|thread5:获得锁后发现singleton已经创建,直接返回2150|thread5:获得单例对象,该对象是由线程thread9创建的5150|main:singleton不为null,直接返回5162|main:获得单例对象,该对象是由线程thread9创建的 实际执行过程第一批线程thread9获得锁，执行到第4步后开始等待 第二批线程thread2，thread6，thread4，thread3，thread7，thread8执行到第1步发现对象不为null，就直接返回了，但这时候initThreadName属性还没赋值，所以拿到对象后打印出来的信息为 12singleton不为null,直接返回获得单例对象,该对象是由线程null创建的 第三批线程thread0,thread1,thread5执行到第2步后开始等待，等到thread9释放锁后在第3步返回，因此他们得到的信息是正确的 12获得锁后发现singleton已经创建,直接返回获得单例对象,该对象是由线程thread9创建的 问题第二批线程获取对象的时候，虽然singleton不为null，但里面的属性还未赋值，所以拿到对象后立即操作就会出现问题，如前所述发现initThreadName是null 解决办法创建一个临时对象，先初始化完毕后再赋值给singleton，简单来说就是讲4，5两步对调 12345678//原代码singleton = new Singleton();//4singleton.initThreadName = Thread.currentThread().getName();//5//新代码Singleton temp= new Singleton();temp.initThreadName = Thread.currentThread().getName();//5singleton=temp;//4 通常来说，大部分情况下是没问题的，但理论上不是这样，写线程和读线程看到的singleton对象，对于计算机来说不是同一个 1234//写线程，在写线程的工作内存为singleton赋值后，需要将这份数据赋值到主内存singleton=temp;//读线程，需要将主内存的数据复制到当前工作线程，然后才能判断数据是否为nullif (singleton != null) &#123; 这里牵扯到java内存模型的问题，java线程是不能直接操作主内存的，每个线程都只能修改自己工作内存，然后将值复制到主内存 singleton=temp虽然只有一句，但需要在2个地方写数据，再加上写操作本身就需要store和write 123456789JAVA内存模型规定工作内存与主内存之间的交互协议，其中包括8种原子操作：1）lock(锁定)：将一个变量标识为被一个线程独占状态。2）unlock(解锁)：将一个变量从独占状态释放出来，释放后的变量才可以被其他线程锁定。3）read(读取)：将一个变量的值从主内存传输到工作内存中，以便随后的load操作。4）load(载入)：把read操作从主内存中得到的变量值放入工作内存的变量的副本中。5）use(使用)：把工作内存中的一个变量的值传给执行引擎，每当虚拟机遇到一个使用到变量的指令时都会使用该指令。6）assign(赋值)：把一个从执行引擎接收到的值赋给工作内存中的变量，每当虚拟机遇到一个给变量赋值的指令时，都要使用该操作。7）store(存储)：把工作内存中的一个变量的值传递给主内存，以便随后的write操作。8）write(写入)：把store操作从工作内存中得到的变量的值写到主内存中的变量 简单来说，多线程环境下，一个线程修改了singleton的信息，另一个线程并不能马上知道完整信息，理论上虽然 if (singleton != null) 判断为true，但线程所获得的singleton 仍然有可能是不完整的 Volatile测试12345678910111213141516171819202122232425262728293031package thread;public class VolatileTest &#123; private static int value = 0;//不加volatile关键字,监听线程是感知不到value值变化的 public static void main(String[] args) &#123; Runnable change=()-&gt;&#123; try&#123; while (value&lt;5)&#123; Thread.sleep(100); value++; System.out.println("修改线程将value修改为:"+value); &#125; &#125;catch (Exception ex)&#123; ex.printStackTrace(); &#125; &#125;; Runnable chanListener=()-&gt;&#123; int local=value; while (value &lt; 5) &#123; if(local!=value)&#123; System.out.println("监听线程发现value已经改变:" +value+"!="+local); local = value; &#125; &#125; &#125;; new Thread(chanListener,"chanListener").start(); new Thread(change,"change").start(); &#125;&#125; 总结所以使用double check方式生成单例需要注意 1.singleton所有初始化工作需要在赋值之前 2.singleton变量需要加上volatile关键字 1234567891011public class Singleton &#123; private static volatile Singleton singleton;//变量设置为volatile ... public static Singleton getInstance() &#123; ... Singleton temp= new Singleton(); //初始化所需的其它字段 ... singleton=temp;//将完整对象赋值给singleton &#125; &#125; 当然创建单例的方式有很多种，实际工作中可以用恶汉模式，或者内部类方式，通过内部类方式实现代码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package thread.innerclass;import java.util.ArrayList;import java.util.List;import java.util.concurrent.CountDownLatch;public class Singleton &#123; private String initThreadName; private Singleton() &#123; &#125; private static class SingletonHandler &#123; private static Singleton singleton = init(); private static Singleton init()&#123; System.out.println("初始化singleton"); Singleton singleton= new Singleton(); singleton.initThreadName=Thread.currentThread().getName(); return singleton; &#125; &#125; public static Singleton getInstance() &#123; return SingletonHandler.singleton; &#125; public static void main(String args[]) throws InterruptedException &#123; debug("只执行静态方法是不会加载对象的"); List&lt;Thread&gt; list = new ArrayList&lt;&gt;(); CountDownLatch c = new CountDownLatch(1); for (int i = 0; i &lt; 10; i++) &#123; Runnable run = () -&gt; &#123; try &#123; debug("线程创建完毕等待执行"); c.await();//等待线程全部到达 debug("准备获取对象"); Singleton singleton = getInstance(); debug("获得单例对象,该对象是由线程" + singleton.initThreadName + "创建的"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;; new Thread(run, "thread" + i).start(); &#125; Thread.sleep(100); c.countDown(); &#125; static long start = System.currentTimeMillis();//记录启动时间 public static void debug(String msg) &#123; System.out.println(System.currentTimeMillis() - start + "|" + Thread.currentThread().getName() + ":" + msg); &#125;&#125;]]></content>
      <categories>
        <category>design</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>设计</tag>
        <tag>单例</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日志收集器]]></title>
    <url>%2Fblog%2Fcode%2F%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E5%99%A8%2F</url>
    <content type="text"><![CDATA[系统概述主要功能，根据配置读取指定服务器上的日志，格式化后发送到日志中心 用到的第三方系统springboot-2.0.3.RELEASE​ 项目是web工程，使用内嵌tomcat方式，页面转发使用springmvc elasticsearch-6.3.0​ 持久化用的是elasticsearch，如何读取日志相关的配置信息都放在elasticsearch上。读到的日志默认也是存到elasticsearch里面 httpclient-4.5.5​ 和elasticsearch通信全部走的是restful接口，用httpclient进行通讯 druid-1.1.9​ 查询的时候页面传进来的是sql语句，用druid的sql parser模块解析sql语句，转为elasticsearch的DSL ace-editor​ 为了方便用户编写sql，引入了ace-editor作为在线编辑器 velocity​ 模板引擎，当需要返回页面时用velocity解析 约定​ 根据convention over configuration原则，编码风格大部分采用springboot的方式，还有一些自定义规则，在不影响性能的前提下，同类型代码尽量采用同一套标准。 ​ 这些规则只是一些人为规定，无所谓好或不好，只是为了查找代码方便。当系统出现bug的时候，特定命名规则下的类行为基本可以预测，调试时可以大大加快效率。 命名规则所有的包均采用这种行形式 12wang.wangby.$&#123;项目&#125;.类型wang.wangby.$&#123;项目&#125;.$&#123;子项目&#125;.类型 特殊的包名一些特定的包名下只能存放指定的类，这些类均有自己的特殊功能。不是这些功能的类，不允许放在这下面 model格式12wang.wangby.$&#123;项目&#125;.model.XXX.XXXwang.wangby.$&#123;项目&#125;.$&#123;子项目&#125;.model.XXX.xxX 功能​ 封装参数，Controller和service，service和dao之间只能传递基本类型和model类 约定 所有model均实现了wang.wangby.model.Dto接口 类名都添加了标签@Data 所有model类都必须有且只有1个主键，主键上加了注解@wang.wangby.annotation.persistence.Id 内部不允许调使用任何非java或wang.wangby.utils开头的类 不允许添加get和set方法，需要的话直接添加属性 新增的public方法只能是无参的 一个项目下的model不允许重名，不论包名是否一样 model.vo格式12wang.wangby.$&#123;项目&#125;.model.vo.XXX.XXXwang.wangby.$&#123;项目&#125;.$&#123;子项目&#125;.model.vo.XXX.XXX 功能​ 封装那些需要在各层之间传输，但没有主键，不需要持久化的对象。可以不实现dto接口 约定​ 和model类一样，只不过没有主键 controller格式12wang.wangby.$&#123;项目&#125;.controller.XXXwang.wangby.$&#123;项目&#125;.$&#123;子项目&#125;.controller.XXX 功能​ 处理请求的url，返回页面或者json 约定 类名均叫xxxController 一个项目下Controller不能重名，不论包名是否一样 全部继承自wang.wangby.controller.BaseController 类上全部加了注解@RestController 类上全部加了注解@RequestMapping，并且value=xxx 所有方法均标记@RequestMapping，value和方法名一样，方法不允许重载 返回值 需要返回json的时候，返回值全部放在Response.data里面 需要返回页面的时候，直接用velocity解析然后返回string service格式12wang.wangby.$&#123;项目&#125;.service.XXXwang.wangby.$&#123;项目&#125;.$&#123;子项目&#125;.service.XXX 功能​ 处理业务逻辑，如需事务设置在这层 约定 service包下的所有类均叫xxxService 类上全部加了注解@org.springframework.stereotype.Service 所有属性只通过@Autowired注解注入 页面映射规则controller请求所有从controller请求格式都是这样的 12/xxx/method/子项目/xxx/method 每个url规定都由xxxController.method处理 url确定了，返回的视图也是固定的，/src/main/java/resources/templates/xxx/method.html，如果有子项目就是/src/main/java/resources/templates/子项目/xxx/method.html 静态资源静态资源全部放在/src/main/java/resources 样式文件/src/main/java/resources/css 图片/src/main/java/resources/img js/src/main/java/resources/js 所有引入js的代码均在/src/main/java/resources/js/importJs.js 开始编码初始化项目新增目录 log-collector：项目跟路径 ​ src ​ main ​ java：源代码 ​ resources：资源文件 ​ static：静态资源 ​ templates：页面 ​ test ​ java：测试代码 添加pom.xml1234567891011121314151617181920212223242526272829303132333435363738394041&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;log-collector&lt;/artifactId&gt; &lt;parent&gt; &lt;groupId&gt;wang.wangby&lt;/groupId&gt; &lt;artifactId&gt;web-parent&lt;/artifactId&gt; &lt;version&gt;0.1&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;wang.wangby&lt;/groupId&gt; &lt;artifactId&gt;webapp-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;my.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; web-parent12345&lt;parent&gt;&lt;groupId&gt;wang.wangby&lt;/groupId&gt; &lt;artifactId&gt;web-parent&lt;/artifactId&gt; &lt;version&gt;0.1&lt;/version&gt;&lt;/parent&gt; web-parent继承自org.springframework.boot:spring-boot-dependencies:2.0.3.RELEASE指定了一些常用的第三jar包的版本号，所有导入第三方jar是通常不需要写版本号 对于自己编写的项目，统一用${my.version} 12345&lt;dependency&gt; &lt;groupId&gt;wang.wangby&lt;/groupId&gt; &lt;artifactId&gt;XXX-XXX&lt;/artifactId&gt; &lt;version&gt;$&#123;my.version&#125;&lt;/version&gt; &lt;/dependency&gt; base-test继承的同时还自动引入了，scrop为test 测试工具包，引入了powermock，提供了一些测试常用的功能 格式化判断字符串是否相等 并发执行代码 脱离spirng容器初始化对象 … 编写testcase的时候继承TestBase就好 默认scope是test webapp-starter12345&lt;dependency&gt; &lt;groupId&gt;wang.wangby&lt;/groupId&gt; &lt;artifactId&gt;webapp-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;my.version&#125;&lt;/version&gt;&lt;/dependency&gt; 引入web工程所需的包和一些默认配置，具体有 spring-mvc 默认json解析改用fastJson BigInteger和Long均输出字符串 忽略所有null字段 日期按毫秒形式出书 拦截所有返回值的是Response对象的方法，如果出异常了，就拦截并且返回Response.fail(ex.getMessage()); 字符串和日期的转换类换成wang.wangby.springboot.autoconfigure.mvc.StringToDateConverter 允许格式yyyy-MM-dd HH:mm:ss|yyyy-MM-dd|纯数字 #####web相关 my.webfilter.enable=true就添加一些httpfilter wang.wangby.web.webfilter.QueueFilter：限制系统允许的最大并发数，超过数量直接返回默认字符串 wang.wangby.web.webfilter.StatistFilter：统计每个请求耗时 #####页面相关 初始化了velocity引擎，使用时调用wang.wangby.utils.template.TemplateUtil里的方法就好了 前端框引入了bootstrap和jquery spring-boot-configuration-processor12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; spring提供的工具类，引入这个jar后，在项目里修改application.yaml就会有提示了]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>code</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch]]></title>
    <url>%2Fblog%2Felasticseach%2Felasticseach%2F</url>
    <content type="text"><![CDATA[elasticsearch使用 安装elasticsearchhttps://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.3.0.zip 修改配置 config/elasticsearch.yml 1234567http.cors.enabled: true http.cors.allow-origin: "*"node.master: truenode.data: truenetwork.host: 0.0.0.0cluster.name: my-applicationnode.name: node-1 中文分词器https://codeload.github.com/medcl/elasticsearch-analysis-ik/zip/master 1E:\soft\elasticseach\elasticsearch-6.3.0\bin&gt;elasticsearch-plugin.bat install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.3.0/elasticsearch-analysis-ik-6.3.0.zip 测试 12345GET _analyze?pretty&#123; "analyzer": "ik_smart", "text": "中华人民共和国国歌"&#125; elasticsearch-headhttps://codeload.github.com/mobz/elasticsearch-head/zip/v5.0.0 123cd E:\soft\elasticseach\elasticsearch-head-5.0.0npm install -g grunt-clinpm install 启动elasticsearch123e:cd E:\soft\elasticseach\elasticsearch-6.3.0\binelasticsearch.bat http://127.0.0.1:9200/ kibana123e:cd E:\soft\elasticseach\kibana-6.2.4-windows-x86_64\binkibana.bat http://127.0.0.1:5601 elasticsearch-head12cd E:\soft\elasticseach\elasticsearch-head-5.0.0\grunt server http://127.0.0.1:9100/ 基本操作查看状态1GET _cat/health?v 12epoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent1547428524 01:15:24 elasticsearch green 1 1 0 0 0 0 0 0 - 100.0% 增设置mapping123456789101112131415161718192021222324PUT store&#123; "mappings":&#123; "book": &#123; "properties": &#123; "bookId": &#123;"type": "long"&#125;, "bookName": &#123;"type": "text"&#125;, "publishDate": &#123; "type": "date", "format": "yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis" &#125;, "description": &#123; "type": "text", "analyzer": "ik_max_word", &#125;, "isbn": &#123;"type": "text"&#125;, "tags": &#123; "type":"keyword" &#125;, "price":&#123;"type":"long"&#125; &#125; &#125; &#125;&#125; 新增数据1234567891011121314151617181920212223242526272829303132PUT /store/book/1&#123; "bookId":1, "bookName":"深入理解虚拟机", "description":"售价100的java图书,包含虚拟机", "isbn":"11233123", "price":100, "publishDate":1547430116594, "tags":["java","虚拟机"]&#125;PUT /store/book/2&#123; "bookId":2, "bookName":"java最佳实践", "description":"售价200的java图书", "isbn":"11233123", "price":200, "publishDate":1547430116594, "tags":["java"]&#125;PUT /store/book/3&#123; "bookId":2, "bookName":"设计模式与java", "description":"售价300的java图书,关于设计模式的", "isbn":"11233123", "price":200, "publishDate":1547430116594, "tags":["java","设计模式"]&#125; 删改1234567POST /store/book/1/_update&#123; "doc": &#123; "description":"更新后的描述信息" &#125;&#125; 查查询全部1GET /store/book/_search 1234GET /store/book/_search&#123; "query": &#123;"match_all":&#123;&#125;&#125;&#125; 按字段匹配，排序123456789101112131415161718GET /store/book/_search&#123; "query": &#123; "match": &#123; "tags": "java" &#125; &#125;, "sort": [ &#123; "price": &#123; "order": "desc" &#125; &#125; ]&#125; 多条件12345678910111213141516171819202122GET /store/book/_search&#123; "query": &#123; "bool": &#123; "must": [ &#123; "match": &#123; "tags": "java" &#125; &#125; ], "filter": &#123; "range": &#123; "price": &#123; "gte": 100, "lte": 500 &#125; &#125; &#125; &#125; &#125;&#125; 分页from,size 相当于 mysql的limit 123456GET /store/book/_search&#123; "query": &#123;"match_all":&#123;&#125;&#125;, "from": 0, "size": 1&#125; 查询部分字段12345GET /store/book/_search&#123; "query": &#123;"match_all":&#123;&#125;&#125;, "_source": ["bookId","bookName"]&#125; 全文检索描述包含”售价 设计模式”排最前面 12345678GET /store/book/_search&#123; "query": &#123; "match": &#123; "description": "售价 设计模式" &#125; &#125;&#125; 高亮高亮描述字段 12345678910111213GET /store/book/_search&#123; "query": &#123; "match": &#123; "description": "售价 虚拟机" &#125; &#125;, "highlight": &#123; "fields": &#123; "description": &#123;&#125; &#125; &#125;&#125; 统计修改字段属性为可以统计123456789PUT /store/_mapping/book&#123; "properties": &#123; "tags":&#123; "type": "text", "fielddata": true &#125; &#125;&#125; groupby1select tags, count(*) from book group by tags 1234567891011GET /store/book/_search&#123; "aggs": &#123; "mygroup": &#123; "terms": &#123; "field": "tags" &#125; &#125; &#125;, "size": 0&#125; avg1select tags,count(*),avg(price) from book group by tags 123456789101112131415161718GET /store/book/_search&#123; "aggs": &#123; "groupbytags": &#123; "terms": &#123; "field": "tags" &#125;, "aggs": &#123; "avgprice": &#123; "avg": &#123; "field": "price" &#125; &#125; &#125; &#125; &#125;, "size": 0&#125; orderby1select tags,count(*),avg(price) avgprice pp from book group by tags order by avgprice 123456789101112131415161718192021GET /store/book/_search&#123; "aggs": &#123; "groupbytags": &#123; "terms": &#123; "field": "tags", "order": &#123; "avgprice": "asc" &#125; &#125;, "aggs": &#123; "avgprice": &#123; "avg": &#123; "field": "price" &#125; &#125; &#125; &#125; &#125;, "size": 0&#125; case123select count(case when price&gt;=0 and preie&lt;100 then tags, case when price&gt;=100 and preie&lt;200 then tags ) from book 1234567891011121314151617181920212223242526272829303132GET /store/book/_search&#123; "aggs": &#123; "statprice": &#123; "range": &#123; "field": "price", "ranges": [ &#123; "from":0, "to": 100 &#125;, &#123; "from":100, "to": 200 &#125;, &#123; "from":200, "to": 300 &#125; ] &#125;, "aggs": &#123; "groupbytags": &#123; "terms": &#123; "field": "tags" &#125; &#125; &#125; &#125; &#125;, "size": 0&#125;]]></content>
      <categories>
        <category>elasticseach</category>
      </categories>
      <tags>
        <tag>elasticseach</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[https流程]]></title>
    <url>%2Fblog%2Fhttp%2Fhttps%2F</url>
    <content type="text"><![CDATA[转自 https://blog.csdn.net/xiaopang_yan/article/details/78709574 https流程 step1： “客户”向服务端发送一个通信请求 step2： “服务器”向客户发送自己的数字证书。证书中有一个公钥用来加密信息，私钥由“服务器”持有 “服务器”-&gt;“客户”：你好，我是服务器，这里是我的数字证书 step3： “客户”收到“服务器”的证书后，它会去验证这个数字证书到底是不是“服务器”的，数字证书有没有什么问题，数字证书如果检查没有问题，就说明数字证书中的公钥确实是“服务器”的。检查数字证书后，“客户”会发送一个随机的字符串给“服务器”用私钥去加密，服务器把加密的结果返回给“客户”，“客户”用公钥解密这个返回结果，如果解密结果与之前生成的随机字符串一致，那说明对方确实是私钥的持有者，或者说对方确实是“服务器”。 “客户”-&gt;“服务器”：向我证明你就是服务器，这是一个随机字符串 //前面的例子中为了方便解释，用的是“你好”等内容，实际情况下一般是随机生成的一个字符串。 “服务器”-&gt;“客户”：{一个随机字符串}[私钥|RSA] step4： 验证“服务器”的身份后，“客户”生成一个对称加密算法和密钥，用于后面的通信的加密和解密。这个对称加密算法和密钥，“客户”会用公钥加密后发送给“服务器”，别人截获了也没用，因为只有“服务器”手中有可以解密的私钥。这样，后面“服务器”和“客户”就都可以用对称加密算法来加密和解密通信内容了。 “服务器”-&gt;“客户”：{OK，已经收到你发来的对称加密算法和密钥！有什么可以帮到你的？}[密钥|对称加密算法] “客户”-&gt;“服务器”：{我的帐号是aaa，密码是123，把我的余额的信息发给我看看}[密钥|对称加密算法] “服务器”-&gt;“客户”：{你好，你的余额是100元}[密钥|对称加密算法] …… //继续其它的通信]]></content>
      <categories>
        <category>http</category>
      </categories>
      <tags>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[httpclient使用]]></title>
    <url>%2Fblog%2Fhttp%2Fhttpclient%2F</url>
    <content type="text"><![CDATA[httpclient使用 1https://www.cnblogs.com/trust-freedom/p/6349502.html]]></content>
      <categories>
        <category>http</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>htpclient</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[wireshark]]></title>
    <url>%2Fblog%2Ftools%2Fwireshark%2F</url>
    <content type="text"><![CDATA[乱码 发现https乱码，可能是压缩问题，将压缩形式改为none]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>fidder</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jdk各个版本日期]]></title>
    <url>%2Fblog%2Fjava%2Fjdkvision%2F</url>
    <content type="text"><![CDATA[版本 名称 发行日期 JDK 1.1.4 Sparkler（宝石） 1997-09-12 JDK 1.1.5 Pumpkin（南瓜） 1997-12-13 JDK 1.1.6 Abigail（阿比盖尔–女子名） 1998-04-24 JDK 1.1.7 Brutus（布鲁图–古罗马政治家和将军） 1998-09-28 JDK 1.1.8 Chelsea（切尔西–城市名） 1999-04-08 J2SE 1.2 Playground（运动场） 1998-12-04 J2SE 1.2.1 none（无） 1999-03-30 J2SE 1.2.2 Cricket（蟋蟀） 1999-07-08 J2SE 1.3 Kestrel（美洲红隼） 2000-05-08 J2SE 1.3.1 Ladybird（瓢虫） 2001-05-17 J2SE 1.4.0 Merlin（灰背隼） 2002-02-13 J2SE 1.4.1 grasshopper（蚱蜢） 2002-09-16 J2SE 1.4.2 Mantis（螳螂） 2003-06-26 Java SE 5.0 (1.5.0) Tiger（老虎） 2004-09-30 Java SE 6.0 (1.6.0) Mustang（野马） 2006-04 Java SE 7.0 (1.7.0) Dolphin（海豚） 2011-07-28 Java SE 8.0 (1.8.0) Spider（蜘蛛） 2014-03-18 Java SE 9.0 2017-09-21]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker网络设置]]></title>
    <url>%2Fblog%2Fdocker%2Fdocker-net%2F</url>
    <content type="text"><![CDATA[个人笔记 本机ip 192.168.1.107 虚拟机ip 192.168.1.110 虚拟机操作创建网络 1docker network create --subnet=192.168.2.0/24 mynet 使用 12345678910version: '3'services: hello: container_name: hello networks: mynet: ipv4_address: 192.168.2.2networks: mynet: external: true 查看结果 1docker network inspect mynet 本机操作windows增加路由规则，将add 192.168.2.1请求转到192.168.1.110 1route add 192.168.2.1/24 192.168.1.110 问题某些端口无法访问查找新网卡名称 br-7cff62268b4c 12[root@centos7 hello]# ip addr|grep 192.168.2inet 192.168.2.1/24 scope global br-7cff62268b4c 设置iptables 1iptables -A DOCKER -d 192.168.2.1/24 ! -i br-7cff62268b4c -o br-7cff62268b4c -p tcp -m tcp --dport 8080 -j ACCEPT 命令记不住,可以导出以后配置修改 1iptables-save -t filter &gt; iptables.bak]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hbase]]></title>
    <url>%2Fblog%2Funcategorized%2Fhbase%2F</url>
    <content type="text"><![CDATA[hbase 基本命令 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136进入hbase shell console$HBASE_HOME/bin/hbase shell如果有kerberos认证，需要事先使用相应的keytab进行一下认证（使用kinit命令），认证成功之后再使用hbase shell进入可以使用whoami命令可查看当前用户hbase(main)&gt; whoami表的管理1）查看有哪些表hbase(main)&gt; list2）创建表# 语法：create &lt;table&gt;, &#123;NAME =&gt; &lt;family&gt;, VERSIONS =&gt; &lt;VERSIONS&gt;&#125;# 例如：创建表t1，有两个family name：f1，f2，且版本数均为2hbase(main)&gt; create 't1',&#123;NAME =&gt; 'f1', VERSIONS =&gt; 2&#125;,&#123;NAME =&gt; 'f2', VERSIONS =&gt; 2&#125;3）删除表分两步：首先disable，然后drop例如：删除表t1hbase(main)&gt; disable 't1'hbase(main)&gt; drop 't1'4）查看表的结构# 语法：describe &lt;table&gt;# 例如：查看表t1的结构hbase(main)&gt; describe 't1'5）修改表结构修改表结构必须先disable# 语法：alter 't1', &#123;NAME =&gt; 'f1'&#125;, &#123;NAME =&gt; 'f2', METHOD =&gt; 'delete'&#125;# 例如：修改表test1的cf的TTL为180天hbase(main)&gt; disable 'test1'hbase(main)&gt; alter 'test1',&#123;NAME=&gt;'body',TTL=&gt;'15552000'&#125;,&#123;NAME=&gt;'meta', TTL=&gt;'15552000'&#125;hbase(main)&gt; enable 'test1'权限管理1）分配权限# 语法 : grant &lt;user&gt; &lt;permissions&gt; &lt;table&gt; &lt;column family&gt; &lt;column qualifier&gt; 参数后面用逗号分隔# 权限用五个字母表示： "RWXCA".# READ('R'), WRITE('W'), EXEC('X'), CREATE('C'), ADMIN('A')# 例如，给用户‘test'分配对表t1有读写的权限，hbase(main)&gt; grant 'test','RW','t1'2）查看权限# 语法：user_permission &lt;table&gt;# 例如，查看表t1的权限列表hbase(main)&gt; user_permission 't1'3）收回权限# 与分配权限类似，语法：revoke &lt;user&gt; &lt;table&gt; &lt;column family&gt; &lt;column qualifier&gt;# 例如，收回test用户在表t1上的权限hbase(main)&gt; revoke 'test','t1'表数据的增删改查1）添加数据# 语法：put &lt;table&gt;,&lt;rowkey&gt;,&lt;family:column&gt;,&lt;value&gt;,&lt;timestamp&gt;# 例如：给表t1的添加一行记录：rowkey是rowkey001，family name：f1，column name：col1，value：value01，timestamp：系统默认hbase(main)&gt; put 't1','rowkey001','f1:col1','value01'用法比较单一。2）查询数据a）查询某行记录# 语法：get &lt;table&gt;,&lt;rowkey&gt;,[&lt;family:column&gt;,....]# 例如：查询表t1，rowkey001中的f1下的col1的值hbase(main)&gt; get 't1','rowkey001', 'f1:col1'# 或者：hbase(main)&gt; get 't1','rowkey001', &#123;COLUMN=&gt;'f1:col1'&#125;# 查询表t1，rowke002中的f1下的所有列值hbase(main)&gt; get 't1','rowkey001'b）扫描表# 语法：scan &lt;table&gt;, &#123;COLUMNS =&gt; [ &lt;family:column&gt;,.... ], LIMIT =&gt; num&#125;# 另外，还可以添加STARTROW、TIMERANGE和FITLER等高级功能# 例如：扫描表t1的前5条数据hbase(main)&gt; scan 't1',&#123;LIMIT=&gt;5&#125;c）查询表中的数据行数# 语法：count &lt;table&gt;, &#123;INTERVAL =&gt; intervalNum, CACHE =&gt; cacheNum&#125;# INTERVAL设置多少行显示一次及对应的rowkey，默认1000；CACHE每次去取的缓存区大小，默认是10，调整该参数可提高查询速度# 例如，查询表t1中的行数，每100条显示一次，缓存区为500hbase(main)&gt; count 't1', &#123;INTERVAL =&gt; 100, CACHE =&gt; 500&#125;3）删除数据a )删除行中的某个列值# 语法：delete &lt;table&gt;, &lt;rowkey&gt;, &lt;family:column&gt; , &lt;timestamp&gt;,必须指定列名# 例如：删除表t1，rowkey001中的f1:col1的数据hbase(main)&gt; delete 't1','rowkey001','f1:col1'注：将删除改行f1:col1列所有版本的数据b )删除行# 语法：deleteall &lt;table&gt;, &lt;rowkey&gt;, &lt;family:column&gt; , &lt;timestamp&gt;，可以不指定列名，删除整行数据# 例如：删除表t1，rowk001的数据hbase(main)&gt; deleteall 't1','rowkey001'c）删除表中的所有数据# 语法： truncate &lt;table&gt;# 其具体过程是：disable table -&gt; drop table -&gt; create table# 例如：删除表t1的所有数据hbase(main)&gt; truncate 't1'Region管理1）移动region# 语法：move 'encodeRegionName', 'ServerName'# encodeRegionName指的regioName后面的编码，ServerName指的是master-status的Region Servers列表# 示例hbase(main)&gt;move '4343995a58be8e5bbc739af1e91cd72d', 'db-41.xxx.xxx.org,60020,1390274516739'2）开启/关闭region# 语法：balance_switch true|falsehbase(main)&gt; balance_switch3）手动split# 语法：split 'regionName', 'splitKey'4）手动触发major compaction#语法：#Compact all regions in a table:#hbase&gt; major_compact 't1'#Compact an entire region:#hbase&gt; major_compact 'r1'#Compact a single column family within a region:#hbase&gt; major_compact 'r1', 'c1'#Compact a single column family within a table:#hbase&gt; major_compact 't1', 'c1'配置管理及节点重启1）修改hdfs配置hdfs配置位置：/etc/hadoop/conf# 同步hdfs配置cat /home/hadoop/slaves|xargs -i -t scp /etc/hadoop/conf/hdfs-site.xml hadoop@&#123;&#125;:/etc/hadoop/conf/hdfs-site.xml#关闭：cat /home/hadoop/slaves|xargs -i -t ssh hadoop@&#123;&#125; "sudo /home/hadoop/cdh4/hadoop-2.0.0-cdh4.2.1/sbin/hadoop-daemon.sh --config /etc/hadoop/conf stop datanode"#启动：cat /home/hadoop/slaves|xargs -i -t ssh hadoop@&#123;&#125; "sudo /home/hadoop/cdh4/hadoop-2.0.0-cdh4.2.1/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start datanode"2）修改hbase配置hbase配置位置：# 同步hbase配置cat /home/hadoop/hbase/conf/regionservers|xargs -i -t scp /home/hadoop/hbase/conf/hbase-site.xml hadoop@&#123;&#125;:/home/hadoop/hbase/conf/hbase-site.xml # graceful重启cd ~/hbasebin/graceful_stop.sh --restart --reload --debug inspurXXX.xxx.xxx.org]]></content>
  </entry>
  <entry>
    <title><![CDATA[docker]]></title>
    <url>%2Fblog%2Fdocker%2Fdocker%2F</url>
    <content type="text"><![CDATA[docker 转自 https://blog.csdn.net/birdben/article/details/49873725 基本命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107# 在ubuntu中安装docker$ sudo apt-get install docker.io# 查看docker的版本信息$ docker version# 查看安装docker的信息$ docker info# 查看本机Docker中存在哪些镜像$ docker images# 检索image$ docker search ubuntu:14.04# 在docker中获取ubuntu镜像$ docker pull ubuntu:14.04# 显示一个镜像的历史$ docker history birdben/ubuntu:v1# 列出一个容器里面被改变的文件或者目$ docker diff birdben/ubuntu:v1# 从一个容器中取日志$ docker logs birdben/ubuntu:v1# 显示一个运行的容器里面的进程信息$ docker top birdben/ubuntu:v1# 从容器里面拷贝文件/目录到本地一个路径$ docker cp ID:/container_path to_path# 列出当前所有正在运行的容器$ docker ps# 列出所有的容器$ docker ps -a# 列出最近一次启动的容器$ docker ps -l# 查看容器的相关信息$ docker inspect $CONTAINER_ID# 显示容器IP地址和端口号，如果输出是空的说明没有配置IP地址（不同的Docker容器可以通过此IP地址互相访问）$ docker inspect --format='&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;' $CONTAINER_ID# 保存对容器的修改 $ docker commit -m "Added ssh from ubuntu14.04" -a "birdben" 6s56d43f627f3 birdben/ubuntu:v1# 参数：# -m参数用来来指定提交的说明信息；# -a可以指定用户信息的；# 6s56d43f627f3代表的时容器的id；# birdben/ubuntu:v1指定目标镜像的用户名、仓库名和 tag 信息。# 构建一个容器 $ docker build -t="birdben/ubuntu:v1" .# 参数：# -t为构建的镜像制定一个标签，便于记忆/索引等# . 指定Dockerfile文件在当前目录下，也可以替换为一个具体的 Dockerfile 的路径。# 在docker中运行ubuntu镜像$ docker run &lt;相关参数&gt; &lt;镜像 ID&gt; &lt;初始命令&gt;# 守护模式启动$ docker run -it ubuntu:14.04# 交互模式启动$ docker run -it ubuntu:14.04 /bin/bash# 指定端口号启动$ docker run -p 80:80 birdben/ubuntu:v1# 指定配置启动$ sudo docker run -d -p 10.211.55.4:9999:22 birdben/ubuntu:v1 '/usr/sbin/sshd' -D# 参数：# -d：表示以“守护模式”执行，日志不会出现在输出终端上。# -i：表示以“交互模式”运行容器，-i 则让容器的标准输入保持打开# -t：表示容器启动后会进入其命令行，-t 选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上# -v：表示需要将本地哪个目录挂载到容器中，格式：-v &lt;宿主机目录&gt;:&lt;容器目录&gt;，-v 标记来创建一个数据卷并挂载到容器里。在一次 run 中多次使用可以挂载多个数据卷。# -p：表示宿主机与容器的端口映射，此时将容器内部的 22 端口映射为宿主机的 9999 端口，这样就向外界暴露了 9999 端口，可通过 Docker 网桥来访问容器内部的 22 端口了。# 注意：这里使用的是宿主机的 IP 地址：10.211.55.4，与对外暴露的端口号 9999，它映射容器内部的端口号 22。ssh外部需要访问：ssh root@10.211.55.4 -p 9999# 不一定要使用“镜像 ID”，也可以使用“仓库名:标签名”# start 启动容器$ docker start 117843ade696117843ade696# stop 停止正在运行的容器$ docker stop 117843ade696117843ade696# restart 重启容器$ docker restart 117843ade696117843ade696# rm 删除容器$ docker rm 117843ade696117843ade696# rmi 删除镜像$ docker rmi ed9c93747fe1Deleted# 登录Docker Hub中心$ docker login# 发布上传image（push）$ docker push birdben/ubuntu:v1#进入容器$ ocker exec -it zookeeper_zoo3_1 bash 当利用 docker run 来创建容器时，Docker 在后台运行的标准操作包括： 检查本地是否存在指定的镜像，不存在就从公有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止 制作镜像2.使用docker commit 命令来创建镜像 通过docker run命令启动容器 修改docker镜像内容 docker commit提交修改的镜像 docker run新的镜像 2.使用 Dockerfile 来创建镜像Dockerfile 123456789101112131415161718# 生成的新镜像以centos镜像为基础FROM centos# 指定作者信息MAINTAINER wangym# 安装openssh-serverRUN yum -y install openssh-serverRUN mkdir /var/run/sshdRUN ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_keyRUN ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key# 指定root密码RUN /bin/echo 'root:123456'|chpasswdRUN /bin/sed -i 's/.*session.*required.*pam_loginuid.so.*/session optional pam_loginuid.so/g' /etc/pam.d/sshdRUN /bin/echo -e "LANG=\"en_US.UTF-8\"" &gt; /etc/default/localEXPOSE 22CMD /usr/sbin/sshd -D 运行 1docker build -t my/centos-ssh:1.0 .]]></content>
      <categories>
        <category>docker</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[rocketmq管理控制台]]></title>
    <url>%2Fblog%2Funcategorized%2Frocketmq%E7%AE%A1%E7%90%86%E6%8E%A7%E5%88%B6%E5%8F%B0%2F</url>
    <content type="text"><![CDATA[namesrv查询， topic管理，produce管理，consumer管理，message查询和重发，开发中。。。 topic查询 详情 新增 消息查询 详细信息]]></content>
      <tags>
        <tag>rocketmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[名词解释]]></title>
    <url>%2Fblog%2Funcategorized%2F%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A%2F</url>
    <content type="text"><![CDATA[编码中常用的名词解释 aop：Aspect Oriented Programming]]></content>
  </entry>
  <entry>
    <title><![CDATA[rocketmq个人定制]]></title>
    <url>%2Fblog%2Funcategorized%2Frocketmq%E4%B8%AA%E4%BA%BA%E5%AE%9A%E5%88%B6%2F</url>
    <content type="text"><![CDATA[由于网络和性能因素，rocketmq对于重复消费，顺序消费，以及事务消息的解决方案，就是不解决。 客户端根据自身业务情况，需要在一致性和可用性之间做出取舍，自己给出方案 我的方案是分别在发送方和消费方创建2张表：发送表和消费表，通过本地事务的方式解决。同时对于每个topic，新增一个结果确认的消息，发送方发送消息同时，需要消费这个结果确认的topic。大体流程 发送方往发送表插入记录，并生成sendid 发送方执行业务代码，如果成功就往MQ发送消息，如果失败则回滚事务 消费方收到消息后，往消费表插入记录，由于sendId做了唯一约束，如果插入失败，表明已经消费过了 插入成功后执行业务代码 业务本身的成功和失败，直接更新消费表 如果出现异常，回滚事务，相当于没消费 消费成功往MQ发送结果 发送方收到消费结果，更新发送表，本次消费结束 发送流程图 异常点由于执行的是本地事务，所以只要消息表里有记录，就说明业务成功了，需要发送消。如果没记录，就说明不需要发。唯一异常原因是消息没发送到MQ，这个问题可以等到消息确认环节再解决。 接收流程图 异常点业务自身结果，例如余额不足，库存不足等情况，属于业务状态，这种情况当做消费成功处理，只需要把结果通知到生产方就好了。只有出现了未知 错误的时候，消息表和业务一起回滚，等待消息重发。 非业务的因素的异常，就是成功消费后，未成功向mq发送结果，这个情况和发送时的异常一样，可以等到确认环节处理 结果确认流程图 异常点这个地方对于MQ来说不存在异常的的情况 补偿机制综上所述，对于MQ来说，所有因网络因素造成的消息未成功到达的情况，最终汇总后的结果都是发送表里的数据长期没有消费记录 所以要做的就是查询发送表里的超过一定时间，无消费结果的数据，向消费方发起查询。在主动查询的的情况下，只要不是服务器全部宕机，总能获取结果的，根据查询结果 如果是消费方未收到消息，就重发 如果消费方一直消费失败，发送预警，人工介入 已经有结果，直接更新记录 具体实现producer 在业务入口添加SendMessage注解 业务在需要发送某种消息的时候只需要调用msgService.send将数据插入消息表 msgService.send除了往数据库插入数据外，还会将插入的记录放一份到当前线程 被SendMessage注解的方法结束，系统会从当前线程取出在此期间插入的消息，自动往mq发送消息 1234567891011121314151617181920212223242526272829@Transactional@SendMessagepublic OrderInfo insert(Long userId, Long bookId, Integer amount) &#123; long orderId = newId(); OrderCreateMsg orderMsg = new OrderCreateMsg(); orderMsg.setBookId(bookId); orderMsg.setAmount(amount); orderMsg.setOrderId(orderId); Long orderSendId = msgService.send(orderMsg);//插入订单创建消息 EmailMsg email = new EmailMsg(); email.setContent("购买图书:" + bookId); email.setBusId(orderId + ""); email.setSubject("准备购买图书"); email.setToAddress("xxxxx@xxxx.com"); Long emailMsId = msgService.send(email);//插入邮件消息 OrderInfo order = new OrderInfo(); order.setBookMsId(orderSendId); order.setEmailMsId(emailMsId); order.setCreateTime(new Date()); order.setOrderId(orderId); order.setUserId(userId); order.setBookId(bookId); order.setAmount(amount); orderDao.insert(order); return order;&#125; 系统在创建一个topic的时候，会自动创建一个叫%RESULT%XXX的topic，这个功能在我自己写的rocketmq管理界面里实现了 produer决定往某个topic发送消息的时候，会通过push的方式消费这个topic对应的%RESULT%topic。 consumer消费者在监听到消息后，进入主业务方法 在这个方法上标注ConsumerMessage 业务方通过msgService.prepare判断消费是否重复消费 消费结束后通过msgService.consumer更新消费结果 系统在ConsumerMessage标记的方法结束后，会从当前线程取出消费过的消息，往MQ里发送消费结果 12345678910111213141516171819202122232425@ConsumerMessage@Transactionalpublic void sendEmail(MessageExt msg) throws Exception &#123; log.debug("收到邮件消息:" + jsonUtil.toString(msg)); EmailMsg email = msgService.prepare(msg, EmailMsg.class, true);//锁定 if (email == null) &#123; return; &#125; ConsumerResult result = ConsumerResult.UNKNOWN; try &#123; result = doBussiness(email); &#125; finally &#123; switch (result) &#123; case SUCCESS: case ROLLBACK: msgService.consumer(msg, email, result, true);//确认 break; case UNKNOWN: throw new RuntimeException("回滚事务,当做未消费处理"); default: break; &#125; &#125;&#125; 定时任务produer需启动一个定时任务，定期查询超过一定时间，还无消费结果记录。 1SELECT * FROM m_msgsend WHERE createTime&lt;TIMESTAMPADD(MINUTE,-10,NOW()) AND msgConsumerId IS NULL consumer端启动的时候，会自动启动一个服务，用于监听那些来查询消费结果的请求，这个用rocketmq封装的org.apache.rocketmq.remoting.netty.NettyRemotingServer实现 123456789101112private NettyRemotingServer server;public MsgConfirmServer(int threadNum,String host,int port,MsgService msgService,KvConfigService kvConfigService) &#123; this.executorService = Executors.newFixedThreadPool(threadNum, new ThreadFactoryImpl("MsgConfirmServer_")); NettyServerConfig config=new NettyServerConfig(); config.setListenPort(port); server=new NettyRemotingServer(config); //设置请求执行类 server.registerDefaultProcessor(new MsgConfirmProcessor(msgService), executorService); this.kvConfigService=kvConfigService; this.address=host+":"+port;&#125; MsgConfirmProcessor里的实现，就是简单的通过sendId查找消费结果 123456789101112131415161718public RemotingCommand processRequest(ChannelHandlerContext ctx, RemotingCommand request) throws Exception &#123; MsgConsumerHeader requestHeader = (MsgConsumerHeader) request.decodeCommandCustomHeader(MsgConsumerHeader.class); //查找通过发送id查找消费结果,如果没有记录说明还没被消费 MsgConsumer consumer=msgService.getBySendId(requestHeader.getSendId()); MsgConfirm confirm=new MsgConfirm(); if(consumer!=null) &#123; confirm.setBusState(consumer.getBusState()); confirm.setMsgConsumerId(consumer.getMsgConsumerId()); &#125; //封装结果 final RemotingCommand response = RemotingCommand.createResponseCommand(null); byte[] content = confirm.encode(); response.setBody(content); response.setCode(ResponseCode.SUCCESS); response.setRemark(null); return response;&#125; 封装请求的MsgConsumerHeader对象，里面只需要一个sendId参数 123456789@Datapublic class MsgConsumerHeader implements CommandCustomHeader&#123; //消息发送id private Long sendId; @Override public void checkFields() throws RemotingCommandException &#123; &#125;&#125; 顺序消费通过以上的方案解决了重复消费，和最终一致性的问题。至于顺序消费，不太严格的情况下，只要将消息按key做分类，MessageQueue本身是有顺序的，通常请求下都能保证 123456789// 根据key做hash保证相同的key进入相同的messagQueuepublic static class QueueSelector implements MessageQueueSelector &#123; public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; String s = arg + ""; int flag = Math.abs(s.hashCode()); int no = flag % mqs.size(); return mqs.get(no); &#125;&#125; 比较严格的情况下，将tag作为顺序的标识，同一业务下，每次插入消息发送表的时候，通过业务id查询最大的tag和当前的tag比较，如果tag+1和当前的不符的话，说明还有消息未到达，需等会再消费 1SELECT MAX(tag) FROM m_msgsend WHERE busid='xxxxx'; st=>start: 准备发送 beginTx=>subroutine: 开启事务 preSend=>operation: 插入发送表 preSendResult=>condition: 插入结果 sendFail=>end: 结束 sendBus=>operation: 业务代码 sendBusResult=>condition: 执行结果 commitTx=>subroutine: 提交事务 rollbackTx=>subroutine: 回滚事务 sendMessage=>end: 发送消到MQ st->beginTx->preSend->preSendResult preSendResult(no)->rollbackTx->sendFail preSendResult(yes)->sendBus->sendBusResult sendBusResult(yes)->commitTx->sendMessage sendBusResult(no)->rollbackTx->sendFail{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);st=>start: 收到消息 beginTx=>subroutine: 开始事务 insertConsumer=>operation: 插入消费表 insertReslut=>condition: 插入结果 ignore=>end: 重复消息,忽略 consumerBus=>operation: 业务代码 consumerResult=>condition: 执行成功 commitTx=>subroutine: 提交事务 rollTx=>subroutine: 回滚事务 consumerFail=>end: 系统异常,当做未消费处理 consumerSuccess=>operation: 消费成功,记录业务状态 sendResult=>operation: 向MQ发送消费结果 st->beginTx->insertConsumer->insertReslut insertReslut(no)->ignore insertReslut(yes)->consumerBus->consumerResult consumerResult(yes)->commitTx->consumerSuccess->sendResult consumerResult(no)->rollTx->consumerFail{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-1-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-1-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-1", options);st=>start: 收到消费结果 cond=>condition: 业务是否成功 success=>operation: 更新发送表 end=>end: 流程结束 rollback=>subroutine: 执行反向业务,更新发送表 st->cond cond(yes)->success->end cond(no)->rollback->end{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-2-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-2-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-2", options);]]></content>
      <tags>
        <tag>rocketmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[监控系统设计]]></title>
    <url>%2Fblog%2Fdesign%2F%E7%9B%91%E6%8E%A7%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[监控的重要性不言而喻，系统许多优化都必须建立在实际数据的基础上。 然而监控范围，监控频率以及监控数据保存时间一直是令人头疼的问题。 理想情况当然是越精确越好，但由于收性能和存储所限，往往都要对其中一部分做一些取舍 数据存储假设监控项有1W个，监控的数据类型为int32，记录为每分钟1条，那么理论上储存90天的数据最少需要 110000*4字节*60分钟*24小时*90天/1024B/1024K/1024M=4.82G 实际上由于存储方式的不同，大部分情况下1条数据的占用空间远不止4个字节。 优化方案定期汇总所以为了解决存储的问题，通常的做法是近期保存精确数据，长期保存趋势数据，超过1定时期的数据通过平均或求和的方式做一次汇总，将1分钟粗化到5分钟，1小时，1天，1周，甚至是1个月。 索引方式考虑到监控数据的特殊性，大部分监控项的取值范围其实变化不大，而且通常如果出现了未预计的统计范围，说明系统需要人工干预了。所以我将一份监控数据分2个地方存放，1个保存普通范围内的数据，1个保存超出范围的数据。 针对普通范围内的数据，正常情况下99%的数据都应该是在这个范围内的，而且由于是正常数据，所以粒度还能粗化，例如 正常情况下cup使用率是10%还是11%其实没有却别，我们都可以记为10 当一个接口1分钟内的平均访问量是10，如果统计粒度是秒，全部变动值都是8-12，那么将每秒都记录为10其实是没任何问题的，因为1秒内的订单算到上一秒和算到下一秒都是合理的。 这样做以后，保存数据时，只需要在头部保存所有可选值的范围，具体数据只存在这个范围内的索引位置。如下面这种结构 heaer 5 10 15 20 保存值 实际值 data1 0 5 data2 1 10 data3 1 10 data4 2 15 data5 0 5 data6 1 10 data7 3 20 data8 0 5 因为数据项只有4个，实际存储时可以只用2个bit，这样保存上面8条数据只需要用到2个字节，空间一下减少到了原来的1/4 压缩许多监控数据的变化都是周期性的，例如JVM的内存使用情况，总是缓慢增长，然后在某次GC后回到某一个值 针对这种数据，一些通用的压缩算法就能很好的处理，拿一段测试数据，分别用nappy和zip压缩 12345678910111213141516public static void main(String[] args) throws Exception &#123; ByteBuf buff = Unpooled.buffer(); int data=0; //12(5秒1次)*60分钟*24小时*90天 for (int i = 0; i &lt; 1555200; i++) &#123; data++; if(data%1000==0) &#123; data=0; &#125; buff.writeInt(data); &#125; createFile(buff,Compress.NONE); createFile(buff,Compress.ZIP); createFile(buff,Compress.SNAPPY);&#125; 结果为 原始大小 snappy zip 6076K 1002K 39K 极端情况下，5秒钟统计一次，90天的数据只要占用39K的磁盘空间 数据采集数据采用，可以采用服务端主动和客户端主动两种方式。但由服务端主动发起的方式存在一些弊端，因为服务端无法获知数据变化情况，所以大部分情况下服务端拉取的可能都是无变化或者变化不大的数据。而且大部分情况下服务端只能按监控项取值，这就造成了发起的链接好多，但大部分链接获取的数据量很少。 这里采用客户采集，然后根据根据时间或者某些条件，将数据发送给服务端的方式。而且由于上面说到的数据存储方案，客户端可以将一些取值范围相近的数据做一次处理然后统计发送，这样不仅减少请求次数，而且可以减少数据的发送量 开始时间 1514736000000 周期(秒) 5 heaer 5 10 15 20 位置 item1 item2 item3 … 1 0 0 0 2 1 1 2 3 1 2 3 4 2 2 3 5 0 1 2 6 1 3 3 7 3 1 2 8 0 2 3 … 可视化通过Echarts实现 报警]]></content>
      <categories>
        <category>design</category>
      </categories>
      <tags>
        <tag>监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cron]]></title>
    <url>%2Fblog%2Flinux%2Fcron%2F</url>
    <content type="text"><![CDATA[cron写法 cron表达式，有专门的语法，而且感觉有点绕人，不过简单来说，大家记住一些常用的用法即可，特殊的语法可以单独去查。cron一共有7位，但是最后一位是年，可以留空，所以我们可以写6位： 第一位，表示秒，取值0-59 第二位，表示分，取值0-59 第三位，表示小时，取值0-23 第四位，日期天/日，取值1-31 第五位，日期月份，取值1-12 第六位，星期，取值1-7，星期一，星期二…，注：不是第1周，第二周的意思另外：1表示星期天，2表示星期一。 第7为，年份，可以留空，取值1970-2099 cron中，还有一些特殊的符号，含义如下：()星号：可以理解为每的意思，每秒，每分，每天，每月，每年…(?)问号：问号只能出现在日期和星期这两个位置，表示这个位置的值不确定，每天3点执行，所以第六位星期的位置，我们是不需要关注的，就是不确定的值。同时：日期和星期是两个相互排斥的元素，通过问号来表明不指定值。比如，1月10日，比如是星期1，如果在星期的位置是另指定星期二，就前后冲突矛盾了。(-)减号：表达一个范围，如在小时字段中使用“10-12”，则表示从10到12点，即10,11,12(,)逗号：表达一个列表值，如在星期字段中使用“1,2,4”，则表示星期一，星期二，星期四(/)斜杠：如：x/y，x是开始值，y是步长，比如在第一位（秒） 0/15就是，从0秒开始，每15秒，最后就是0，15，30，45，60 另：/y，等同于0/y 下面列举几个例子:0 0 3 ? 每天3点执行0 5 3 ? 每天3点5分执行0 5 3 ? 每天3点5分执行，与上面作用相同0 5/10 3 ? 每天3点的 5分，15分，25分，35分，45分，55分这几个时间点执行0 10 3 ? 1 每周星期天，3点10分 执行，注：1表示星期天0 10 3 ? 1#3 每个月的第三个星期，星期天 执行，#号只能出现在星期的位置]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>cron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rocketmq下载]]></title>
    <url>%2Fblog%2Frocketmq%2Frockedmq%2F</url>
    <content type="text"><![CDATA[rocketmq下载 下载无法编译 1将rockedmq -all 下build下的plugin 全部包在 下 2.将classifier注释 123456&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-tcnative&lt;/artifactId&gt; &lt;version&gt;1.1.33.Fork22&lt;/version&gt; &lt;!--&lt;classifier&gt;$&#123;os.detected.classifier&#125;&lt;/classifier&gt;--&gt;&lt;/dependency&gt; 启动nameserver: 123e:cd E:\app\rocketmq\rocketmq-all-4.2.0-bin-release\binmqnameserver broker 123e:cd E:\app\rocketmq\rocketmq-all-4.2.0-bin-release\binmqbroker -c E:\opt\config\rocketmq\broker-a.properties 控制台 https://codeload.github.com/apache/rocketmq-externals/zip/master 12cd E:\app\rocketmq\rocketmq-externals\rocketmq-console\targetjava -jar rocketmq-console-ng-1.0.0.jar --server.port=7777 --rocketmq.config.namesrvAddr=127.0.0.1:9876]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pointcut配置]]></title>
    <url>%2Fblog%2Fcode%2Fspring%2Fpointcut%2F</url>
    <content type="text"><![CDATA[Pointcut配置，官方文档 名称..代表任意包。第一个*是返回值，第二个*是类名,第三个*是方法名 12@Pointcut("execution(* com.xyz.someapp..service.*.*(..))") public void businessService() &#123;&#125; 注解所有类注解包含Transactional 1@within(org.springframework.transaction.annotation.Transactional) 方法上包含注解Transactional 1@annotation(org.springframework.transaction.annotation.Transactional) 参数参数是特定类型 1args(com.my.model.Request) 与或非&amp;&amp; || ! 12345678@Pointcut("execution(public * *(..))")private void anyPublicOperation() &#123;&#125;@Pointcut("within(com.xyz.someapp.trading..*)")private void inTrading() &#123;&#125;@Pointcut("anyPublicOperation() &amp;&amp; inTrading()")private void tradingOperation() &#123;&#125;]]></content>
      <categories>
        <category>code</category>
        <category>spring</category>
      </categories>
      <tags>
        <tag>aop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot多数据源]]></title>
    <url>%2Fblog%2Fcode%2Fspringboot%2F%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%2F</url>
    <content type="text"><![CDATA[个人笔记 配置数据源yaml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960mysql: datasource: type: com.alibaba.druid.pool.DruidDataSource write: url: jdbc:mysql://127.0.0.1:3306/test?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 123456 driver-class-name: com.mysql.jdbc.Driver minIdle: 5 maxActive: 100 initialSize: 10 maxWait: 60000 timeBetweenEvictionRunsMillis: 60000 minEvictableIdleTimeMillis: 300000 validationQuery: select 'x' testWhileIdle: true testOnBorrow: false testOnReturn: false poolPreparedStatements: true maxPoolPreparedStatementPerConnectionSize: 50 removeAbandoned: true filters: stat read01: url: jdbc:mysql://127.0.0.1:3306/test_01?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 123456 driver-class-name: com.mysql.jdbc.Driver minIdle: 5 maxActive: 100 initialSize: 10 maxWait: 60000 timeBetweenEvictionRunsMillis: 60000 minEvictableIdleTimeMillis: 300000 validationQuery: select 'x' testWhileIdle: true testOnBorrow: false testOnReturn: false poolPreparedStatements: true maxPoolPreparedStatementPerConnectionSize: 50 removeAbandoned: true filters: stat read02: url: jdbc:mysql://127.0.0.1:3306/test_02?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 123456 driver-class-name: com.mysql.jdbc.Driver minIdle: 5 maxActive: 100 initialSize: 10 maxWait: 60000 timeBetweenEvictionRunsMillis: 60000 minEvictableIdleTimeMillis: 300000 validationQuery: select 'x' testWhileIdle: true testOnBorrow: false testOnReturn: false poolPreparedStatements: true maxPoolPreparedStatementPerConnectionSize: 50 removeAbandoned: true filters: stat Configuration12345678910111213141516171819202122232425262728293031@Configuration@Slf4jpublic class DataSourceConfiguration &#123; @Value("$&#123;mysql.datasource.type&#125;") private Class&lt;? extends DataSource&gt; dataSourceType; @Bean(name = "writeDataSource") @Primary @ConfigurationProperties(prefix = "mysql.datasource.write")//此注解会将返回值和配置信息自动匹配 public DataSource writeDataSource() throws IllegalArgumentException, IllegalAccessException &#123; log.debug("新增数据源writeDataSource"); return DataSourceBuilder.create().type(dataSourceType).build(); &#125; @Bean(name = "readDataSource01") @ConfigurationProperties(prefix = "mysql.datasource.read01") public DataSource readDataSourceOne() &#123; log.debug("新增数据源readDataSource01"); return DataSourceBuilder.create().type(dataSourceType).build(); &#125; @Bean(name = "readDataSource02") @ConfigurationProperties(prefix = "mysql.datasource.read02") public DataSource readDataSourceTwo() &#123; log.debug("新增数据源readDataSource02"); return DataSourceBuilder.create().type(dataSourceType).build(); &#125; &#125; 配置路由SqlSessionFactory设置DataSource为RoutingDataSource RoutingDataSource里放置所有数据源 Configuration12345678910111213141516171819202122232425262728293031323334353637383940@Configuration@AutoConfigureAfter(DataSourceConfiguration.class)public class DaoConfig &#123; @Autowired @Qualifier("writeDataSource") private DataSource writeDataSource; @Autowired @Qualifier("readDataSource01") private DataSource readDataSource01; @Autowired @Qualifier("readDataSource02") private DataSource readDataSource02; @Bean public RoutingDataSource routingDataSource() throws IllegalArgumentException, IllegalAccessException &#123; Map map = new HashMap(); map.put("default", writeDataSource); map.put("01", readDataSource01); map.put("02", readDataSource02); RoutingDataSource ds=new RoutingDataSource(writeDataSource, map); return ds; &#125; @Bean public SqlSessionFactory sqlSessionFactory(MybatisProperties properties, RoutingDataSource dataSource,CreatedCode code) throws Exception &#123; SqlSessionFactoryBean factory = new SqlSessionFactoryBean(); factory.setDataSource(dataSource); Resource[] resource =properties.resolveMapperLocations(); List list=new ArrayList(); list.addAll(Arrays.asList(resource)); list.addAll(code.getMyBatisMapping()); factory.setMapperLocations((Resource[]) list.toArray(new Resource[] &#123;&#125;)); return factory.getObject(); &#125; &#125; RoutingDataSource通过DbContextHolder获得当前使用数据源标识 1234567891011121314public class RoutingDataSource extends AbstractRoutingDataSource &#123; public RoutingDataSource(DataSource defaultTargetDataSource,Map&lt;String,DataSource&gt; datasource) &#123; Map map=datasource; this.setDefaultTargetDataSource(defaultTargetDataSource); this.setTargetDataSources(map); &#125; @Override protected Object determineCurrentLookupKey() &#123; return DbContextHolder.getDbType(); &#125;&#125; DbContextHolder内部的contextHolder和当前线程绑定 12345678910111213141516171819public class DbContextHolder &#123; public static final String DEFAULT="default"; private static final ThreadLocal&lt;String&gt; contextHolder = new ThreadLocal&lt;String&gt;() &#123; protected String initialValue() &#123; return DEFAULT; &#125; &#125;; public static String getDbType() &#123; return contextHolder.get(); &#125; public static void setDb(String key) &#123; contextHolder.set(key); &#125;&#125; 使用调用数据源之前，设置一下就行了，可以在Controller里直接写，也可以用AOP 注意切换要在开启事务之前 1DbContextHolder.setDb("01");]]></content>
      <categories>
        <category>code</category>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NIO]]></title>
    <url>%2Fblog%2Fcode%2Fjava%2FNIO%2F</url>
    <content type="text"><![CDATA[nio Selector 实现原理linux下select的实现是EpollSelectorImpl EPollArrayWrapper将Linux的epoll相关系统调用封装成了native方法供EpollSelectorImpl使用。 1234private native int epollCreate();private native void epollCtl(int epfd, int opcode, int fd, int events);private native int epollWait(long pollAddress, int numfds, long timeout, int epfd) throws IOException; epoll原理epoll是Linux下的一种IO多路复用技术，可以非常高效的处理数以百万计的socket句柄。先看看使用c封装的3个epoll系统调用: int epoll_create(int size) epoll_create建立一个epoll对象。参数size是内核保证能够正确处理的最大句柄数，多于这个最大数时内核可不保证效果。 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event) epoll_ctl可以操作epoll_create创建的epoll，如将socket句柄加入到epoll中让其监控，或把epoll正在监控的某个socket句柄移出epoll。 int epoll_wait(int epfd, struct epoll_event *events,int maxevents, int timeout) epoll_wait在调用时，在给定的timeout时间内，所监控的句柄中有事件发生时，就返回用户态的进程。 大概看看epoll内部是怎么实现的： epoll初始化时，会向内核注册一个文件系统，用于存储被监控的句柄文件，调用epoll_create时，会在这个文件系统中创建一个file节点。同时epoll会开辟自己的内核高速缓存区，以红黑树的结构保存句柄，以支持快速的查找、插入、删除。还会再建立一个list链表，用于存储准备就绪的事件。 当执行epoll_ctl时，除了把socket句柄放到epoll文件系统里file对象对应的红黑树上之外，还会给内核中断处理程序注册一个回调函数，告诉内核，如果这个句柄的中断到了，就把它放到准备就绪list链表里。所以，当一个socket上有数据到了，内核在把网卡上的数据copy到内核中后，就把socket插入到就绪链表里。 当epoll_wait调用时，仅仅观察就绪链表里有没有数据，如果有数据就返回，否则就sleep，超时时立刻返回。 epoll的两种工作模式： LT：level-trigger，水平触发模式，只要某个socket处于readable/writable状态，无论什么时候进行epoll_wait都会返回该socket。 ET：edge-trigger，边缘触发模式，只有某个socket从unreadable变为readable或从unwritable变为writable时，epoll_wait才会返回该socket。 socket读数据 socket写数据 顺便说下在Linux系统中JDK NIO使用的是 LT ，而Netty epoll使用的是 ET。 NIO比BIO效率高原因网上大多给出了两者的区别，可是具体效率高在哪里呢。 首先我们看一下各自的特点BIO： socketServer的accept方法是阻塞的。 当有连接请求时，socketServer通过accept方法获取一个socket 取得socket后，将这个socket分给一个线程去处理。此时socket需要等待有效的请求数据到来后，才可以真正开始处理请求。 socket交给线程后，这时socketServer才可以接收下一个连接请求。 获得连接的顺序是和客户端请求到达服务器的先后顺序相关。 NIO： 基于事件驱动，当有连接请求，会将此连接注册到多路复用器上（selector）。 在多路复用器上可以注册监听事件，比如监听accept、read 通过监听，当真正有请求数据时，才来处理数据。 不会阻塞，会不停的轮询是否有就绪的事件，所以处理顺序和连接请求先后顺序无关，与请求数据到来的先后顺序有关 主要对比这里写的有点问题，NIO处理的时候也需要多个线程的，针对2，那个7秒对java来说是不存在的 BIO一个连接，一个线程，非http请求，有可能只连接不发请求数据，此时线程是无用浪费的。 BIO处理依赖于连接建立；NIO处理依赖于请求数据的到来。导致执行顺序不同。 一个线程处理一个请求BIO：连接请求来，建立socket，等待请求数据到来（t1），处理时间（t2）NIO：连接请求来，注册到selector，设置读监听，等待请求数据（t1），处理时间（t2）此时，两者用时皆为t1+t2，没有区别 一个线程处理两个请求第一个请求，等待请求数据（10），处理时间（1）第二个请求，等待请求数据（1），处理时间（2）BIO：用时 10+1+1+2=14，第1个执行完用时10+1，等待第一个执行完处理第2个，用时1+2NIO：用时 1+2+7+1=11， 第二个数据先到，时间 1+2，此时第一个需要等时为10秒，还没到，还需等待7秒，时间为7+1 两个线程处理两个请求第一个请求，等待请求数据（10），处理时间（1）第二个请求，等待请求数据（1），处理时间（2）BIO：用时 10+1+2=13，等待第1个请求10，交给工作线程一处理，此时同时接受第2个，等待1秒，处理时间2秒，此间线程一处理时间为一秒，在线程二结束之前就已经结束NIO：用时 1+2+7+1=11，第二个数据先到，时间 1+2，此时第一个还没到，还需等待7秒，时间为7+1如果两个请求顺序相反，则bio和nio一样，都是11秒由此可见由于阻塞等待机制的不同，导致效率不同，主要优化点为，不必排队等待，先到先处理，就有可能效率高一点。 BIO如果想要处理并发请求，则必须使用多线程，一般后端会用线程池来支持NIO可以使用单线程，可以减少线程切换上下文的消耗。但是虽然单线程减少了线程切换的消耗，但是处理也变为线性的，也就是处理完一个请求，才能处理第二个。这时，有这么两个场景： 后端是密集型的计算，没有大量的IO操作，比如读些文件、数据库等 后端是有大量的IO操作。 当为第一种场景时：NIO单线程则比较有优势， 理由是虽然是单线程，但是由于线程的计算是并发计算，不是并行计算，说到底，计算压力还是在CPU上，一个线程计算，没有线程的多余消耗，显然比NIO多线程要高效。BIO则必为多线程，否则将阻塞到天荒地老，但多线程是并发，不是并行，主要还是依靠CPU的线性计算，另外还有处理大量的线程上下文。如果为第二种场景，多线程将有一定优势，多个线程把等待IO的时间能平均开。此时两者区别主要取决于以上分析的处理顺序了，显然NIO要更胜一筹。 总结NIO在接收请求方式上，无疑是要高效于BIO，原因并非是不阻塞，我认为NIO一样是阻塞的，只是方式不同，先来的有效请求先处理，先阻塞时间短的。此时间可用于等待等待时间长的。在处理请求上，NIO和BIO并没有什么不同，主要看线程池规划是否和理。NIO相对BIO在密集型计算的模型下，可以用更少的线程，甚至单线程。 原文地址 Selector 实现原理 http://www.importnew.com/26258.html Java NIO Selector详解 https://blog.csdn.net/jeffleo/article/details/54695959 为什么NIO比BIO效率高 https://blog.csdn.net/wy0123/article/details/79382761]]></content>
      <categories>
        <category>code</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>nio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm]]></title>
    <url>%2Fblog%2Fcode%2Fjava%2Fjvm%2F</url>
    <content type="text"><![CDATA[jvm内存模型 Java内存区域只是概念 堆区: 存储的全部是对象，每个对象都包含一个与之对应的class的信息。(class的目的是得到操作指令) jvm只有一个堆区(heap)被所有线程共享，堆中不存放基本类型和对象引用，只存放对象本身 栈区: 每个线程包含一个栈区，栈中只保存基础数据类型的对象和自定义对象的引用(不是对象)，对象都存放在堆区中 每个栈中的数据(原始类型和对象引用)都是私有的，其他栈不能访问。 栈分为3个部分：基本类型变量区、执行环境上下文、操作指令区(存放操作指令)。 方法区: 又叫静态区，跟堆一样，被所有的线程共享。方法区包含所有的class和static变量。 方法区中包含的都是在整个程序中永远唯一的元素，如class，static变量。 Java内存模型 主内存 主要存储的是Java实例对象，所有线程创建的实例对象都存放在主内存中，不管该实例对象是成员变量还是方法中的本地变量(也称局部变量)，当然也包括了共享的类信息、常量、静态变量。由于是共享数据区域，多条线程对同一个变量进行访问可能会发现线程安全问题。 工作内存 主要存储当前方法的所有本地变量信息(工作内存中存储着主内存中的变量副本拷贝)，每个线程只能访问自己的工作内存，即线程中的本地变量对其它线程是不可见的，就算是两个线程执行的是同一段代码，它们也会各自在自己的工作内存中创建属于当前线程的本地变量，当然也包括了字节码行号指示器、相关Native方法的信息。注意由于工作内存是每个线程的私有数据，线程间无法相互访问工作内存，因此存储在工作内存的数据不存在线程安全问题。 倘若两个线程同时调用了同一个对象的同一个方法，那么两条线程会将要操作的数据拷贝一份到自己的工作内存中，执行完成操作后才刷新到主内存 硬件内存架构 Java线程与硬件处理器Java线程的实现是基于一对一的线程模型，所谓的一对一模型，实际上就是通过语言级别层面程序去间接调用系统内核的线程模型，即我们在使用Java线程时，Java虚拟机内部是转而调用当前操作系统的内核线程来完成当前任务 垃圾收集VisualVM截图 判断对象是否存活可达性分析算法对象到GC Roots没有引用链，则回收。 GC Roots包括： （1）Java虚拟机栈中引用的对象。 （2）方法区中类静态属性引用的对象。 （3）方法去中常量引用的对象。 （4）本地方法栈中Native方法（JNI）引用的对象。 关于引用 （1）强引用：Object obj = new Object()，不会被jvm回收 （2）软引用：在内存溢出异常发生之前才被强制回收。 1SoftReference&lt;String&gt; sr = new SoftReference&lt;String&gt;(new String("hello")); （3）弱引用：延迟到下次垃圾回收之前再被回收。 （4）虚引用：仅为了在被回收时收到一个系统通知。 垃圾收集算法标记-清除算法（Mark-Sweep） 效率问题：标记和清除两个过程的效率都不高。 空间问题：清除后剩余空间零散不连续，无法为大的对象分配内存。 复制算法将内存分为两个半区，将区A中的存活对象全部复制到B区的连续空间，然后清理A中所有空间。 缺点：内存实际空间减半。在对象存活率较高时需要进行较多的复制操作。 实际应用：将堆内存分为新生代和老年代。由于新生代中的对象98%都是可回收的，故将新生代又划分为Eden空间和两块较小的Survivor空间，默认Eden:Survivor（单个）=8:1 这样每次垃圾收集时，将Eden和S1中的存活对象复制到S2，然后清空Eden和S1区。 为了防止S2中空间不足以存储Eden和S1的所有剩余存活对象，提供老年代作为保障（Handle Promotion：分配担保）。 标记-整理算法将标记后的存活对象进行移动，清除剩余对象。 应用：老年代 分代收集 新生代：存活率低，使用复制算法 老年代：存活率高，使用“标记-整理”或“标记-清除”算法 垃圾收集器Parallel Scavenge收集器新生代、复制算法、多线程。 注重吞吐量，适合后台进程。 -XX:MacGCPauseMillis：最大垃圾收集停顿时间 -XX:GCTimeRatio：吞吐量大小 GCTimeRatio=99，意味着允许最大垃圾收集时间占比为1/(1+99)=1%，GCTimeRatio=用户代码运行时间/GC时间。 -XX:+UseAdaptiveSizePolicy：动态自适应调整JVM参数（-Xmn、SurvivorRatio等） Parallel Old收集器Parallel Scavenge的老年代版本 G1收集器最前沿成果。削弱新生代与老年代概念，将整个堆划分为独立的不同Region。根据各Region的回收价值，确定优先列表。 从整体来看：“标记-整理” 算法 从局部（两个Region之间）来看：“复制”算法 jvm默认垃圾收集器jdk1.7 默认垃圾收集器Parallel Scavenge（新生代）+Parallel Old（老年代） jdk1.8 默认垃圾收集器Parallel Scavenge（新生代）+Parallel Old（老年代） jdk1.9 默认垃圾收集器G1 -XX:+PrintCommandLineFlagsjvm参数可查看默认设置收集器类型 -XX:+PrintGCDetails亦可通过打印的GC日志的新生代、老年代名称判断 内存分配与回收策略优先在Eden区分配（如果启动本地线程分配缓冲TLAB-Thread Local Allocation Buffer，则优先在TLAB）如果Eden区满，则触发一次Minor GC(也称Young GC) -XX:+PrintGCDetails 在JVM发生垃圾收集时打印内存回收日志 在进程退出时输出当前各区域的内存分配情况 在JDK8中，PermGen（永久代）被Metaspace（元空间）取代了。 大对象直接进入老年代-XX:PretenureSizeThreshold：直接进入老年代的对象大小 长期存活的对象将进入老年代-XX:MaxTenuringThreshold：设置对象在新生代中能存活的最大年龄，默认15 -XX:+PrintTenuringDistribution：打印老年代内的各年龄对象内存分配情况 动态对象年龄判定若Survivor中相同年龄的所有对象大小总和超过Survivor的一半，则年龄大于或等于该年龄的对象就可以直接进入老年代。 空间分配担保 （1）YGC发生前先检查“老年代最大可用的连续空间”是否大于新生代所有对象总空间。如果是，则触发YGC,无风险；如果否，进入（2） （2）再次判断“老年代最大可用的连续空间”是否大于历次平均晋升到老年代的对象大小总和。如果否，则直接执行FullGC；如果是，进入（3） （3）执行YGC，有风险。 （4）如果3中的YGC失败，则再执行FullGC。]]></content>
      <categories>
        <category>code</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springMVC]]></title>
    <url>%2Fblog%2Fcode%2Fspring%2FMVC%2F</url>
    <content type="text"><![CDATA[springMVC发起一次请求到返回的流程 MVC1234567graph LR用户--发起请求--&gt;ControllerController--&gt;|传递参数|M(&quot;Model&lt;br&gt;(service,domain,dao)&quot;)M-.-&gt;|返回数据|ControllerController--渲染视图--&gt;ViewView-.-&gt;|生成返回内容|ControllerController-.-&gt;|返回|用户 springMVC12345678910111213graph LR用户--&gt;|1|DispatcherServletDispatcherServlet--&gt;|2|HandlerMappingHandlerMapping-.-&gt;|3|DispatcherServletDispatcherServlet--&gt;|4|HandlerAdapterHandlerAdapter--&gt;|5|HandlerHandler-.-&gt;|6|HandlerAdapterHandlerAdapter-.-&gt;|7|DispatcherServletDispatcherServlet--&gt;|8|ViewResolverViewResolver-.-&gt;|9|DispatcherServletDispatcherServlet--&gt;|10|ViewView-.-&gt;|11|DispatcherServletDispatcherServlet--&gt;|12|用户 序列图 12345678910111213用户-&gt;DispatcherServlet:Requestparticipant DispatcherServletDispatcherServlet-&gt;HandlerMapping: 查找HandlerHandlerMapping--&gt;DispatcherServlet:HandlerDispatcherServlet-&gt;HandlerAdapter:执行HandlerHandlerAdapter-&gt;Handler:调用Handler--&gt;HandlerAdapter:ModelAndViewHandlerAdapter--&gt;DispatcherServlet:ModelAndViewDispatcherServlet-&gt;ViewResolver:查找ViewViewResolver--&gt;DispatcherServlet:返回ViewDispatcherServlet-&gt;View:渲染视图View--DispatcherServlet:返回内容DispatcherServlet--&gt;用户:response DispatcherServletdoDispatch方法是所有请求的入口 HandlerInterceptor拦截器链 doDispatch里分别有3个调用对应了HandlerInterceptor里的三个方法 mappedHandler.applyPreHandle–&gt;preHandle mappedHandler.applyPostHandle–&gt;postHandle processDispatchResult–&gt;afterCompletion 1234567if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return;&#125;// Actually invoke the handler.mv = ha.handle(processedRequest, response, mappedHandler.getHandler());mappedHandler.applyPostHandle(processedRequest, response, mv);processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); HandlerMapping规定了url和handler的对应关系 HandlerAdapter相当于handler的代理类，由他调用handler，可以在调用前对参数做一些处理，也可以在调用后，将返回值按照特定的格式进行封装 Handler具体处理业务的类，大部分情况就是我们说的controller ViewResolver根据指定的规则通过名称找到视图对象 View最终的视图，系统处理后产生的model对象输出到Response里面 1234void render(@Nullable Map&lt;String, ?&gt; model, HttpServletRequest request, HttpServletResponse response) throws Exception;]]></content>
      <categories>
        <category>code</category>
        <category>spring</category>
      </categories>
      <tags>
        <tag>springMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[URI和URL]]></title>
    <url>%2Fblog%2Fweb%2FURI%E5%92%8CURL%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[URI和URL区别 Uniform Resource Identifier ：统一资源标识符 Uniform Resource Location ：统一资源定位符 ftp://ftp.is.co.za/rfc/rfc1808.txt (also a URL because of the protocol) http://www.ietf.org/rfc/rfc2396.txt (also a URL because of the protocol) ldap://[2001:db8::7]/c=GB?objectClass?one (also a URL because of the protocol) mailto:John.Doe@example.com (also a URL because of the protocol) news:comp.infosystems.www.servers.unix (also a URL because of the protocol) tel:+1-816-555-1212 telnet://192.0.2.16:80/ (also a URL because of the protocol) urn:oasis:names:specification:docbook:dtd:xml:4.1.2 这些全都是URI, 其中有些事URL. 哪些? 就是那些提供了访问机制的.]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>url</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown画图]]></title>
    <url>%2Fblog%2Fcode%2Fmarkdown%2Fmarkdown%E7%94%BB%E5%9B%BE%E6%A8%A1%E6%9D%BF%2F</url>
    <content type="text"><![CDATA[typora画图示例 流程图flow 1234567891011121314st=&gt;start: 开始|past:&gt;https://xixhaha.gitee.io/blog/[blank]e=&gt;end: 结束op1=&gt;operation: 操作1op2=&gt;operation: 操作2sub1=&gt;subroutine: 子流程cond=&gt;condition: 判断1c2=&gt;condition: 判断2io=&gt;inputoutput: 输入输出st-&gt;op1(right)-&gt;condcond(yes, right)-&gt;c2cond(no)-&gt;sub1(left)-&gt;op1c2(yes)-&gt;io-&gt;ec2(no)-&gt;op2-&gt;e 序列图sequence 123A-&gt;B: 请求?Note right of B: 备注B--&gt;A: 响应 mermaid方向graph tb TB（ top bottom）表示从上到下 BT（bottom top）表示从下到上 RL（right left）表示从右到左 LR（left right）表示从左到右 节点有以下几种节点和形状： 默认节点 A 文本节点 B[bname] 圆角节点 C(cname) 圆形节点 D((dname)) 非对称节点 E&gt;ename] 菱形节点 F{fname} 1234567graph TDab[文本]c(圆角)d((圆))e&gt;不规则]f&#123;菱形&#125; 连线节点间的连接线有多种形状，而且可以在连接线中加入标签： 箭头连接 A–&gt;B1 开放连接 A—B2 标签连接 A3–&gt;|text|B3 虚线-.- 粗线== 123456graph TBA--&gt;B1A---B2A3--&gt;|text|B3A1===B4A1==&gt;B5 st=>start: 开始|past:>https://xixhaha.gitee.io/blog/[blank] e=>end: 结束 op1=>operation: 操作1 op2=>operation: 操作2 sub1=>subroutine: 子流程 cond=>condition: 判断1 c2=>condition: 判断2 io=>inputoutput: 输入输出 st->op1(right)->cond cond(yes, right)->c2 cond(no)->sub1(left)->op1 c2(yes)->io->e c2(no)->op2->e{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);]]></content>
      <categories>
        <category>code</category>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lazydoc使用手册]]></title>
    <url>%2Fblog%2Fmanual%2Fmanual%2Flazydoc%2F</url>
    <content type="text"><![CDATA[lazydoc，一个简单的接口文档生成器。 功能，自动生成接口文档，并为每个接口提供一个测试页面。 实现原理，扫描所有带有@controller注解的类，解析带有@RequestMapping的方法，根据方法签名和自定义标签生成文档 最终生成的效果：点这里 网站只是静态页面，所以大部分按钮是无效的 下面就以一个简单的spring-boot工程说一下怎么使用 运行环境暂时用到的依赖包 jdk：1.8 spring-boot-starter-web：2.0.3.RELEASE velocity：1.7 lombok：1.16.22 目前版本算是初稿，因为用到了一些jdk的新功能，所以jdk1.8是必须。 spring-boot只用到了它的Annotation和AnnotationUtils，所以版本没啥要求，引入时scope我用的是provided lombok版本是随spring-boot走的 velocity，生成页面的，用习惯了，后续可能会换 创建工程pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;hello&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;demo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 启动类123456789101112131415package com.example.demo;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import wang.wangby.lazydoc.controller.LazyDocController;@SpringBootApplicationpublic class HelloApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(HelloApplication.class, args); &#125;&#125; 一个简单的Controller123456789101112131415package com.example.demo;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;@Controllerpublic class HelloController &#123; @RequestMapping("/hello") @ResponseBody public String hello() &#123; return "hello world"; &#125;&#125; 运行http://127.0.0.1:8080/hello hello world引入jar包12345&lt;dependency&gt; &lt;groupId&gt;wang.wangby&lt;/groupId&gt; &lt;artifactId&gt;lazydoc&lt;/artifactId&gt; &lt;version&gt;0.1&lt;/version&gt;&lt;/dependency&gt; 重启这时候会看到启动日志里面多了三个地址 123RequestMappingHandlerMapping - Mapped &quot;&#123;[/lazydoc/index]&#125;RequestMappingHandlerMapping - Mapped &quot;&#123;[/lazydoc/detail/&#123;index&#125;],methods=[GET]&#125;&quot;RequestMappingHandlerMapping - Mapped &quot;&#123;[/lazydoc/treeView],methods=[GET || POST],produces=[application/json;charset=UTF-8]&#125; 访问打开这个页面，就可以看到生成的文档了：http://127.0.0.1:8080/lazydoc/index 点击测试，可以看到返回内容和网页上的一样 0配置上面的hello方法，没有参数，返回值也是简单的字符串，所以看不出什么。为了演示，我这里简单的模拟了一个查询的场景。 客户端传过来一些查询条件和分页信息，服务端返回封装好的一页查询结果。 model类12345678910111213141516//图书信息@Datapublic class BookInfo &#123; //主键 private Long bookId; //书名 private String bookName; //出版日期 private Date publication; //标准图书编号 private String isbn; //创建时间 private Date createTime; //售价 private Integer price;&#125; 封装查询条件的对象12345678910//图书查询条件@Datapublic class BookSelector &#123; //图书信息 private BookInfo bookInfo; //最低价格 private Integer minPrice; //最高价 private Integer maxPrice;&#125; 封装返回结果的对象1234567891011@Datapublic class Page&lt;T&gt; &#123; //返回的记录集 private List&lt;T&gt; result; //总条数 private Integer total; //查询起始位置 Integer offset; //返回条数 Integer limit;&#125; Controller这里模拟返回10条 1234567891011121314151617181920212223242526272829303132@Controller@RequestMapping("/book")//图书管理public class BookController &#123; /** * 查询图书信息 * @param selector 查询条件 * @param offset 查询 * @param limit 返回条数 * @return 查询到的结果集 * */ @RequestMapping("/select") @ResponseBody public Page&lt;BookInfo&gt; select(BookSelector selector, Integer offset, Integer limit) &#123; Page page = new Page(); List list=new ArrayList(); for(int i=0;i&lt;10;i++) &#123; BookInfo inf=new BookInfo(); inf.setCreateTime(new Date()); inf.setBookId(i+0L); inf.setBookName("bookName:"+i); inf.setIsbn("isbn"+i); list.add(inf); &#125; page.setResult(list); page.setOffset(0); page.setLimit(10); page.setTotal(1000); return page; &#125;&#125; 启动并访问在没有任何配置的情况下，文档也生成了，查看网页版：点这里 完善文档可以看到，按正常方式写代码，没有做任何配置的情况下，接口文档已经生成了。 下面来看看如何完善文档，其实完善就是把说明字段写清楚就好了，lazydoc的所有配置信息均采用注解方式 参数和返回值对象只需要将普通的备注换成@remark便签即可，像这样 12345678910111213141516@Remark("图书信息")@Datapublic class BookInfo &#123; @Remark("主键") private Long bookId; @Remark("书名") private String bookName; @Remark("出版日期") private Date publication; @Remark("标准图书编号") private String isbn; @Remark("创建时间") private Date createTime; @Remark("售价") private Integer price;&#125; controller方法将原来的注释换个形式 12345678910111213141516171819202122232425@Remark("查询图书信息")@Param("查询条件")@Param("查询起始位置偏移量")@Param("返回条数")@Return("查询结果")@RequestMapping("/select")@ResponseBodypublic Page&lt;BookInfo&gt; select(BookSelector selector, Integer offset, Integer limit) &#123; Page page = new Page(); List list = new ArrayList(); for (int i = 0; i &lt; 10; i++) &#123; BookInfo inf = new BookInfo(); inf.setCreateTime(new Date()); inf.setBookId(i + 0L); inf.setBookName("bookName:" + i); inf.setIsbn("isbn" + i); inf.setPrice(i * 100 + i); list.add(inf); &#125; page.setResult(list); page.setOffset(0); page.setLimit(10); page.setTotal(1000); return page;&#125; 可以看到，相比于原来的，代码量并没有增多 再次启动可以看到备注信息已经显示在页面了，网页版：点这里 接口测试设置日期格式为了处理日期，需要给spring添加一个Converter 1234567891011121314151617181920212223242526272829@Componentpublic class StringToDateConverter implements Converter&lt;String, Date&gt; &#123; private static final String dateFormat = "yyyy-MM-dd HH:mm:ss"; private static final String shortDateFormat = "yyyy-MM-dd"; @Override public Date convert(String value) &#123; if (StringUtils.isEmpty(value)) &#123; return null; &#125; value = value.trim(); try &#123; return convertInternal(value); &#125; catch (Exception ex) &#123; throw new RuntimeException("将字符串转为日期失败:" + value + "," + ex.getMessage()); &#125; &#125; private Date convertInternal(String value) throws ParseException &#123; if (value.matches("^\\d+$")) &#123; return new Date(Long.parseLong(value)); &#125; if (value.contains(":")) &#123; return new SimpleDateFormat(dateFormat).parse(value); &#125; else &#123; return new SimpleDateFormat(shortDateFormat).parse(value); &#125; &#125;&#125; 修改application.properties 12spring.jackson.date-format=yyyy-MM-dd HH:mm:ssspring.jackson.time-zone=GMT+8 测试接收参数将select方法稍微改下，将接受到的参数原封传回页面 123456789101112Page page = new Page();List list = new ArrayList();for (int i = 0; i &lt; limit; i++) &#123; BookInfo inf = selector.getBookInfo(); inf.setPrice(selector.getMaxPrice()); list.add(inf);&#125;page.setResult(list);page.setOffset(offset);page.setLimit(limit);page.setTotal(1000);return page; 启动并访问网页版：点这里 参数配置忽略参数有事为了省事，把model对象直接放到查询对象里了，但有些查询条件是没用的，可以设置ignores，这样页面就不会显示了 1@Param(value="查询条件",ignores= &#123;"bookInfo.bookId","bookInfo.createTime","bookInfo.price","bookInfo.publication"&#125;) 参数校验默认配置根据数据对应的java类型，默认已经有参数校验了，比如日期和数字。 date类型默认是按YYYY-MM-DD hh:mm:ss校验的，如果只有日期没有时间，在字段上做一些配置 @Property注解，dateOnly参数判断是时间还是日期 12@Property(value="出版日期",dateOnly=true)private Date publication; 非空notNull属性设置为true，提交时就会自动校验了 1@Param(value="查询起始位置偏移量",notNull=true) 最终效果：点这里 json形式的参数微服务下，接口的参数通常是通过json的方式传递，如果在方法上加了@RequestBody 注解 123456789101112131415161718192021@Remark("通过json查询图书")@Param(value="查询条件")@Param(value="查询起始位置偏移量")@Param(value="返回条数")@Return("查询结果")@RequestMapping("/selectJs")@ResponseBodypublic Page&lt;BookInfo&gt; selectJs(@RequestBody BookSelector selector) &#123; Page page = new Page(); List list = new ArrayList(); for (int i = 0; i &lt; selector.getLimit(); i++) &#123; BookInfo inf = selector.getBookInfo(); inf.setPrice(selector.getMaxPrice()); list.add(inf); &#125; page.setResult(list); page.setOffset(selector.getOffset()); page.setLimit(selector.getLimit()); page.setTotal(1000); return page;&#125; 那么测试页面就会自动变为json方式输入了，同时会把需要的字段自动设置为null，例如这样 json格式的数据目前还无法做到参数校验，同时只要有1个参数上标注了RequestBody ，页面就会使用json形式 mock通常的开发流程是，各部门之间定好接口，然后各自独立开发。当各方进度不一样的时候，为了方便别人测试，需要对方提供一个可供测试的接口。 我的实现方式是，将模拟的返回数据存在缓存中，请求时通过一个唯一标识来获取模拟数据。 暂时做法是将数据放在redis里，为了实现mock功能需要做以下配置 引入新的jar包api-cache：用于将请求内容放入缓存，项目地址https://gitee.com/xixhaha/apicache spring-boot-starter-aop：通过AOP判断哪些方法需要做mock spring-boot-starter-data-redis：数据存在redis 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;wang.wangby&lt;/groupId&gt; &lt;artifactId&gt;api-cache&lt;/artifactId&gt; &lt;version&gt;0.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 修改Controller方法注解这里采用annotation的方式，新增了一个注解Api，这个方内部同时引用了ResponseBody，RequestMapping，Remark 123456@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@ResponseBody@RequestMapping@Remarkpublic @interface Api &#123;... 所以可以把三个注解去掉，换成下面这样 1234567891011121314151617181920@Param(value="查询条件",ignores= &#123;"bookInfo.createTime","bookInfo.price","bookInfo.publication","bookInfo.isbn", "minPrice","maxPrice"&#125;)@Return("查询结果")@Api(name="查询图书信息",path="/select")public Page&lt;BookInfo&gt; select(BookSelector selector) &#123; Page page = new Page(); List list = new ArrayList(); for (int i = 0; i &lt; selector.getLimit(); i++) &#123; BookInfo b=new BookInfo(); b.setBookId(i+0L); b.setBookName(selector.getBookInfo().getBookName()+i); b.setCreateTime(new Date()); list.add(b); &#125; page.setResult(list); page.setOffset(selector.getOffset()); page.setLimit(selector.getLimit()); page.setTotal(1000); return page;&#125; 配置AOP接口调用的时候会出现一些异常，同时当多台服务器做集群的时候，由于网络异常需要重试，有可能出现重复请求的情况，出现这些情况如何处理，专门设置了一个类 12345678910111213141516171819202122232425/** 设置mock异常处理规则 */public interface ApiMock &#123; /** * 当其他服务器正在执行方法的时候,接口调用的返回值 * @param method 请求的方法 * */ public Object getRunningResult(Method method); /** * 当调用方法出现异常后,接口的返回值 * * @param method 请求的方法 * @param ex 异常信息 */ public Object getExceptionResult(Method method, Exception ex); /** * 获得请求的唯一标识 * * @param method 请求方法 * @param args 方法参数 */ public String getRequestId(Method method, Object[] args);&#125; 客户端设置拦截规则的同时，需要实现以上接口，最终的配置类如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Configuration@Slf4jpublic class MockConfig &#123; @Bean public MockMethod apiMethods(CacheServer cacheServer) &#123; MockMethod method=new MockMethod(); method.setCacheServer(cacheServer); return method; &#125; @Aspect public class MockMethod implements ApiMock&#123; CacheServer cacheServer; public void setCacheServer(CacheServer cacheServer) &#123; this.cacheServer=cacheServer; &#125; //只处理有Api注解的方法，同时返回值必须是Page @Pointcut("@annotation(wang.wangby.annotation.Api) &amp;&amp; execution(com.example.demo.book.model.Page *.*(..))") private void apiMethod() &#123; &#125; @Around("apiMethod()") public Object process(ProceedingJoinPoint pjp) throws Throwable &#123; return new ApiIntercept(pjp,cacheServer).process(this); &#125; @Override public Object getRunningResult(Method method) &#123; throw new RuntimeException("重复请求"); &#125; //如果请求出现异常,打印异常,并造一个假的Page @Override public Object getExceptionResult(Method method, Exception ex) &#123; log.error(ex.getMessage(),ex); Page&lt;BookInfo&gt; page=new Page(); BookInfo bk=new BookInfo(); bk.setBookName("查询出错:"+ex.getMessage()); List list=new ArrayList(); list.add(bk); page.setResult(list); return page; &#125; //通过bookId做为标识 @Override public String getRequestId(Method method, Object[] args) &#123; BookSelector sel=(BookSelector) args[0]; String requestId=sel.getBookInfo().getBookId()+""; log.debug("收到请求:"+requestId); return requestId; &#125; &#125;&#125; 配置redis修改application.yaml 12345spring: redis: database: 0 host: 127.0.0.1 port: 6379 启动程序bookId设置为123456 查询一次以后，只要参数里的bookId是123456，其它条件无论写什么返回的都是相同内容，同时redis里面多了一些数据，箭头标注的地方就是请求的唯一标识了，同时可以任意修改里面的内容，这样就可以造出不同的mock数据]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>lazydoc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot初探]]></title>
    <url>%2Fblog%2Fcode%2Fspringboot%2Fspringboot%2F</url>
    <content type="text"><![CDATA[草稿 一 准备1. 环境java version 1.8 spring boot Version 2.0.3 2. 官方文档http://spring.io/projects/spring-boot https://docs.spring.io/spring-boot/docs/2.0.3.RELEASE/reference/htmlsingle/ 3. 项目生成器https://start.spring.io/ 二 spring boot helloworld1. 创建1.1 生成pom文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;top.luckie&lt;/groupId&gt; &lt;artifactId&gt;mservice&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;demo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 1.2 启动类Application.java 1234567@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 1.3 controller12345678910111213import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;@Controllerpublic class HelloController &#123; @RequestMapping("/") @ResponseBody public String hello() &#123; return "hello world"; &#125;&#125; ##2.运行 1) 执行启动类的main方法 2) 在浏览器输入地址:http://127.0.0.1:8080/ 日志配置https://logback.qos.ch/manual/layouts.html 格式说明如下： %m 输出代码中指定的消息 %p 输出优先级，即DEBUG，INFO，WARN，ERROR，FATAL %r 输出自应用启动到输出该log信息耗费的毫秒数 %c 输出所属的类目，通常就是所在类的全名 %t 输出产生该日志事件的线程名 %n 输出一个回车换行符，Windows平台为“\r\n”，Unix平台为“\n” %d 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d{yyy MMM dd HH:mm:ss,SSS}，输出类似：2002年10月18日 22：10：28，921 %l 输出日志事件的发生位置，包括类目名、发生的线程，以及在代码中的行数。举例：Testlog4.main(TestLog4.java:10) logger参数 Format modifier Logger name Result [%20.20logger] main.Name [ main.Name] [%-20.20logger] main.Name [main.Name ] [%10.10logger] main.foo.foo.bar.Name [o.bar.Name] [%10.-10logger] main.foo.foo.bar.Name [main.foo.f] 示例 1234567891011logging.level.top.luckie=debug#格式logging.pattern.console=%d&#123;HH:mm:ss.SSS&#125; %logger&#123;10&#125; - %msg#logging.pattern.file==%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg#目录和地址二选一#指定目录#logging.pth=/opt/log/demo#指定文件#logging.file=/opt/log/demo.log 三.spring boot mvc1.配置1. 自动配置处理类1org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration 2. 自定义配置1) 说明f you want to keep Spring Boot MVC features and you want to add additional MVC configuration (interceptors, formatters, view controllers, and other features), you can add your own @Configuration class of type WebMvcConfigurer but without @EnableWebMvc. If you wish to provide custom instances ofRequestMappingHandlerMapping, RequestMappingHandlerAdapter, or ExceptionHandlerExceptionResolver, you can declare aWebMvcRegistrationsAdapter instance to provide such components. If you want to take complete control of Spring MVC, you can add your own @Configuration annotated with @EnableWebMvc. 2) 编写配置类1) 编写配置类覆盖WebMvcConfigurer里的方法 1234@Configurationpublic class MyMvcConfig implements WebMvcConfigurer &#123; ...&#125; 3) 全局映射1234public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController("/").setViewName("login"); registry.addViewController("/index.html").setViewName("login");&#125; 4) 拦截器123456public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new LogInterceptor()).addPathPatterns("/**") .excludePathPatterns("/webjars/**"); registry.addInterceptor(new PermissionInterceptor()).addPathPatterns("/**") .excludePathPatterns("/webjars/**","/","/login","/index.html","/logout");&#125; 5) 异常处理系统规则1org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration ErrorPageCustomizer:将所有错误请求转发到/error 123public class ErrorProperties &#123; @Value("$&#123;error.path:/error&#125;") private String path = "/error"; BasicErrorController: 处理/error 根据html和json返回不同内容 123456789101112131415161718192021222324@Controller@RequestMapping("$&#123;server.error.path:$&#123;error.path:/error&#125;&#125;")public class BasicErrorController extends AbstractErrorController &#123; @RequestMapping(produces = "text/html") public ModelAndView errorHtml(HttpServletRequest request, HttpServletResponse response) &#123; HttpStatus status = getStatus(request); Map&lt;String, Object&gt; model = Collections.unmodifiableMap(getErrorAttributes( request, isIncludeStackTrace(request, MediaType.TEXT_HTML))); response.setStatus(status.value()); //去向 ModelAndView modelAndView = resolveErrorView(request, response, status, model); return (modelAndView != null ? modelAndView : new ModelAndView("error", model)); &#125; @RequestMapping @ResponseBody public ResponseEntity&lt;Map&lt;String, Object&gt;&gt; error(HttpServletRequest request) &#123; Map&lt;String, Object&gt; body = getErrorAttributes(request, isIncludeStackTrace(request, MediaType.ALL)); HttpStatus status = getStatus(request); return new ResponseEntity&lt;&gt;(body, status); &#125; 12 DefaultErrorViewResolver:决定最终返回的错误页面 123456789101112private ModelAndView resolve(String viewName, Map&lt;String, Object&gt; model) &#123; //默认返回 error/状态码 String errorViewName = "error/" + viewName; //如果有模板直接返回对应的模板视图,否则返回静态资源("error/状态码.html) TemplateAvailabilityProvider provider = this.templateAvailabilityProviders .getProvider(errorViewName, this.applicationContext); if (provider != null) &#123; return new ModelAndView(errorViewName, model); &#125; return resolveResource(errorViewName, model);&#125; DefaultErrorAttributes:存放异常信息 123456789101112131415import org.springframework.boot.web.servlet.error.DefaultErrorAttributes;@Override public Map&lt;String, Object&gt; getErrorAttributes(ServerRequest request, boolean includeStackTrace) &#123; Map&lt;String, Object&gt; errorAttributes = new LinkedHashMap&lt;&gt;(); errorAttributes.put("timestamp", new Date()); errorAttributes.put("path", request.path()); Throwable error = getError(request); HttpStatus errorStatus = determineHttpStatus(error); errorAttributes.put("status", errorStatus.value()); errorAttributes.put("error", errorStatus.getReasonPhrase()); errorAttributes.put("message", determineMessage(error)); handleException(errorAttributes, determineException(error), includeStackTrace); return errorAttributes; &#125; 根据规则添加页面/template/404.html,4xx.html,5xx.html 123456status:[[$&#123;status&#125;]]&lt;br/&gt;timestamp:[[$&#123;timestamp&#125;]]&lt;br/&gt;error:[[$&#123;error&#125;]]&lt;br/&gt;message:[[$&#123;message&#125;]]&lt;br/&gt;status:[[$&#123;status&#125;]]&lt;br/&gt;path:[[$&#123;path&#125;]]&lt;br/&gt; 自定义异常返回内容通过继承DefaultErrorAttributes创建自己的ErrorAttributes,重写getErrorAttributes方法 123456789101112@Componentpublic class MyErrorAttributes extends DefaultErrorAttributes&#123; @Override public Map&lt;String, Object&gt; getErrorAttributes(WebRequest webRequest, boolean includeStackTrace) &#123; Map&lt;String, Object&gt; errorAttributes = super.getErrorAttributes(webRequest, true); errorAttributes.put("custom", "自定义信息"); return errorAttributes; &#125;&#125; 2 静态文件映射规则https://www.webjars.org/ 1) webjars/webjars/–&gt;classPath:/META-INF/resources/webjars/ 12345&lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;bootstrap&lt;/artifactId&gt; &lt;version&gt;4.1.1&lt;/version&gt;&lt;/dependency&gt; bootstrap文件访问地址如下: http://127.0.0.1:8080/webjars/bootstrap/4.1.1/js/bootstrap.min.js 2)静态文件12345"classpath:/META-INF/resources/", "classpath:/resources/","classpath:/static/", "classpath:/public/""/" 3 模板引擎(Thymeleaf)1) pom1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; 2) 默认规则自动配置类 1org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration 映射规则xxx–&gt;classpath:/templates/xxx.html 12345678@ConfigurationProperties(prefix = "spring.thymeleaf")public class ThymeleafProperties &#123; private static final Charset DEFAULT_ENCODING = StandardCharsets.UTF_8; public static final String DEFAULT_PREFIX = "classpath:/templates/"; public static final String DEFAULT_SUFFIX = ".html"; 四. spring boot 访问数据库1. 数据源1) pom.xml1234567891011&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.8&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;4.2.5.RELEASE&lt;/version&gt;&lt;/dependency&gt; 2) 参数 配置 缺省值 说明 name 配置这个属性的意义在于，如果存在多个数据源，监控的时候可以通过名字来区分开来。 如果没有配置，将会生成一个名字，格式是：”DataSource-“ + System.identityHashCode(this) jdbcUrl 连接数据库的url，不同数据库不一样。例如： mysql : jdbc:mysql://10.20.153.104:3306/druid2 oracle : jdbc:oracle:thin:@10.20.149.85:1521:ocnauto username 连接数据库的用户名 password 连接数据库的密码。如果你不希望密码直接写在配置文件中，可以使用ConfigFilter。详细看这里：https://github.com/alibaba/druid/wiki/%E4%BD%BF%E7%94%A8ConfigFilter driverClassName 根据url自动识别 这一项可配可不配，如果不配置druid会根据url自动识别dbType，然后选择相应的driverClassName(建议配置下) initialSize 0 初始化时建立物理连接的个数。初始化发生在显示调用init方法，或者第一次getConnection时 maxActive 8 最大连接池数量 maxIdle 8 已经不再使用，配置了也没效果 minIdle 最小连接池数量 maxWait 获取连接时最大等待时间，单位毫秒。配置了maxWait之后，缺省启用公平锁，并发效率会有所下降，如果需要可以通过配置useUnfairLock属性为true使用非公平锁。 poolPreparedStatements false 是否缓存preparedStatement，也就是PSCache。PSCache对支持游标的数据库性能提升巨大，比如说oracle。在mysql下建议关闭。 maxOpenPreparedStatements -1 要启用PSCache，必须配置大于0，当大于0时，poolPreparedStatements自动触发修改为true。在Druid中，不会存在Oracle下PSCache占用内存过多的问题，可以把这个数值配置大一些，比如说100 validationQuery 用来检测连接是否有效的sql，要求是一个查询语句。如果validationQuery为null，testOnBorrow、testOnReturn、testWhileIdle都不会其作用。 testOnBorrow true 申请连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能。 testOnReturn false 归还连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能 testWhileIdle false 建议配置为true，不影响性能，并且保证安全性。申请连接的时候检测，如果空闲时间大于timeBetweenEvictionRunsMillis，执行validationQuery检测连接是否有效。 timeBetweenEvictionRunsMillis 有两个含义： 1) Destroy线程会检测连接的间隔时间2) testWhileIdle的判断依据，详细看testWhileIdle属性的说明 numTestsPerEvictionRun 不再使用，一个DruidDataSource只支持一个EvictionRun minEvictableIdleTimeMillis connectionInitSqls 物理连接初始化的时候执行的sql exceptionSorter 根据dbType自动识别 当数据库抛出一些不可恢复的异常时，抛弃连接 filters 属性类型是字符串，通过别名的方式配置扩展插件，常用的插件有： 监控统计用的filter:stat日志用的filter:log4j防御sql注入的filter:wall proxyFilters 类型是List&lt;com.alibaba.druid.filter.Filter&gt;，如果同时配置了filters和proxyFilters，是组合关系，并非替换关系 123456spring.datasource.username=rootspring.datasource.password=123456spring.datasource.url=jdbc:mysql://127.0.0.1:3306/jdbcspring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.datasource.type=com.alibaba.druid.pool.DruidDataSourcespring.datasource.filters=stat,log4j,wall 配置数据源监控 1234567891011121314151617181920212223242526272829303132@Configurationpublic class DruidConfig &#123; @ConfigurationProperties(prefix="spring.datasource") @Bean public DataSource druid() &#123; return new DruidDataSource(); &#125; //管理后台的servlet @Bean public ServletRegistrationBean&lt;StatViewServlet&gt; staViewServlet()&#123; ServletRegistrationBean&lt;StatViewServlet&gt; bean= new ServletRegistrationBean&lt;&gt;(new StatViewServlet(),"/druid/*"); Map&lt;String,String&gt; map=new HashMap&lt;&gt;(); map.put(ResourceServlet.PARAM_NAME_USERNAME,"root"); map.put(ResourceServlet.PARAM_NAME_PASSWORD,"123456"); map.put(ResourceServlet.PARAM_NAME_ALLOW, "");//默认允许所有 bean.setInitParameters(map); return bean; &#125; //监控的filter @Bean public FilterRegistrationBean&lt;WebStatFilter&gt; webStaFilter() &#123; FilterRegistrationBean&lt;WebStatFilter&gt; bean=new FilterRegistrationBean&lt;&gt;(); bean.setFilter(new WebStatFilter()); Map&lt;String,String&gt; map=new HashMap&lt;&gt;(); map.put(WebStatFilter.PARAM_NAME_EXCLUSIONS, "*.js,*.css,/druid/*"); bean.setInitParameters(map); bean.setUrlPatterns(Arrays.asList("/*")); return bean; &#125;&#125; 五 spring boot mybatis六 spring boot 启动流程1.启动流程1).创建SpringApplication对象​ 获取ApplicationContextInitializer和ApplicationListener 所有jar包特定路径(META-INF/spring.factories)下的ApplicationContextInitializer 123456789101112public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, "PrimarySources must not be null"); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); this.webApplicationType = deduceWebApplicationType(); //在类路径下找到META-INF/spring.factories配置的所有ApplicationContextInitializer setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); //同样文件下再找ApplicationListener setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass();&#125; 2)运行程序12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); //获取监听器 SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); Banner printedBanner = printBanner(environment); //创建IOC容器 context = createApplicationContext(); exceptionReporters = getSpringFactoriesInstances( SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); //准备 //执行所有ApplicationContextInitializer的Initial方法 //执行ApplicationListener的prepare方法 prepareContext(context, environment, listeners, applicationArguments, printedBanner); // //扫描,创建,加载所有组件 refreshContext(context); afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; listeners.started(context); callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); &#125; try &#123; listeners.running(context); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); &#125; return context;&#125; 3)事件监听 配置在META-INF/spring.factories ApplicationContextInitializer SpringApplicationRunListener IOC容器内的 ApplicationRunner CommandLineRunner 七 自定义startersstarter:启动器 1) 是一个空的jar文件 2) 只用来做依赖导入配置和autoconfigure 3) 官方叫 spring-boot-starter-模块名,自己编写的为:xxx-spring-boot-starter 12graph LRa[xxx-starter]--&gt;|引入|b[xxx-spring-boot-autoconfigure] 编写xxxAutoConfiguration 123456789101112@Configuration //设置为配置类@ConditionalOnxxx //配置生效条件@AutoConfigureAfter //规定配置顺序public class WebMvcAutoConfiguration &#123;...&#125;//具体方法@Bean //给容器添加Bean@EnableConfigurationProperties(&#123; WebMvcProperties.class&#125;)//需要配置参数就创建一个ConfigurationProperties@ConfigurationProperties(prefix = "spring.mvc")public class WebMvcProperties &#123;...&#125;自动类要生效,需要放在 META-INF/spring.factories下 八 缓存 1234567891011graph TBApplication--&gt;a(&quot;CacheProvider&quot;)Application--&gt;b(&quot;CacheProvider&quot;)a--&gt;c(&quot;CacheManager(Ehcache)&quot;)a--&gt;d(&quot;CacheManager(Redis)&quot;)c--&gt;e(&quot;Cache(员工)&quot;)c--&gt;f(&quot;Cache(商品)&quot;)c--&gt;g(&quot;Cache(...)&quot;)e--&gt;h(&quot;Entry&lt;K,V&gt;&quot;)f--&gt;i(&quot;Entry&lt;K,V&gt;&quot;)g--&gt;j(&quot;Entry&lt;K,V&gt;&quot;)]]></content>
      <categories>
        <category>code</category>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程]]></title>
    <url>%2Fblog%2Fcode%2Fjava%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[多线程个人理解 多线程原子性这一点，跟数据库事务的原子性概念差不多，即一个操作（有可能包含有多个子操作）要么全部执行（生效），要么全部都不执行（都不生效）。 CAS（compare and swap）CAS是CPU指令 基础类型变量自增（i++）是一种常被新手误以为是原子操作而实际不是的操作。Java中提供了对应的原子操作类来实现该操作，并保证原子性，其本质是利用了CPU级别的CAS指令。由于是CPU级别的指令，其开销比需要操作系统参与的锁的开销小。 可见性可见性是指，当多个线程并发访问共享变量时，一个线程对共享变量的修改，其它线程能够立即看到。可见性问题是好多人忽略或者理解错误的一点。 CPU从主内存中读数据的效率相对来说不高，现在主流的计算机中，都有几级缓存。每个线程读取共享变量时，都会将该变量加载进其对应CPU的高速缓存里，修改该变量后，CPU会立即更新该缓存，但并不一定会立即将其写回主内存（实际上写回主内存的时间不可预期）。此时其它线程（尤其是不在同一个CPU上执行的线程）访问该变量时，从主内存中读到的就是旧的数据，而非第一个线程更新后的数据。 这一点是操作系统或者说是硬件层面的机制，所以很多应用开发人员经常会忽略。 顺序性顺序性指的是，程序执行的顺序按照代码的先后顺序执行 happens-before倘若在程序开发中，仅靠sychronized和volatile关键字来保证原子性、可见性以及有序性，那么编写并发程序可能会显得十分麻烦，幸运的是，在Java内存模型中，还提供了happens-before 原则来辅助保证程序执行的原子性、可见性以及有序性的问题，它是判断数据是否存在竞争、线程是否安全的依据，happens-before 原则内容如下 程序顺序原则，即在一个线程内必须保证语义串行性，也就是说按照代码顺序执行。 锁规则 解锁(unlock)操作必然发生在后续的同一个锁的加锁(lock)之前，也就是说，如果对于一个锁解锁后，再加锁，那么加锁的动作必须在解锁动作之后(同一个锁)。 volatile规则 volatile变量的写，先发生于读，这保证了volatile变量的可见性，简单的理解就是，volatile变量在每次被线程访问时，都强迫从主内存中读该变量的值，而当该变量发生变化时，又会强迫将最新的值刷新到主内存，任何时刻，不同的线程总是能够看到该变量的最新值。 线程启动规则 线程的start()方法先于它的每一个动作，即如果线程A在执行线程B的start方法之前修改了共享变量的值，那么当线程B执行start方法时，线程A对共享变量的修改对线程B可见 传递性 A先于B ，B先于C 那么A必然先于C 线程终止规则 线程的所有操作先于线程的终结，Thread.join()方法的作用是等待当前执行的线程终止。假设在线程B终止之前，修改了共享变量，线程A从线程B的join方法成功返回后，线程B对共享变量的修改将对线程A可见。 线程中断规则 对线程 interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted()方法检测线程是否中断。 对象终结规则 对象的构造函数执行，结束先于finalize()方法 volatile关键字及其作用1 保证内存可见性1.1 基本概念 可见性是指线程之间的可见性，一个线程修改的状态对另一个线程是可见的。也就是一个线程修改的结果，另一个线程马上就能看到。 1.2 实现原理 当对非volatile变量进行读写的时候，每个线程先从主内存拷贝变量到CPU缓存中，如果计算机有多个CPU，每个线程可能在不同的CPU上被处理，这意味着每个线程可以拷贝到不同的CPU cache中。 volatile变量不会被缓存在寄存器或者对其他处理器不可见的地方，保证了每次读写变量都从主内存中读，跳过CPU cache这一步。当一个线程修改了这个变量的值，新值对于其他线程是立即得知的。 2 禁止指令重排2.1 基本概念 指令重排序是JVM为了优化指令、提高程序运行效率，在不影响单线程程序执行结果的前提下，尽可能地提高并行度。指令重排序包括编译器重排序和运行时重排序。 在JDK1.5之后，可以使用volatile变量禁止指令重排序。针对volatile修饰的变量，在读写操作指令前后会插入内存屏障，指令重排序时不能把后面的指令重排序到内存屏 1234示例说明：double r = 2.1; //(1) double pi = 3.14;//(2) double area = pi*r*r;//(3)1234 虽然代码语句的定义顺序为1-&gt;2-&gt;3，但是计算顺序1-&gt;2-&gt;3与2-&gt;1-&gt;3对结果并无影响，所以编译时和运行时可以根据需要对1、2语句进行重排序。 2.2 指令重排带来的问题如果一个操作不是原子的，就会给JVM留下重排的机会。 1234567891011线程A中&#123; context = loadContext(); inited = true;&#125;线程B中&#123; if (inited) fun(context);&#125; 如果线程A中的指令发生了重排序，那么B中很可能就会拿到一个尚未初始化或尚未初始化完成的context,从而引发程序错误。 2.3 禁止指令重排的原理 volatile关键字提供内存屏障的方式来防止指令被重排，编译器在生成字节码文件时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。 JVM内存屏障插入策略： 每个volatile写操作的前面插入一个StoreStore屏障； 在每个volatile写操作的后面插入一个StoreLoad屏障； 在每个volatile读操作的后面插入一个LoadLoad屏障； 在每个volatile读操作的后面插入一个LoadStore屏障。 实际使用volatile保证每次修改值都会写到主内存中去 1234567891011121314151617181920212223242526272829public class MainTest &#123; //加volatile关键字最后输出的是1,没加最后输出的是0,,如果thread2操作过慢也会输出0 private static volatile boolean i = false; private static int x = 0; public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(() -&gt; &#123; try &#123; Thread.sleep(100); i = true; i = false; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); Thread t2 = new Thread(() -&gt; &#123; while (true) &#123; if (i == true) &#123; x++; &#125; &#125; &#125;); t1.start(); t2.start(); Thread.sleep(1000); System.out.println(x); System.exit(1); &#125;&#125; 代码锁AQSAQS即是AbstractQueuedSynchronizer，一个用来构建锁和同步工具的框架，包括常用的ReentrantLock、CountDownLatch、Semaphore等。 公平非公平 公平锁：线程获取锁的顺序和调用lock的顺序一样，FIFO； 非公平锁：线程获取锁的顺序和调用lock的顺序无关，全凭运气。 ExecutorService+CountDownLatch保证线程同时执行 12345678910111213141516171819202122public class CountDownLatchs &#123; static int count=0; public static void main(String[] args) &#123; CountDownLatch countDownLatch = new CountDownLatch(1); ExecutorService executorService = Executors.newFixedThreadPool(10); for(int i=0;i&lt;10;i++) &#123; Thread r=new Thread() &#123; public void run() &#123; try &#123; countDownLatch.await(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; System.out.println(this.getName()+":"+System.currentTimeMillis()); &#125; &#125;; r.setName("thread"+i); executorService.submit(r); &#125; countDownLatch.countDown(); &#125;&#125; CyclicBarrierCyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。 它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。 CyclicBarrier默认的构造方法是CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用await方法告诉CyclicBarrier我已经到达了屏障，然后当前线程被阻塞。 CountDownLatch和CyclicBarrier(1).CountDownLatch 的作用是允许1或者多个线程，等待另外N个线程完成某件事情之后，这1个或者多个线程才能执行。CyclicBarrier 是N个线程相互等待，任何一个线程完成任务之前，所有的线程必须等待。 (2).CountDownLatch 计数器是一次性的，无法被重置的，而CyclicBarrier的计数器在调用reset方法之后，还可以重新使用，因此被称为循环的barrier。 CountDownLatch 底层实现构造方法：创建一个Sync对象，而Sync继承AQS(AbstractQueuedSynchronized) tryAcquire()​ 尝试去获取独占资源。如果获取成功，则直接返回true，否则直接返回false。 addWaiter()​ 当前线程加入到等待队列的队尾，并返回当前线程所在的结点 acquireQueued()​ 使线程在等待队列中获取资源，一直获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。 ​ 如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上。 JAVA锁对象在内存中的头信息 自旋–&gt;偏向–&gt;轻量级–&gt;重量级 synchronized的执行过程： 1. 检测Mark Word里面是不是当前线程的ID，如果是，表示当前线程处于偏向锁 2. 如果不是，则使用CAS将当前线程的ID替换Mard Word，如果成功则表示当前线程获得偏向锁，置偏向标志位1 3. 如果失败，则说明发生竞争，撤销偏向锁，进而升级为轻量级锁。 4. 当前线程使用CAS将对象头的Mark Word替换为锁记录指针，如果成功，当前线程获得锁 5. 如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。 6. 如果自旋成功则依然处于轻量级状态。 7. 7. 如果自旋失败，则升级为重量级锁。 自旋锁线程的阻塞和唤醒需要CPU从用户态转为核心态 ，比较耗时 如果本身任务时间很短，通过不断循环的方式抢占cup时间片，已达到等待不阻塞线程 适应自旋锁JDK 1.6引入机制，通过计算自旋成功率，自动判断是否需要升级锁 锁消除通过逃逸分析，自动给不需要加锁的程序去锁 所以不用纠用StringBuild和StingBuffer了? 锁粗化将几个多次加锁解锁的过程合并 例如在for循环里面vector.add 偏向锁目的：为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径 CAS获得锁，不释放 如果获得失败升级为轻量级锁 访问Mark Word中偏向锁的标识是否设置成1，锁标志位是否为01，确认为可偏向状态。 如果为可偏向状态，则测试线程ID是否指向当前线程，如果是，进入步骤5，否则进入步骤3。 如果线程ID并未指向当前线程，则通过CAS操作竞争锁。如果竞争成功，则将Mark Word中线程ID设置为当前线程ID，然后执行5；如果竞争失败，执行4。 如果CAS获取偏向锁失败，则表示有竞争。当到达全局安全点（safepoint）时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。（撤销偏向锁的时候会导致stop the word） 执行同步代码。 轻量级锁轻量级锁是由偏向所升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁；轻量级锁的加锁过程： 在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，官方称之为 Displaced Mark Word。这时候线程堆栈与对象头的状态如图： 拷贝对象头中的Mark Word复制到锁记录中； 拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock record里的owner指针指向object mark word。如果更新成功，则执行步骤4，否则执行步骤5。 如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，即表示此对象处于轻量级锁定状态，这时候线程堆栈与对象头的状态如图所示。 如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行。否则说明多个线程竞争锁，轻量级锁就要膨胀为重量级锁，锁标志的状态值变为“10”，Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。 而当前线程便尝试使用自旋来获取锁，自旋就是为了不让线程阻塞，而采用循环去获取锁的过程。 轻量级锁的释放释放锁线程视角：由轻量锁切换到重量锁，是发生在轻量锁释放锁的期间，之前在获取锁的时候它拷贝了锁对象头的markword，在释放锁的时候如果它发现在它持有锁的期间有其他线程来尝试获取锁了，并且该线程对markword做了修改，两者比对发现不一致，则切换到重量锁。 因为重量级锁被修改了，所有display mark word和原来的markword不一样了。 怎么补救，就是进入mutex前，compare一下obj的markword状态。确认该markword是否被其他线程持有。 此时如果线程已经释放了markword，那么通过CAS后就可以直接进入线程，无需进入mutex，就这个作用。 尝试获取锁线程视角：如果线程尝试获取锁的时候，轻量锁正被其他线程占有，那么它就会修改markword，修改重量级锁，表示该进入重量锁了。 还有一个注意点：等待轻量锁的线程不会阻塞，它会一直自旋等待锁，并如上所说修改markword。 这就是自旋锁，尝试获取锁的线程，在没有获得锁的时候，不被挂起，而转而去执行一个空循环，即自旋。在若干个自旋后，如果还没有获得锁，则才被挂起，获得锁，则执行代码。 重量级锁操作系统的互斥锁(Mutex Lock)来实现 参考资料 https://blog.csdn.net/zqz_zqz/article/details/70233767 https://blog.csdn.net/u012722531/article/details/78244786 Thread常用方法 Thread.sleep(long millis)，一定是当前线程调用此方法，当前线程进入TIME_WAITING状态，但不释放对象锁，millis后线程自动苏醒进入就绪状态。作用：给其它线程执行机会的最佳方式。 Thread.yield()，一定是当前线程调用此方法，当前线程放弃获取的cpu时间片，由运行状态变会就绪状态，让OS再次选择线程。作用：让相同优先级的线程轮流执行，但并不保证一定会轮流执行。实际中无法保证yield()达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。Thread.yield()不会导致阻塞。 t.join()/t.join(long millis)，当前线程里调用其它线程t的join方法，当前线程进入TIME_WAITING/TIME_WAITING状态，当前线程不释放已经持有的对象锁。线程t执行完毕或者millis时间到，当前线程进入就绪状态。 obj.wait()，当前线程调用对象的wait()方法，当前线程释放对象锁，进入等待队列。依靠notify()/notifyAll()唤醒或者wait(long timeout)timeout时间到自动唤醒。 obj.notify()唤醒在此对象监视器上等待的单个线程，选择是任意性的。notifyAll()唤醒在此对象监视器上等待的所有线程。 线程状态转换NEW：new Thread() RUNNABLE：Thread.start() BLOCKED：遇到synchronized WAITING：获得锁后主动等待 TIMED_WAITING：等待，加上时间 TERMINATED：线程结束 # 锁膨胀过程 st=>start: new dead=>end: dead runnable=>subroutine: runnable run2=>subroutine: runnable running=>subroutine: running running1=>condition: 根据执行情况走各种分支 run3=>operation: 重复runnable步骤 block=>subroutine: 等待条件完成 wait=>subroutine: 释放锁,进入等待池 lock=>subroutine: 争抢锁 lock1=>operation: lock2=>operation: threadStart=>operation: thread.start() os=>operation: 获得时间片 getLock=>operation: 获得锁 doNotify=>operation: notify(),notifyAll() runFinish=>operation: run方法结束,程序异常 endblock=>operation: sleep结束,IO完成 doWait=>condition: wait(),join() yeald=>operation: yeald() doJoin=>condition: sleep(),IO操作 doSync=>condition: synchronized st->threadStart->runnable->os->running->running1 running1(yes)->doSync running1(no)->yeald(right)->runnable doSync(yes)->lock1->lock2->lock doSync(no)->doWait doWait(no)->doJoin doJoin(no)->dead doWait(yes)->wait doJoin(yes)->block lock->getLock->run2 block->endblock->run2 wait->doNotify->lock run2->run3{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);st=>start: 开始 prelock=>operation: 遇到同步语句 empty=>condition: 无锁 setThread0=>operation: setThread=>operation: 当markdown设置为当前线程,状态为偏向锁 isbiasedLock=>condition: 偏向锁 cancelBiasedLock=>condition: 当前线程和偏向id一样 spin=>operation: 清空markdown信息,准备膨胀 run=>operation: 执行同步代码 ed=>end: 结束 spinLock=>获得锁 spinCond=>condition: 自旋获得锁 updateThread=>operation: markdown设置为当前线程 copylight=>operation: 复制锁信息到当前线程 wrightLight=>operation: 将轻量级锁指针指到当前线程 lightLock=>operation: 轻量级锁 weightLock0=>operation: weightLock1=>operation: weightLock2=>operation: weightLock3=>operation: weightLock=>operation: 膨胀为重量级锁 run2=>operation: 执行同步代码 callbackLight=>condition: cas回写lock信息成功 ed2=>end: 结束 st->prelock->empty empty(yes)->setThread0->setThread->run->ed empty(no)->isbiasedLock isbiasedLock(yes)->cancelBiasedLock isbiasedLock(no)->spin cancelBiasedLock(yes)->setThread cancelBiasedLock(no)->spin->copylight spinCond(no)->copylight->wrightLight->callbackLight callbackLight(yes,right)->lightLock->ed2 callbackLight(no)->spinCond spinCond(no)->weightLock{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-1-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-1-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-1", options);]]></content>
      <categories>
        <category>code</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix使用]]></title>
    <url>%2Fblog%2Fops%2Fmonitor%2Fzabbix%2F</url>
    <content type="text"><![CDATA[安装zabbix并添加自定义监控，通过模板实现监控项的自动添加 安装yum源方式12rpm -i https://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-2.el7.noarch.rpmyum install zabbix-server-mysql zabbix-web-mysql zabbix-agent 初始化数据库12345# mysql -uroot -ppasswordmysql&gt; create database zabbix character set utf8 collate utf8_bin;mysql&gt; grant all privileges on zabbix.* to zabbix@localhost identified by &apos;password&apos;;mysql&gt; quit; 导入数据1# zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbix 配置zabbix_serve/etc/zabbix/zabbix_server.conf 1DBPassword=password 修改php1# php_value date.timezone Europe/Riga 启动12# systemctl restart zabbix-server zabbix-agent httpd# systemctl enable zabbix-server zabbix-agent httpd ISO方式 Linux Ubuntu用户名及密码：appliance/zabbixroot没有初始密码，sudo passwd root可配置root密码 zabbix web用户名及密码Admin/zabbix mysql启动systemctl start mysqld.service 查询登录密码grep ‘temporary password’ /var/log/mysqld.log 修改密码政策set global validate_password_policy=0; set global validate_password_length=1; 设置密码SET PASSWORD = PASSWORD(‘123456’); 测试yum install zabbix-get zabbix_get -s 127.0.0.1 -p 10050 -k “system.cpu.load[all,avg1]” 无数据检查服务是否启动 lsof -i:10051 查看日志 /var/log/zabbix/zabbix_server Permission deniedcurl: (7) Failed to connect to 192.168.1.103: Permission denied 关闭Selinux setenforce 0 常用命令重启service zabbix-server restart systemctl restart zabbix-agent.service 优化改为主动式 配置主机名称和和zabbix_agentd.conf中的Hostname配置一样 自定义配置zabbix发现流程 提供接口发现接口 1234567891011121314151617@Query(name="提供给zabbix用于自动发现的接口",path="zabbix")public String zabbix(String host,Integer port)&#123; List list=new ArrayList(); TimeMonitor tm=(TimeMonitor) MonitorFacade.getMonitor(MonitorFacade.HTTP_MONITOR); tm.getMap().forEach((name,st)-&gt;&#123; Map map=new LinkedHashMap(); for(int i=0;i&lt;st.getAccuracy().length;i++) &#123; map.put("&#123;#ITEM"+i+"&#125;",st.getAccuracy()[i]); &#125; map.put("&#123;#NAME&#125;",name); map.put("&#123;#URL&#125;", "/app/monitor/getItem"); list.add(map); &#125;); Map map=new HashMap(); map.put("data", list); return jsonUtil.toString(map);&#125; 取值接口 1234567891011121314151617@Query(name="获取单个统计项的值",path="getItem")public String getItem(String name,String item)&#123; try &#123; TimeMonitor tm=(TimeMonitor) MonitorFacade.getMonitor(MonitorFacade.HTTP_MONITOR); TimeStatist st=tm.get(name); if(st==null) &#123; log.info("找不到监控项:"+name); return "0"; &#125; int num=Integer.parseInt(item); return st.getAccuracyCount()[num].get()+""; &#125;catch(Exception ex) &#123; ex.printStackTrace(); log.error("请求参数不正确:"+name+":"+item+","+ex.getMessage()); return ""; &#125;&#125; 自定义参数将此文件上传到/etc/zabbix/zabbix_agentd.d目录下,并重启agent userparameter_responsetimel.conf 12UserParameter=getItems[*],curl &apos;http://$1:$2/app/monitor/zabbix?host=$1&amp;port=$2&apos; 2&gt;/dev/nullUserParameter=getItemValue[*],curl &apos;http://$1:$2$3?name=$4&amp;item=$5&apos; 2&gt;/dev/null 自动发现123456#直接访问curl http://192.168.1.103:8080/app/monitor/zabbix#配置UserParameter=getItems[*],curl &apos;http://$1:$2/app/monitor/zabbix?host=$1&amp;port=$2&apos; 2&gt;/dev/null#验证zabbix_get -s 192.168.1.105 -p 10050 -k &quot;getItems[192.168.1.103,8080,time]&quot; 返回内容 123456789101112131415161718192021222324252627282930313233343536&#123; "data": [ &#123; "&#123;#ITEM0&#125;": "5", "&#123;#ITEM1&#125;": "10", "&#123;#ITEM2&#125;": "100", "&#123;#ITEM3&#125;": "500", "&#123;#ITEM4&#125;": "1000", "&#123;#ITEM5&#125;": "5000", "&#123;#NAME&#125;": "/app/monitor/zabbix", "&#123;#URL&#125;": "/app/monitor/getItem" &#125;, &#123; "&#123;#ITEM0&#125;": "5", "&#123;#ITEM1&#125;": "10", "&#123;#ITEM2&#125;": "100", "&#123;#ITEM3&#125;": "500", "&#123;#ITEM4&#125;": "1000", "&#123;#ITEM5&#125;": "5000", "&#123;#NAME&#125;": "httpRequest.totalrequest", "&#123;#URL&#125;": "/app/monitor/getItem" &#125;, &#123; "&#123;#ITEM0&#125;": "5", "&#123;#ITEM1&#125;": "10", "&#123;#ITEM2&#125;": "100", "&#123;#ITEM3&#125;": "500", "&#123;#ITEM4&#125;": "1000", "&#123;#ITEM5&#125;": "5000", "&#123;#NAME&#125;": "/app/monitor/getItem", "&#123;#URL&#125;": "/app/monitor/getItem" &#125; ], "success": true, "state": 2&#125; 获取某项的值123456#直接访问curl http://192.168.1.103:8080/app/monitor/getItem?name=/app/monitor/zabbix&amp;item=0#配置UserParameter=getItemValue[*],curl &apos;http://$1:$2$3?name=$4&amp;item=$5&apos; 2&gt;/dev/nul#验证zabbix_get -s 192.168.1.105 -p 10050 -k &quot;getItemValue[192.168.1.103,8080,/app/monitor/timeValue,/app/monitor/time,0]&quot; 返回内容 13 配置模板新增模板12345Templates-&gt;Create TemplateTemplate name:httpTemplateAdd 新增发现规则123456789Templates-&gt;httpTemplate-&gt;Discovery rules-&gt;Create discovery ruleName:httpDiscoveryType:Zabbix agent/Zabbix agent(active)Key :getItems[&#123;$MONITOR_HOST&#125;,&#123;$MONITOR_PORT&#125;]点击Add 新增监控项(Item prototypes)123456789Templates-&gt;httpTemplate-&gt;Discovery rules-&gt;httpDiscovery-&gt;Item prototypes-&gt;Create item prototypeName:&#123;#NAME&#125;_&#123;#ITEM0&#125;Type:Zabbix agent/Zabbix agent(active)Key:getItemValue[&#123;$MONITOR_HOST&#125;,&#123;$MONITOR_PORT&#125;,&#123;#URL&#125;,&#123;#NAME&#125;,0]点击Add 继续添加item1,2,3,4,5 监控图(Graph prototypes)Templates-&gt;httpTemplate-&gt;Graph prototypes-&gt;Create graph prototype 12Name:&#123;#NAME&#125;Graph type:Stacked Add prototype Add 将模板关联到目标主机1234567891011host-&gt;要监控的host-&gt;Templates-&gt;select-&gt; httpTemplate-&gt;Select-&gt;Add-&gt;Updatehost-&gt;要监控的host-&gt;Macros&#123;$MONITOR_HOST&#125;:192.168.1.103add&#123;$MONITOR_PORT&#125;:8080update 最终效果 中文修改系统语言 替换字体 到C:\Windows\Fonts下找到需要的字体上传到/usr/share/zabbix/fonts 备份原字体 替换 1234#备份mv /usr/share/zabbix/fonts/graphfont.ttf /usr/share/zabbix/fonts/graphfont.ttf.bak#替换ln /usr/share/zabbix/fonts/SIMFANG.TTF /usr/share/zabbix/fonts/graphfont.ttf]]></content>
      <categories>
        <category>ops</category>
        <category>monitor</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务接口设计]]></title>
    <url>%2Fblog%2Fdesign%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[微服务架构下，为了保证系统的高可用，服务通常会设计成集群的方式，当客户端调用其中一个服务端失败时，通常会自动找其他机器进行重试。但由于网络间通信存在超时问题，有可能存在客户端返回失败，但服务端已成功的情况，这就存出现了重复调用的问题。 所以为了保证业务逻辑的正确性，系统间的接口最好保证幂等，这里给出的方案是给每一个请求都绑定一个requestId的方式，保证一个请求在全局是唯一性 客户端 服务端 st=>start: 开始 requestId=>condition: 否有requestId createRequest=>operation: 创建requestId getResult=>operation: 到reids获取结果 redisSucces=>condition: redis为空 put=>operation: 将requestId放入redis hasReq=>condition: 已经存在 toServer=>operation: 向服务器发起请求 success=>condition: 获得结果 running=>condition: 对方执行中 successEnd=>end: 正常结束 timeout=>condition: 超时 busError=>end: 异常结束 retry=>condition: 延迟处理 record=>end: 补偿流程 toRetry=>end: 重试流程 st->put requestId(yes)->put requestId(no)->createRequest->put put->hasReq hasReq(yes)->getResult hasReq(no)->toServer->success success(yes)->running running(no, right)->successEnd running(yes)->record success(no)->timeout timeout(yes)->retry timeout(no)->busError retry(yes)->record retry(no)->toRetry getResult->redisSucces redisSucces(no)->successEnd redisSucces(yes)->record{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);st=>start: 开始 getState=>operation: 查询请求状态 running=>condition: 是否可执行 hasResult=>condition: 已有结果 uptorun=>operation: 更新为执行中 upSuccess=>condition: 更新成功 finish=>condition: 已经完成 computer=>operation: 执行程序 getResult=>operation: 读取Redis setReslut=>operation: 将结果放入Reids rt=>end: 返回执行中 retValue=>end: 返回执行结果 redisEnd=>end: 返回ridis数据 st->getState getState->running running(no)->rt running(yes)->hasResult hasResult(yes)->getResult hasResult(no)->uptorun->upSuccess upSuccess(no)->rt upSuccess(yes)->computer computer->setReslut setReslut->retValue getResult->redisEnd{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-1-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-1-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-1", options);]]></content>
      <categories>
        <category>design</category>
      </categories>
      <tags>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类加载器]]></title>
    <url>%2Fblog%2Fcode%2Fjava%2F%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%2F</url>
    <content type="text"><![CDATA[简述java的类加载器和类加载过程 类加载器 类加载过程 加载：类加载过程的一个阶段：通过一个类的完全限定查找此类字节码文件，并利用字节码文件创建一个Class对象 验证：目的在于确保Class文件的字节流中包含信息符合当前虚拟机要求，不会危害虚拟机自身安全。主要包括四种验证，文件格式验证，元数据验证，字节码验证，符号引用验证。 准备：为类变量(即static修饰的字段变量)分配内存并且设置该类变量的初始值即0(如static int i=5;这里只将i初始化为0，至于5的值将在初始化时赋值)，这里不包含用final修饰的static，因为final在编译的时候就会分配了，注意这里不会为实例变量分配初始化，类变量会分配在方法区中，而实例变量是会随着对象一起分配到Java堆中。 解析：主要将常量池中的符号引用替换为直接引用的过程。符号引用就是一组符号来描述目标，可以是任何字面量，而直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。有类或接口的解析，字段解析，类方法解析，接口方法解析(这里涉及到字节码变量的引用，如需更详细了解，可参考《深入Java虚拟机》)。 初始化：类加载最后阶段，若该类具有超类，则对其进行初始化，执行静态初始化器和静态初始化成员变量(如前面只初始化了默认值的static变量将会在这个阶段赋值，成员变量也将被初始化)。 类加载启动（Bootstrap）类加载器启动类加载器主要加载的是JVM自身需要的类，这个类加载使用C++语言实现的，是虚拟机自身的一部分，它负责将 &lt;JAVA_HOME&gt;/lib路径下的核心类库或-Xbootclasspath参数指定的路径下的jar包加载到内存中，注意必由于虚拟机是按照文件名识别加载jar包的，如rt.jar，如果文件名不被虚拟机识别，即使把jar包丢到lib目录下也是没有作用的(出于安全考虑，Bootstrap启动类加载器只加载包名为java、javax、sun等开头的类)。 扩展（ExtClassLoader ）类加载器扩展类加载器是指Sun公司(已被Oracle收购)实现的sun.misc.Launcher$ExtClassLoader类，由Java语言实现的，是Launcher的静态内部类，它负责加载&lt;JAVA_HOME&gt;/lib/ext目录下或者由系统变量-Djava.ext.dir指定位路径中的类库，开发者可以直接使用标准扩展类加载器。 系统（AppClassLoader ）类加载器也称应用程序加载器是指 Sun公司实现的sun.misc.Launcher$AppClassLoader。它负责加载系统类路径java -classpath或-D java.class.path 指定路径下的类库，也就是我们经常用到的classpath路径，开发者可以直接使用系统类加载器，一般情况下该类加载是程序中默认的类加载器，通过ClassLoader#getSystemClassLoader()方法可以获取到该类加载器。]]></content>
      <categories>
        <category>code</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>类加载器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud环境搭建]]></title>
    <url>%2Fblog%2Fcode%2Fspring%2FspringClould%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[通过springcloud环境搭建，包括spring-config-server，eureka，hystrix spring版本号：2.1.9.RELEASE clould版本号：Greenwich.SR3 spring-config-server创建服务pom.xml1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt; app.java1234567@SpringBootApplication@EnableConfigServerpublic class MserviceConfigServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(MserviceConfigServerApplication.class, args); &#125;&#125; 客户端配置添加bootstrap.yml123456spring: cloud: config: uri: http://192.168.2.100:9001/config/ application: name: mservice-eureka-server 添加jar包1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt; 使用客户端可以通过以下方式获取配置值,config是自定义的前缀，在configserver里的spring.cloud.config.server.prefix=config 12345678910/config/&#123;name&#125;-&#123;profiles&#125;.properties/config/&#123;name&#125;-&#123;profiles&#125;.yml/config/&#123;name&#125;-&#123;profiles&#125;.yaml/config/&#123;name&#125;/&#123;profiles:.*[^-].*&#125;/config/&#123;label&#125;/&#123;name&#125;-&#123;profiles&#125;.json/config/&#123;label&#125;/&#123;name&#125;-&#123;profiles&#125;.properties/config/&#123;name&#125;-&#123;profiles&#125;.json/config/&#123;label&#125;/&#123;name&#125;-&#123;profiles&#125;.yml/config/&#123;label&#125;/&#123;name&#125;-&#123;profiles&#125;.yaml/config/&#123;name&#125;/&#123;profiles&#125;/&#123;label:.*&#125; 配置中心最终将从容器中获取EnvironmentRepository的实现类并调用findOne获取配置信息覆盖本地的application.yml内容 1org.springframework.cloud.config.server.environment.EnvironmentRepository#findOne 目前配置目前是写在数据库里的 12345678910111213DROP TABLE IF EXISTS `m_appconfig`;CREATE TABLE `m_appconfig` ( `appConfigId` double DEFAULT NULL, `application` varchar(64) COLLATE utf8_bin DEFAULT NULL, `profile` varchar(64) COLLATE utf8_bin DEFAULT NULL, `varLabel` varchar(64) COLLATE utf8_bin DEFAULT NULL, `varKey` varchar(64) COLLATE utf8_bin DEFAULT NULL, `varValue` varchar(255) COLLATE utf8_bin DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin;insert into `m_appconfig`(`appConfigId`,`application`,`profile`,`varLabel`,`varKey`,`varValue`) values (7,NULL,NULL,NULL,'logging.level.wang.wangby','debug'),(8,NULL,NULL,NULL,'logging.pattern.console','%-5level %logger&#123;0&#125;.%M:%L - %msg%n'),(14,NULL,NULL,NULL,'eureka.instance.prefer-ip-address','false'),(15,NULL,NULL,NULL,'eureka.client.service-url.defaultZone','http://eureka1:7000/eureka/,http://eureka2:7000/eureka/,http://eureka3:7000/eureka/'),(20,NULL,NULL,NULL,'mybatis.mapper-locations','classpath:mybatis/mapper/**/*.xml'),(16,'mservice-demo-client',NULL,'demo1','server.port','8080'),(13,'mservice-demo-server',NULL,'demo1','mserver.machineNo','101'),(17,'mservice-demo-server',NULL,'demo1','server.port','8001'),(18,'mservice-demo-server',NULL,'demo2','server.port','8002'),(19,'mservice-demo-server',NULL,'demo2','mserver.machineNo','102'),(9,'mservice-demo-server',NULL,'demo\\d','spring.datasource.username','root'),(10,'mservice-demo-server',NULL,'demo\\d','spring.datasource.password','123456'),(11,'mservice-demo-server',NULL,'demo\\d','spring.datasource.driver-class-name','com.mysql.jdbc.Driver'),(12,'mservice-demo-server',NULL,'demo\\d','spring.datasource.url','jdbc:mysql://127.0.0.1:3306/demo?useUnicode=true&amp;charact&amp;useSSL=false'),(1,'mservice-eureka-server',NULL,NULL,'eureka.client.fetch-registry','true'),(2,'mservice-eureka-server',NULL,NULL,'eureka.client.register-with-eureka','true'),(4,'mservice-eureka-server',NULL,'1','eureka.client.service-url.defaultZone','http://eureka2:7000/eureka/,http://eureka3:7000/eureka/'),(5,'mservice-eureka-server',NULL,'2','eureka.client.service-url.defaultZone','http://eureka1:7000/eureka/,http://eureka3:7000/eureka/'),(6,'mservice-eureka-server',NULL,'','server.port','7000'),(21,'mservice-hystrix-dashboard',NULL,NULL,'server.port','9002'),(22,'bookstore-provider',NULL,NULL,'mserver.machineNo','200'),(23,'bookstore-provider',NULL,'1','eureka.instance.instance-id','bookstoreProvider1'),(24,'bookstore-provider',NULL,'2','eureka.instance.instance-id','bookstoreProvider2'),(25,'mservice-eureka-server',NULL,'3','eureka.client.service-url.defaultZone','http://eureka1:7000/eureka/,http://eureka2:7000/eureka/'),(27,'mservice-eureka-server',NULL,'1','eureka.instance.hostname','eureka1'),(28,'bookstore-provider',NULL,'3','eureka.instance.instance-id','bookstoreProvider3'); eureka创建服务pom.xml1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; app.java1234567@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication &#123; public static void main(String[] args) throws ClassNotFoundException &#123; SpringApplication.run(EurekaServerApplication.class, args); &#125;&#125; 从配置中心读取到的配置1234567891011121314eureka: client: fetch-registry: 'true' register-with-eureka: 'true' service-url: defaultZone: http://eureka1:7000/eureka/,http://eureka2:7000/eureka/ instance: hostname: eureka1 prefer-ip-address: 'false'server: port: '7000'spring: application: name: mservice-eureka-server 可能问题如果出现unavailable-replicas需要将prefer-ip-address设为false hystrix-dashboardpom.xml1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt;&lt;/dependency&gt; app.java1234567@SpringBootApplication@EnableHystrixDashboardpublic class HystrixDashboardApplication &#123; public static void main(String[] args) throws ClassNotFoundException &#123; SpringApplication.run(HystrixDashboardApplication.class, args); &#125;&#125; 访问地址1http://hystrixdashboard:9002/hystrix 地址栏输入要监控的服务提供者 最终效果]]></content>
      <categories>
        <category>code</category>
        <category>spring</category>
      </categories>
      <tags>
        <tag>springcloud，微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用命令]]></title>
    <url>%2Fblog%2Fops%2Fops%2F%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[日常开发经常会碰到，但过阵子又忘记了的命令，做一个备份，便于搜索，不断更新中。。。 windows查看端口占用1netstat -ano|findstr 22 结束进程1taskkill /pid 1111 /f 查看文件占用任务管理器–&gt;性能–&gt;打开资源监视器–&gt;–&gt;cpu–&gt;搜索句柄 linux切换语言1LANG=en 查找文件1find / -name 'xxx' 查看磁盘占用 df -h 查看目录占用 du -sh * | sort -nr 软链 /usr/share占用空间太大,移到/docker/softlink/share -s软 -d目录 ln -sd /docker/softlink/share/ /usr/share git分支切换123456#查看git branch -a#获取git fetch origin branchName#切换git branch 还原123git statusgit checkout 文件名checkout的意思是用缓存区的文件替换掉工作区 ssh生成秘钥1ssh-keygen -t rsa -C "xxx@qq.com"]]></content>
      <categories>
        <category>ops</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用快捷键]]></title>
    <url>%2Fblog%2Fops%2Fops%2F%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[一些快捷键，不常用，但想用了又不好查，统计记录一下 win10系统默认Win + Ctrl +左/右 切换桌面 Win + R 打开运行对话框 Win + Q 快速打开搜索 Win + I 快速打开Win10设置栏 Ctrl+Shift+Esc 打开任务管理器 自定义快捷键 添加快捷方式 选择要输入或者运行的程序 右键属性，在快捷键栏输入要使用的快捷键，必须是组合键 nodepad++123Ctrl + U #小写Ctrl + shift + U #大写Ctrl + Shift + L #自动换行]]></content>
      <categories>
        <category>ops</category>
      </categories>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用sql]]></title>
    <url>%2Fblog%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2Fmysql%2Fdatabase%2F%E5%B8%B8%E7%94%A8sql%2F</url>
    <content type="text"><![CDATA[一些mysql日常维护和使用经常用的sql，包括数据库，用户，表等 1234567select user,host,password from mysql.user;grant all privileges on *.* to ming@'*' identified by '123456';update mysql.user set password=password('newpwd') where user="ming" and Host="%";flush privileges;select table_name ,column_name ,is_nullable ,data_type as datatype ,character_maximum_length ,column_comment from information_schema.columns where table_schema='mysql' order by table_name, ordinal_position 查询数据库123show databases;show tables;select user,host,password from mysql.user; mysql创建用户1234567#创建用户ming，密码123456，所有数据库权限CREATE USER &apos;ming&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;;grant all privileges on *.* to &apos;ming&apos;@&apos;%&apos; ;#新版mysql加密方式变了ALTER USER &apos;ming&apos;@&apos;%&apos; IDENTIFIED BY &apos;ming&apos; PASSWORD EXPIRE NEVERALTER USER &apos;ming&apos;@&apos;%&apos; IDENTIFIED WITH mysql_native_password BY &apos;ming&apos;; flush privileges; mysql修改密码123#注意第二句不写新密码不会生效ALTER USER &apos;ming&apos;@&apos;%&apos; IDENTIFIED WITH mysql_native_password BY &apos;ming&apos;; flush privileges; mysql删除用户直接删mysql.user表记录就好了 查询表结构123456#查询表名和备注select table_name,table_comment from information_schema.TABLES where table_schema=&apos;mysql&apos;#查看字段信息select table_name ,column_name ,is_nullable ,data_type as datatype ,character_maximum_length ,column_comment from information_schema.columns where table_schema=&apos;mysql&apos; order by table_name, ordinal_position]]></content>
      <categories>
        <category>数据库</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7下安装mysql]]></title>
    <url>%2Fblog%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2Fmysql%2Fdatabase%2Fcentos7%E5%AE%89%E8%A3%85mysql%2F</url>
    <content type="text"><![CDATA[coentos7安装mysql 123456wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpmrpm -ivh mysql-community-release-el7-5.noarch.rpmyum -y install mysql-serversystemctl start mysqld.servicemysql -u rootgrant all privileges on *.* to ming@'%' identified by 'ming'; 安装123wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpmrpm -ivh mysql-community-release-el7-5.noarch.rpmyum -y install mysql-server 看到这个说明就在下载了，如果没下载，到别处看看吧，这篇文章可能过时了 如果发现yum被锁,ps -ef|grep yum |awk ‘{print $1}’|kill-9 启动1systemctl start mysqld.service 输入mysql能进去就说明启动成功了 初始化数据库12345mysql -u rootcreate database hello;grant all privileges on hello.* to foo@localhost identified by &apos;123456&apos;;#如果不限制IP改为#grant all privileges on hello.* to foo@&apos;%&apos; identified by &apos;123456&apos;;]]></content>
      <categories>
        <category>数据库</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo搭建个人博客]]></title>
    <url>%2Fblog%2Fcode%2Fhexo%2Fdevelop%2Fhexo%E6%90%AD%E5%BB%BAblog%2F</url>
    <content type="text"><![CDATA[记录这个博客搭建过程，目前为止用到的功能如下，不断丰富中 hexo生成代码 next主题 码云web服务 leancloud记录阅读量 编译并提交 123456e:cd E:\blog\public\bloghexo ggit add .git commit -am '备注'git push 准备工作这些工作因为以前就做过了，这里就不专门写出来了， 安装npm（Node Package Manager ），我的版本是5.6.0 安装TortoiseGit，我的版本是TortoiseGit 2.6.0.0 注册码云账号，并创建项目，这里定的项目名称是blog 本地新建目录，我用的是：E:\blog，下面如果没特殊说明，所有命令均是在这个目录下执行的 下面正式开始 进入工作目录 12E:cd blog 安装hexo1npm install -g hexo 创建项目1hexo init 启动，如果不行就执行一下npm install 1hexo s 打开浏览器,在地址栏输入输入：http://127.0.0.1:4000/ 就可以直接访问了 更换主题个人选的是NexT 可以到网站上将其下载到主题目录E:\blog\themes，也可以直接用git命令 1git clone https://github.com/theme-next/hexo-theme-next.git themes/next 修改项目根路径下的配置文件（e:/blog/_config.yml，后面简称站点文件） 将theme改为next 1234# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: next 修改next的配置文件（E:/blog/themes/next/_config.yml，后面简称主题文件） 还可以进一步更换样式,目前可选的有下面这些，根据个人喜好，可自行选择 12345# Schemes#scheme: Muse#scheme: Mistscheme: Pisces#scheme: Gemini 基础配置标题1title: 个人博客 语言1language: zh-CN 语言是和这个目录下的文件对应的：E:\blog\themes\next\languages 添加分类和标签新建页面12hexo new page categorieshexo new page tage 修改生成页面的内容E:\blog\source\categories\index.md 12345---title: 分类date: 2018-07-30 00:12:56type: "categories"--- E:\blog\source\tags\index.md 12345---title: 标签date: 2018-07-30 00:13:55type: "tags"--- 修改主题文件根据需要选择要显示的页面，因为分类和标签对个人比较有用，就先开放这两个 123456789menu: home: / || home #about: /about/ || user tags: /tags/ || tags categories: /categories/ || th #archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat 开始撰写写博客唯一要做的事就是在这个目录（E:\blog\source_posts）下新建md文件 除了头部有一些特殊要求外，其余部分基本可以自由发挥 头部信息文章标题和分类等信息需要按专门的格式写 123456---title: 文章标题date: 2018-07-29 22:48:10categories: [一级分类,二级分类]tags: [标签1,标签2]--- 文章主体通过more便签可以将文正分为简介和正文两部分，下面是一个简单示例 12345678910111213141516这里是内容简介，点击阅读全文可以看到更多内容&lt;!--more--&gt;# 这里是一级标题## 测试画图'``flowst=&gt;start: 开始op=&gt;operation: 操作cond=&gt;condition: 判断en=&gt;end: 结束st-&gt;opop-&gt;condcond(yes)-&gt;en'``## 测试二级标题# 一级标题2# 一级标题3 实际效果首页 阅读全文 分类 标签 发布到网上由于网速问题原因，我暂时未将项目发布到github，而是用了码云 码云上提供了一个免费的Gitee Pages服务，可以用于展示静态页面 只要在项目里点击服务，然后点击Gitee Pages，再启动就可以了 修改项目根路径项目取名叫blog，所以最终发布到网上的网址为https://xixhaha.gitee.io/blog/ 为了保证页面和和资源能正常访问，需要对路径做一些修改 修改网站文件将root改为/blog 1root: /blog 下载项目到本地我下载到了这个目录：E:/blog/public/blog 1git clone https://gitee.com/xixhaha/blog.git public/blog 修改生成目录因为这个目录E:/blog/public/blog将会是最终的发布目录，所以要将生成的静态页面都放这里 修改站点文件 1public_dir: public/blog 生成静态页面1hexo g 提交到网站用的是TortoiseGit ，所以只需要在blog目录按右键选择git commit就可以了 commit填写备注，随便写点什么，然后点击All和Commit pushcommit后会转到push界面，直接点push 换成命令就是 123456e:cd E:\blog\public\bloghexo ggit add .git commit -am '备注'git push 总结基本上这样个人的博客就算搭建完毕了，以后要撰写博客只需要进行以下几个步骤 在E:\blog\blog_posts目录下新建md文件 开始撰写文章 执行命令 hexo g git commit and git push 个性化配置按分类生成路径文章的链接地址默认是按日期生成的，这样当要链接到自己文章时不太方便，可以改为按分类生成 修改网站文件 1permalink: :category/:title/ 排序规则默认是按发布时间倒序的，这里改成了按更新时间 1234index_generator: path: '' per_page: 10 order_by: -updated 图片问题因为我将图片全放到了E:\blog\source\images目录下，所以在外网访问时图片的路径是这个样子的 1/blog/images/1532877733213.png 为了保证撰写文章时图片也能正常显示所以需要做一些调整 将网站配置源文件目录改为blog 1source_dir: blog 每次插入图片时将图片复制到E:\blog\blog\images 我用的markdown编辑器是typroa需要在头部做一些配置，这样就保证能本地链接的地址和网站地址一致，同时在每次插入图片时自动复制到指定目录 最终每次创建md文件时，都需要这么一个文件头 12345678---title: date: categories: []tags: []typora-copy-images-to: ../imagestypora-root-url: E:/blog/--- 写了一个文件（blog.py）专门干这事，每次要写博客的时候只要双击这个文件就可以了 12345678910111213141516171819202122232425262728293031# -*- coding: UTF-8 -*-import datetimeimport subprocessimport threadingnow = datetime.datetime.now()fileName= now.strftime("%Y%m%d%H%M%S")now = now.strftime("%Y-%m-%d %H:%M:%S")head='''---title: date: &#123;&#125;categories: []tags: []typora-copy-images-to: ../imagestypora-root-url: E:/blog---&lt;!--more--&gt;'''.format(now)fileName='E:/blog/blog/_posts/'+fileName+'.md'fileHandle = open (fileName, 'w' )fileHandle.write (head)fileHandle.close()print("创建文件:"+fileName)cmd="cmd /c D:/Typora/Typora.exe "+fileNamedef action(): subprocess.call(cmd,shell=True,stdout=subprocess.PIPE)t=threading.Thread(target=action)t.start() 插件markdown画图原始的hexo是不支持作图的，需要安装插件，目前试了只有流程图能用 1npm install --save hexo-filter-flowchart 其它类型的图，暂时只能通过截图方式。。。 站内搜索我大部分时间拿博客当云笔记用，所以搜索功能必不可少，幸好有插件实现了站内搜索功能 安装插件1npm install hexo-generator-searchdb --save 修改站点文件12345search: path: search.xml field: post format: html limit: 10000 修改主题文件12local_search: enable: true 最终效果 阅读次数next内部已经集成了leancloud，我们要做的只是开启这个功能 修改主题文件将leancloud_visitors.enable设true，并配置app_id和app_key，这两个值需要到leancloud上获取 1234leancloud_visitors: enable: true app_id: XXXXXXXXXXX app_key: XXXXXXXXXXXXXXX 注册并登录leancloud略 创建应用点击头像–&gt;点击应用按钮–&gt;创建新应用 输入应用名，点击创建 创建Class选择刚才创建的应用后，点击云存储–&gt;创建class–&gt;输入class名称–&gt;创建class 这里名称要写Counter 获取app_id和app_key将设置–&gt;应用Key下的App ID和App Key写到上面说的主题文件里面 发布应用123456e:cd E:\blog\public\bloghexo ggit add .git commit -am '新增显示阅读次数功能'git push 最终效果 访问网页后点击Counter可以查看实际存储的数据的值，time就是保存的阅读次数，可以随意修改 评论可能遇到问题无法删除文件某些情况下会发现.md文件已经删除了，但最终还是会生成html，这时候需要清一下缓存。但clean命令会将整个public目录删掉，git信息也没了，所以需要先备份一下，具体命令如下 12345cd E:\blogren E:\blog\public public1hexo cleanren E:\blog\public1 publichexo g 404代码刚发布立即访问，有可能遇到临时无法访问的情况。如果不是这个原因，确认一下代码是否提交了， 使用TortoiseGit，默认是不提交新增文件的，所以commit前记得点一下All Template render error生成html页面的时候报错 可能原因是md文件里写了这样的代码 1&#123;#xxx&#125; 解决办法，想我这样写在代码块里就好了]]></content>
      <categories>
        <category>code</category>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springMVC组件说明]]></title>
    <url>%2Fblog%2Fcode%2Fspring%2FspringMVC%2Fdevelop%2FspringMVC%2F</url>
    <content type="text"><![CDATA[springMVC相关组件说明 ViewResolver:视图解析器,根据视图名称获取视图 Converter:将http参数转为JAVA对象 Formatter:格式化器,格式化日期 HttpMessageConverers:转换http请求和响应 webbingder autoconfigure.web]]></content>
      <categories>
        <category>code</category>
        <category>spring</category>
        <category>springMVC</category>
      </categories>
      <tags>
        <tag>springMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[秒杀场景系统设计]]></title>
    <url>%2Fblog%2Fdesign%2Fdesign%2Fseckill%2F</url>
    <content type="text"><![CDATA[秒杀是一种典型的高并发场景，大量用户会在同一时间访问系统，网站流量激增。但库存一般都是有限的，许多用户的请求基本无效，如果如何将用户请求拦截在关键节点之外，是系统设计的关键。从页面到数据库，系统的请求数量应该是一个漏斗的形状 整体流程 缓存初始化和更新1234graph TB活动开始--&gt;|放入可抢商品|redis活动开始--&gt;|放入门票|本地缓存定时任务--&gt;|更新活动信息|本地缓存 st=>start: 开始 op0=>operation: 进入队列 queue=>condition: 队列未满 op=>operation: 查询本地缓存 op1=>operation: 操作reids op2=>operation: 操作数据库 search1=>condition: 验证门票 search2=>condition: 活动状态 lock=>condition: 获得商品ID db=>condition: 更新商品 e=>end: 抢购完成 e1=>end: 活动未开始/结束 e2=>end: 库存不足 e3=>end: 排队 sec=>condition: 计划任务 st->op0->queue queue(yes)->op(buttom) queue(no)->e3 op->search1 search1(yes)->search2 search1(no)->e3 search2(yes)->op1(right)->lock search2(no)->e1 lock(yes)->op2->db lock(no)->e2 db(yes)->e db(no)->e2{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);]]></content>
      <categories>
        <category>design</category>
      </categories>
      <tags>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式事务]]></title>
    <url>%2Fblog%2Fdesign%2Fdesign%2F%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[事务是保证业务逻辑正确最基本的前提，同时也常常是系统性能的最大的瓶颈，如果用好事务，在保证一致性的前提下，进一步缩短事务时间，一直是一个考验系统设计的重大难题 数据库事务ACID Atomic原子性: 一个事务的所有系列操作步骤被看成是一个动作，所有的步骤要么全部完成要么一个也不会完成，如果事务过程中任何一点失败，将要被改变的数据库记录就不会被真正被改变。 Consistent一致性:事务在完成时，必须使所有的数据都保持一致状态。在相关数据库中，所有规则都必须应用于事务的修改，以保持所有数据的完整性。事务结束时，所有的内部数据结构（如 B 树索引或双向链表）都必须是正确的。某些维护一致性的责任由应用程序开发人员承担，他们必须确保应用程序已强制所有已知的完整性约束。例如，当开发用于转帐的应用程序时，应避免在转帐过程中任意移动小数点。 Isolated隔离性: 主要用于实现并发控制, 隔离能够确保并发执行的事务能够顺序一个接一个执行，通过隔离，一个未完成事务不会影响另外一个未完成事务。 Durable持久性: 一旦一个事务被提交，它应该持久保存，不会因为和其他操作冲突而取消这个事务。通常是将数据保存在磁盘上。 数据隔离级别 Read Uncommitted（读取未提交内容） ​ 在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。 Read Committed（读取提交内容） ​ 这是大多数数据库系统的默认隔离级别（但不是MySQL默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别 也支持所谓的不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的commit，所以同一select可能返回不同结果。 Repeatable Read（可重读） ​ 这是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读 （Phantom Read）。简单的说，幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行。InnoDB和Falcon存储引擎通过多版本并发控制（MVCC，Multiversion Concurrency Control）机制解决了该问题。 Serializable（可串行化） ​ 这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。 ​ 这四种隔离级别采取不同的锁类型来实现，若读取的是同一个数据的话，就容易发生问题。例如： ​ 脏读(Drity Read)：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。 ​ 不可重复读(Non-repeatable read):在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新的原有的数据。 ​ 幻读(Phantom Read):在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列(Row)数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就会发现有几列数据是它先前所没有的。 MVCCMulti-Version Concurrency Contro：多版本并发控制 mysql的存储引擎InnoDB 通过MVCC实现事务 具体实现为 每开启一个事务都对应一个版本号 每行记录后面保存两个隐藏列，数据创建时的版本号，删除时的版本号 innoDB只会查找版本早于当前事务版本的数据行 行的删除版本要么未定，要么大于当前事务版本号，就认为数据没被删除 更新就是新插入一条记录 幻读产生原因1234begin;select bookId,bookName from m_book where bookId=1update m_book set bookName=2 where bookname=1commit; 只要开启了事务，mysql就保证每次 查询出来的数据是一样的。如果在这个事务执行期间，其它事务修改了或插入了一些数据，在这个事务中是查不到的。 上述语句查询出来bookId=1的数据bookName=1也是1 当执行update的时候，如果只写bookname=1，这时候会更新到什么数据是不确定的，因为update跟新的是实际数据，而不是这个查询出来的某个版本的数据 转账示例张三有100块，李四也有100块，张三给李四转50块，转账分2步 张三账户减少50 李四账户增加50 转账这个过程就是一个事物 原子性：账户只存在2种情况：转账陈功张三50，李四150。转账失败，两人各自持有100块。不存在任其他情况. 一致性：账户总额是200，无论事物成功与否，最终总额必须还是200 隔离性：转账的中间过程对外是不可见的，其它事物只能看到结果，不能看到中间过程 持久性：转账过程一旦完成，账户数据就被持久保存，要修改必须另起事务。 环境 数据库：mysql 语言：java 框架：springboot，mybatis 流程 123456入口-&gt;service:账户信息和金额service-&gt;dao:减少张三余额dao--&gt;service:影响记录条数service--&gt;dao:增加李四账户余额dao-&gt;service:影响记录条数service--&gt;入口:转账成功 初始化数据 sql12345678910111213141516drop table if exists m_account;#建表create table m_account( accountId bigint not null comment '主键', accountName varchar(16) not null comment '账户名，唯一非空', balance int unsigned comment '账户余额，必须大于0', primary key (accountId));#增加唯一约束alter table m_account add unique key(accountName);#初始化数据insert into `m_account`(`accountId`,`accountName`,`balance`)values(1,'zhangsan',100);insert into `m_account`(`accountId`,`accountName`,`balance`)values(2,'lisi',100);#查看结果select * from m_account 基础代码model12345public class Account &#123; private Long accountId; private Integer balance; private String accountName; //省略get和set dao1234567891011@Mapperpublic interface AccountDao&#123; /** * 修改账户余额 * @param params.accountName 账户名 * @param params.balance 要变动金额，如果为正就增加，为负就减少 * @return 影响的条数 * */ public Integer updateBalanceByName(Map&lt;String,Object&gt; params);&#125; mapper.xml123456789&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="top.luckie.demo.dao.AccountDao" &gt; &lt;update id="updateBalanceByName" parameterType="java.util.Map"&gt; update m_account set balance=balance+#&#123;amount&#125; where accountName=#&#123;accountName&#125; &lt;/update&gt;&lt;/mapper&gt; 无事务的情况为了模拟出错的情况，先增加李四账户后减少张三账户 1234567891011121314151617181920212223242526@Servicepublic class AccountService &#123; @Autowired AccountDao accountDao; /** * 转账 * @param from 减少金额账户名 * @param to 增加金额账户名 * @param amount 要转金额 * */ public void transfer(String from,String to,Integer amount) &#123; //给李四账户加钱 Map&lt;String,Object&gt; map=new HashMap(); map.put("accountName", to); map.put("amount", amount); accountDao.updateBalanceByName(map); //给账户账户减钱 map=new HashMap(); map.put("accountName", from); map.put("amount", 0-amount); accountDao.updateBalanceByName(map); &#125;&#125; 最初两个人账户上都有100 第一次张三向李四转50 1accountService.transfer("zhangsan", "lisi", 50); log 123456DEBUG updateBalanceByName.debug:159 - ==&gt; Preparing: update m_account set balance=balance+? where accountName=? DEBUG updateBalanceByName.debug:159 - ==&gt; Parameters: 50(Integer), lisi(String)DEBUG updateBalanceByName.debug:159 - &lt;== Updates: 1DEBUG updateBalanceByName.debug:159 - ==&gt; Preparing: update m_account set balance=balance+? where accountName=? DEBUG updateBalanceByName.debug:159 - ==&gt; Parameters: -50(Integer), zhangsan(String)DEBUG updateBalanceByName.debug:159 - &lt;== Updates: 1 数据更新为 第二次恢复数据 1update m_account set balance=100; 张三向李四转110 1accountService.transfer("zhangsan", "lisi", 110); 日志报错 1### Error updating database. Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: BIGINT UNSIGNED value is out of range in '(`demo`.`m_account`.`balance` + -(110))' 由于账户余额不能小于0，所以程序出错了 查看数据库 李四金额增加了，但张三的账户余额没少，这个逻辑不对 数据库事务在service方法上加上@Transactional 123@Transactionalpublic void transfer(String from,String to,Integer amount) &#123; 。。。。 再执行转账操作 1accountService.transfer("zhangsan", "lisi", 110); 查看日志发现报一样的错，但数据库李四的余额还是100，说明事务回滚了 spring是用AOP实现事务的，所以入口不能是当前的service，如果这样写事务是不生效的 12345678@Transactionalpublic void transfer(String from,String to,Integer amount) &#123; ...&#125;public void transfer2(String from,String to,Integer amount) &#123; this.transfer(from, to, amount);&#125; 入口代码 1accountService.transfer2("zhangsan", "lisi", 110); 变通方法，自己注入自己 1234567891011121314@Servicepublic class AccountService &#123; @Autowired AccountService self; @Transactional public void transfer(String from,String to,Integer amount) &#123; ... &#125; public void transfer2(String from,String to,Integer amount) &#123; self.transfer(from, to, amount); &#125;... 分布式事务CAP定理cap是分布式系统中进行平衡的理论，它是由 Eric Brewer发布在2000年。 Consistent一致性: 同样数据在分布式系统中所有地方都是相同的。 Available可用性: 所有在分布式系统活跃的节点都能够处理操作且能响应查询。 Partition Tolerant分区容错性: 即使出现单个组件无法可用,操作依然可以完成 一般情况下CAP理论认为你不能同时拥有上述三种，只能同时选择两种，这是一个实践总结，当有网络分区情况下，也就是分布式系统中，你不能又要有完美一致性和100%的可用性，只能这在两者选择一个。 BASE理论在分布式系统中，我们往往追求的是可用性，它的重要程序比一致性要高，那么如何实现高可用性呢？ 前人已经给我们提出来了另外一个理论，就是BASE理论，它是用来对CAP定理进行进一步扩充的。BASE理论指的是： Basically Available（基本可用） Soft state（软状态） Eventually consistent（最终一致性） BASE理论是对CAP中的一致性和可用性进行一个权衡的结果，理论的核心思想就是：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。 TCCTCC 其实就是采用的补偿机制，其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作。它分为三个阶段： Try 阶段主要是对业务系统做检测及资源预留 Confirm 阶段主要是对业务系统做确认提交，Try阶段执行成功并开始执行 Confirm阶段时，默认 Confirm阶段是不会出错的。即：只要Try成功，Confirm一定成功。 Cancel 阶段主要是在业务执行错误，需要回滚的状态下执行的业务取消，预留资源释放。 购买示例悲观锁基本动作 减少用户余额 库存库存数量 为了实现TCC，需要多做以下动作 创建/取消订单 锁定/释放库存 保存扣款记录并和订单关联 保存库存变化记录并和订单关联 订单状态变化 ​ 正常流程123456789101112131415用户-&gt;用户系统:购买用户系统-&gt;订单系统:下单请求订单系统-&gt;订单系统:创建订单记录订单系统-&gt;库存系统:锁库存请求库存系统-&gt;库存系统:锁定库存库存系统-&gt;订单系统:锁定成功订单系统-&gt;订单系统:状态改为库存锁定订单系统-&gt;用户系统:下单成功用户系统-&gt;用户系统:扣款用户系统--&gt;订单系统:扣款成功用户系统-&gt;用户:购买成功订单系统--&gt;订单系统:状态改为已扣款订单系统-&gt;库存系统:减库存库存系统-&gt;订单系统:减库存成功订单系统--&gt;订单系统:状态改为已减库存 锁定失败123456789用户-&gt;用户系统:购买用户系统-&gt;订单系统:下单请求订单系统-&gt;订单系统:创建订单记录订单系统-&gt;库存系统:锁库存请求库存系统-&gt;库存系统:锁定库存库存系统-&gt;订单系统:锁定失败订单系统-&gt;订单系统:状态改为取消订单系统-&gt;用户系统:下单失败用户系统-&gt;用户:库存不足 扣款失败12345678910111213用户-&gt;用户系统:购买用户系统-&gt;订单系统:下单请求订单系统-&gt;订单系统:创建订单记录订单系统-&gt;库存系统:锁库存请求库存系统-&gt;库存系统:锁定库存库存系统-&gt;订单系统:锁定成功订单系统-&gt;订单系统:状态改为库存锁定订单系统-&gt;用户系统:下单成功用户系统-&gt;用户系统:扣款用户系统--&gt;订单系统:恢复库存用户系统-&gt;用户:余额不足订单系统--&gt;库存系统:恢复库存订单系统--&gt;订单系统:状态改为已恢复库 系统对应操作用户系统 减少用户余额 记录扣款记录 库存系统 锁定库存 恢复库存 减少库存 记录库存变化 订单系统 创建订单 取消订单 修改订单状态 不一致产生原因 用户系统，订单系统，库存系统是相互独立的，由于网络原因，购买流程里凡是涉及到系统间交互的动作都有可能造成数据的不一致，所有不一致造成的结果就是订单状态一直处于未完成状态。 ​ 如上所述订单所有可能处于的状态有：创建，锁定，已扣款，成功（已减库存），失败（锁定失败），取消（库存恢复）。其中成功，失败和取消是完成的状态，其它情况代表未完成。 解决方案如果订单长时间处于中间状态，表示系统出现了通讯异常，需要额外的程序介入，保证数据的最终一致性，下面对所有不一致的情况逐一分析 长期处于创建 原因：发送锁定库存请求超时 解决方案：查询库存系统，看对应订单是否有锁定记录，如果有就恢复库存，如果没有就将状态改为失败。 长期处于锁定 原因：下单操作超时，或者未能成功发送扣款结果 解决方案：查询扣款记录，如果有扣款记录就减少库存，没有就恢复库存，并修改状态 长期处于已扣款 原因：库存系统未成功接收到减库存指令 解决方案：查询是否有减库存记录，如果有直接改状态，如果没有减库存后修改状态 本地消息表方法1234567用户-&gt;库存系统:购买库存系统-&gt;库存系统:创建订单并扣除库存库存系统--&gt;消息中间件:异步发送购买消息库存系统-&gt;用户:提示用户下单成功消息中间件--&gt;用户系统:传递消息用户系统-&gt;用户系统:减少余额用户系统--&gt;库存系统:修改订单状态为完成 为了进一步提高系统可用性，可以将那些在业务逻辑上可以回退的操作放在前面，然后通过消息队列的方式将消息发送到需要后续操作的系统上，给用户的响应时间就能进一步缩短了st=>start: 创建 op=>operation: 已扣款 op3=>end: 已减库存 op2=>end: 恢复库存 cond=>condition: 锁库存 io=>operation: 库存锁定 cond1=>condition: 扣款 e=>end: 取消 st->cond cond(yes)->io(bottom)->cond1 cond(no)->e cond1(yes)->op->op3 cond1(no)->op2{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);]]></content>
      <categories>
        <category>design</category>
      </categories>
      <tags>
        <tag>高并发</tag>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[eureka集群unavailable-replicas问题]]></title>
    <url>%2Fblog%2Fcode%2Fspring%2Feureka%2Fdevelop%2Feureka-unavailable-replicas%2F</url>
    <content type="text"><![CDATA[搭建了2台eureka的集群，结果一直处于unavailable-replicas host文件已经做了域名映射 12127.0.0.1 eureka1127.0.0.1 eureka2 并且两台机器都显式开启了注册 12eureka.client.fetch-registry=trueeureka.client.register-with-eureka=true 查了半天发现还要设置hostname,最终的配置如下 eureka1 1234567891011server: port: 7001 eureka: client: service-url: defaultZone: http://eureka2:7002/eureka/ register-with-eureka: true fetch-registry: true instance: hostname: eureka1 eureka2 123456789101112server: port: 7002 eureka: client: service-url: defaultZone: http://eureka1:7001/eureka/ register-with-eureka: true fetch-registry: true instance: hostname: eureka2 prefer-ip-address: false prefer-ip-address的作用是将点开的服务器连接换成IP。对于Eureka服务来说，如果eureka部署在同一台机器，并且这个值设成了true，也会造成unavailable-replicas，即使host做了ip映射，hostname也写了也没用。]]></content>
      <categories>
        <category>code</category>
        <category>spring</category>
        <category>eureka</category>
      </categories>
      <tags>
        <tag>eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式]]></title>
    <url>%2Fblog%2Fdesign%2Fdesign%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[简述23中设计模式 六大原则单一职责原则类的功能尽量做到单一 里氏替换原则一个子类应该可以替换掉父类并且可以正常工作 接口隔离原则一个接口拥有的行为应该尽可能的小 依赖倒置原则高层模块不该依赖于低层模块，二者都应该依赖于抽象，抽象不应该依赖于细节，细节应该依赖于抽象 迪米特原则一个类应该尽量不要知道其他类太多的东西 开-闭原则对修改关闭，对扩展开放 创建型1. 单例错误实现12345678910public class Singleton &#123; private static Singleton singleton; private Singleton()&#123;&#125; public static Singleton getInstance()&#123; if (singleton == null) &#123;//多线程情况下这里判断会失效 singleton = new Singleton(); &#125; return singleton; &#125;&#125; 同步方法有性能问题，同步范围太小又会造成多次new double check123456789101112131415161718public class Singleton &#123; private static volatile Singleton instance; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if (instance != null) &#123; return instance; &#125; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; &#125;&#125; 避免的上面方式的明显缺点，但是java内存模型（jmm）并不限制处理器重排序，在执行instance=new Singleton()；时，并不是原子语句，实际是包括了下面三大步骤： 1.为对象分配内存 2.初始化实例对象 3.把引用instance指向分配的内存空间 这个三个步骤并不能保证按序执行，处理器会进行指令重排序优化，存在这样的情况：优化重排后执行顺序为：1,3,2, 这样在线程1执行到3时，instance已经不为null了，线程2此时判断instance!=null，则直接返回instance引用，但现在实例对象还没有初始化完毕，此时线程2使用instance可能会造成程序崩溃。 volatile作用1.保证可见性 可以保证在多线程环境下，变量的修改可见性。每个线程都会在工作内存（类似于寄存器和高速缓存），实例对象都存放在主内存中，在每个线程要使用的时候把主内存中的内容拷贝到线程的工作内存中。使用volatile关键字修饰后的变量，保证每次修改了变量需要立即写回主内存中，同时通知所有的该对变量的缓存失效，保证缓存一致性，其他线程需要使用该共享变量时就要重新从住内存中获取最新的内容拷贝到工作内存中供处理器使用。这样就可以保证变量修改的可见性了。但volatile不能保证原子性，比如++操作。 2.提供内存屏障 volatile关键字能够通过提供内存屏障，来保证某些指令顺序处理器不能够优化重排，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。 下面是保守策略插入内存屏障： 在每个volatile写操作的前面插入一个StoreStore屏障。 在每个volatile写操作的后面插入一个StoreLoad屏障。 在每个volatile读操作的前面插入一个LoadLoad屏障。 在每个volatile读操作的后面插入一个LoadLoad屏障。 这样可以保证在volatile关键字修饰的变量的赋值和读取操作前后两边的大的顺序不会改变，在内存屏障前面的顺序可以交换，屏障后面的也可以换序，但是不能跨越内存屏障重排执行顺序。 静态内部类12345678910111213public class Singleton &#123; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; return InstanceHolder.instance; &#125; static class InstanceHolder &#123; private static Singleton instance = new Singleton(); &#125;&#125; 恶汉模式只要类加载了就会执行 1234567public class Singleton &#123; private static Singleton instance = new Singleton(); private Singleton() &#123;&#125; public static Singleton getInstance() &#123; return instance; &#125; &#125; 2. 静态工厂方法​ 一个工厂类，一个产品接口（其实也可以是一个抽象类，甚至一个普通的父类，但通常我们觉得接口是最稳定的，所以基本不需要考虑普通父类的情况），和一群实现了产品接口的具体产品，而这个工厂类，根据传入的参数去创造一个具体的实现类，并向上转型为接口作为结果返回。 1234567891011121314151617public class StaticFactory &#123; public static Map getMap(String name) &#123; if ("HashMap".equals(name)) &#123; return new HashMap(); &#125; if ("TreeMap".equals(name)) &#123; return new TreeMap(); &#125; if ("LinkedHashMap".equals(name)) &#123; return new LinkedHashMap(); &#125; if ("hashMap".equals(name)) &#123; return new HashMap(); &#125; return null; &#125;&#125; 3. 工厂方法产品的生产延迟到具体工厂实现类 123456789101112131415161718192021public class FactoryMethod &#123; public interface Factory &#123; public Product createProduct(); &#125; public interface Product &#123; public void doSomething(); &#125; public static void main(String[] args) &#123; Factory f1=()-&gt;()-&gt;System.out.println("product1"); Factory f2=()-&gt;()-&gt;System.out.println("product2"); f1.createProduct().doSomething(); f2.createProduct().doSomething(); &#125;&#125; 4. 抽象工厂抽象工厂只是把工厂的一个方法变成多个 12345public interface Factory &#123; public Product createProduct1(); public Product createProduct2(); public Product createProduct3();&#125; 5. 建造者模式构造对象极其复杂，并且需要按照特定步骤，但过程又过程又比较类似。 客户端不需要知道产品怎么造出来的，要新增产品只要新增builder就行了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public class Builder &#123; static public class Person&#123; public String name; public int age; public Date birthday; &#125; public interface PersonBuilder&#123; public void step1(); public void step2(); public void step3(); public Person get(); &#125; public static class BuilderManager&#123; public static Person build(PersonBuilder builder)&#123; builder.step1(); builder.step2(); builder.step3(); return builder.get(); &#125; &#125; public static void main(String[] args) &#123; PersonBuilder b1=new PersonBuilder() &#123; private Person p=new Person(); @Override public void step3() &#123; p.birthday=new Date(); &#125; @Override public void step2() &#123; p.age=2; &#125; @Override public void step1() &#123; p.name="p1"; &#125; @Override public Person get() &#123; return p; &#125; &#125;; PersonBuilder b2=new PersonBuilder() &#123; private Person p=new Person(); @Override public void step3() &#123; p.birthday=new Date(0); &#125; @Override public void step2() &#123; p.age=22; &#125; @Override public void step1() &#123; p.name="p2"; &#125; @Override public Person get() &#123; return p; &#125; &#125;; Person p1=BuilderManager.build(b1); Person p2=BuilderManager.build(b2); System.out.println(p1.name); System.out.println(p2.name); &#125;&#125; 6. 原型模式浅复制只复制引用，深复制复制所有属性 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class Clone &#123; public static MyBean BEAN = create(); public static String name = getName(10000000); public static String name2=name+"1"; public static String name3=name+"2"; public static String name4=name+"3"; public static void main(String[] args) throws ClassNotFoundException, InterruptedException &#123; Class.forName(Clone.class.getName()); ExecResult r = null; MultiThreadResult r2 = null; int count=100000; r = MultiThreadTest.calculate("clone", Clone::doClone, 100,count); System.out.println(r.getResult()); r2 = MultiThreadTest.getResult(Clone::doClone, 10000); System.out.println(r2.getResult()); r = MultiThreadTest.calculate("deepClone", Clone::deepClone, 100,count); System.out.println(r.getResult()); r2 = MultiThreadTest.getResult(Clone::deepClone, 10000); System.out.println(r2.getResult()); r = MultiThreadTest.calculate("create", Clone::create, 100,count); System.out.println(r.getResult()); r2 = MultiThreadTest.getResult(Clone::create, 10000); System.out.println(r2.getResult()); &#125; private static String getName(int length) &#123; StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; length; i++) &#123; sb.append("1"); &#125; System.out.println("创建了一个长达" + sb.length() + "的字符串"); return sb.toString(); &#125; public static MyBean create() &#123; MyBean bean = new MyBean(); bean.setName1(name); bean.setName2(name2); bean.setName3(name3); bean.setName4(name4); MyBean son=new MyBean(); son.setName1(name); son.setName1(name2); son.setName1(name3); bean.setSon(son); return bean; &#125; public static MyBean doClone() &#123; return BEAN.clone(); &#125; public static void deepClone() &#123; try &#123; ByteArrayOutputStream bo = new ByteArrayOutputStream(); ObjectOutputStream oo = new ObjectOutputStream(bo); oo.writeObject(BEAN); ByteArrayInputStream bi = new ByteArrayInputStream(bo.toByteArray()); ObjectInputStream oi = new ObjectInputStream(bi); oi.read(); &#125; catch (Exception ex) &#123; throw new RuntimeException(ex); &#125; &#125;&#125; 从log来看，深复制只是在单线程的情况下性能有点问题，其它的都差不多 123456789101112131415---------clone-------------执行100次:0.0408(ms)执行100,000次:4.6025(ms)10000个线程,创建耗时:15.5978(ms),执行耗时:673.3472(ms),平均耗时0.0421(ms)---------deepClone-------------执行100次:15.8698(ms)执行100,000次:413.6056(ms)10000个线程,创建耗时:10.8982(ms),执行耗时:659.5116(ms),平均耗时0.0583(ms)---------create-------------执行100次:0.0718(ms)执行100,000次:3.9428(ms)10000个线程,创建耗时:7.4955(ms),执行耗时:628.8875(ms),平均耗时0.0306(ms) 结构型7. 代理模式改变原有方法的某些行为，参考spring aop cglib动态代理，通过MethodInterceptor拦截原有方法 12345678910111213import org.springframework.cglib.proxy.Enhancer;import org.springframework.cglib.proxy.LazyLoader;import org.springframework.cglib.proxy.MethodInterceptor;public class MockUtil&#123; public static &lt;T&gt; T mock(Class&lt;T&gt; clazz,MethodInterceptor callback)&#123; Enhancer e=new Enhancer(); e.setSuperclass(clazz); e.setCallback(callback); return (T)e.create(); &#125; &#125; 8. 适配器扩展类功能用于适配特定接口，实现一个可以在thread里执行的map 1234567891011121314151617181920public class Adapter &#123; static public class RunableMap extends HashMap implements Runnable &#123; @Override public void run() &#123; System.out.println(this.keySet()); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; RunableMap map=new RunableMap(); map.put("1", "1"); map.put("2", "1"); map.put("3", "1"); map.put("4", "1"); new Thread(map).start(); &#125;&#125; 9. 装饰器给类动态添加方法，例如给HttpServletRequest添加setParam 使用适配器要求接口不变，而且要用新增的方法有需要知道实际的实现类，所以用的场景不大 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class Decorator &#123; public interface Person&#123; public void say(); public void sleep(); &#125; static public class DefaultPerson implements Person&#123; @Override public void say() &#123; System.out.println("hello"); &#125; @Override public void sleep() &#123; System.out.println("zzzzzz"); &#125; &#125; static public class PersonDecorator implements Person &#123; private Person person; public PersonDecorator(Person person) &#123; this.person=person; &#125; @Override public void say() &#123; person.say(); &#125; @Override public void sleep() &#123; person.sleep(); &#125; public void run() &#123; System.out.println("running"); &#125; &#125; public static void main(String[] args) &#123; Person p=new PersonDecorator(new DefaultPerson()); PersonDecorator dp=(PersonDecorator)p; dp.run(); &#125;&#125; 10.桥接模式将一部分要变化的内容抽象出来，主要执行类不变，当需要执行不同操作时，放入不同的implement 汽车要换 变速器 只需要传入不同的Transmission 1234567891011121314151617181920212223242526272829public class Bridge &#123; public interface Impl &#123; public void doMethod(); &#125; static class Holder &#123; private Impl impl; public void setImpl(Impl impl) &#123; this.impl = impl; &#125; public void operation() &#123; impl.doMethod(); &#125; &#125; public static void main(String[] args) &#123; Impl impl1=()-&gt;System.out.println("impl1"); Impl impl2=()-&gt;System.out.println("impl2"); Holder h=new Holder(); h.setImpl(impl1); h.operation(); h.setImpl(impl2); h.operation(); &#125;&#125; 11. 组合模式不用看了，就是一棵树 12345678public class Composite &#123; public class TreeNode &#123; List&lt;TreeNode&gt; children; String id; String name; &#125;&#125; 12. 享元系统中存在一些可以用key区分的相似对象，主要用在于节约内存 WPF的属性系统是我看到对享元模式最好的使用 123456789101112131415public class Flyweight &#123; static public class FlyweightFactory &#123; private static Map&lt;String,Flyweight&gt; map = new ConcurrentHashMap(); public static Flyweight getFlyweight(String key) &#123; Flyweight f=map.get(key); if(f==null) &#123; f=new Flyweight(); map.put(key, f); &#125; return f; &#125; &#125;&#125; 13. 门面模式对外提供一个统一访问接口 12345678910111213141516171819202122232425262728293031323334353637public class Facade &#123; public class ClassA &#123; public void doSomething() &#123; &#125; &#125; public class ClassB &#123; public void doSomething() &#123; &#125; &#125; public class ClassC &#123; public void doSomething() &#123; &#125; &#125; public class ClassFacade &#123; private ClassA a=new ClassA(); private ClassB b=new ClassB(); private ClassC c=new ClassC(); public void invokeA() &#123; a.doSomething(); &#125; public void invokeB() &#123; b.doSomething(); &#125; public void invokeC() &#123; c.doSomething(); &#125; &#125;&#125; 行为型14. 观察者发布/订阅，生产/消费 1234567891011121314151617181920212223242526272829303132333435363738public class Observer &#123; public interface Observe&#123; public void update(Observable ob); &#125; public static class Observable &#123; List&lt;Observe&gt; observers = new ArrayList&lt;Observe&gt;(); private String name; public void addObserver(Observe o) &#123; observers.add(o); &#125; public void changed() &#123; name=name+"changed"; notifyObservers();// 通知观察自己的所有观察者 &#125; public void notifyObservers() &#123; for (Observe observer : observers) &#123; observer.update(this); &#125; &#125; &#125; public static void main(String[] args) &#123; Observable ob=new Observable(); ob.name="被观察者"; ob.addObserver(oo-&gt;System.out.println("a看到了:"+oo.name)); ob.addObserver(oo-&gt;System.out.println("b看到了:"+oo.name)); ob.changed(); &#125;&#125; 15. 模板方法模板规定好所有要做到事和步骤，具体类继承后实现或改变其中部分行为 12345678910111213141516171819202122232425abstract public class TemplateMethod &#123; public void invoke() &#123; this.step1(); this.step2(); this.step3(); this.step4(); &#125; void step1() &#123;&#125;; void step2() &#123;&#125;; void step3() &#123;&#125;; void step4() &#123;&#125;; static public class Implement extends TemplateMethod&#123; public void step3() &#123; System.out.println("步骤3要做到事情是。。。"); &#125; &#125; public static void main(String[] args) &#123; TemplateMethod method=new Implement(); method.invoke(); &#125;&#125; 16. 命令模式将要做的工作封装在一个类里面 发送方只管发命令，命令谁执行，怎么执行不用管 可以和观察者模式结合，将观察者update方法的参数封装成一个命令，就实现事件驱动了 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class Command &#123; public static class Invoker&#123; private Manager manager; public void pushCommand(Cmd cmd) &#123; manager.comds.add(cmd); &#125; &#125; static public class Manager&#123; List&lt;Cmd&gt; comds=new ArrayList(); private Employer employer; public void assign()&#123; Cmd cmd=comds.remove(0); employer.doCommand(cmd); &#125; &#125; public static class Employer&#123; String name; public void doCommand(Cmd cmd) &#123; System.out.println(name+"开始工作"); cmd.run(); &#125; &#125; public interface Cmd&#123; public void run(); &#125; public static void main(String[] args) &#123; Cmd cmd1=()-&gt;System.out.println("cmd1"); Cmd cmd2=()-&gt;System.out.println("cmd2"); Cmd cmd3=()-&gt;System.out.println("cmd3"); Manager mg=new Manager(); mg.employer=new Employer(); mg.employer.name="员工A"; Invoker i=new Invoker(); i.manager=mg; i.pushCommand(cmd1); i.pushCommand(cmd2); i.pushCommand(cmd3); mg.assign(); mg.assign(); &#125;&#125; 18. 状态根据状态不同，行为也不同 1234567891011121314151617181920212223242526272829303132333435363738public class State &#123; public static class Person&#123; Stat st; public void say(String word) &#123; System.out.println(st.getWord(word)); &#125; &#125; static public enum Stat&#123; a(1),b(2),c(3); int count; Stat(int count) &#123; this.count=count; &#125; public String getWord(String word) &#123; StringBuilder sb=new StringBuilder(); for(int i=0;i&lt;count;i++) &#123; sb.append(word+","); &#125; return sb.toString(); &#125; &#125; public static void main(String[] args) &#123; Person p=new Person(); p.st=Stat.a; p.say("hello"); p.st=Stat.b; p.say("hello"); p.st=Stat.c; p.say("hello"); &#125;&#125; 19. 责任链将要做的是组合成一个责任链，让每个对象都有机会执行，参考springMVC的HandlerIterceptor 任务可以所以组合，注意别搞成死循环了 123456789101112131415161718192021222324252627282930313233343536public class Chain &#123; public static void main(String[] args) &#123; Handler h1=new Handler() &#123; @Override boolean doSomething(Request req) &#123; req.message=req.message+":h1"; return true; &#125; &#125;; Handler h2=new Handler() &#123; @Override boolean doSomething(Request req) &#123; req.message=req.message+":h2"; return true; &#125; &#125;; Handler h3=new Handler() &#123; @Override boolean doSomething(Request req) &#123; req.message=req.message+":h3"; return true; &#125; &#125;; h1.setNext(h2); h2.setNext(h3); Request req=new Request(); req.message="begin"; h1.handle(req); System.out.println(req.message); &#125;&#125; 20. 中介者当对象之间的交互操作很多且每个对象的行为操作都依赖彼此时，为防止在修改一个对象的行为时，同时涉及很多其他对象的行为，可使用中介者模式。 21. 策略模式流程基本固定，通过给方法传递一个接口，改变计算方式 1234567891011121314151617public class Strategy &#123; public interface Method&#123; public void invoke(); &#125; public void run(Method method) &#123; method.invoke(); &#125; public static void main(String[] args) &#123; Method m1=()-&gt;System.out.println("执行方法1"); Method m2=()-&gt;System.out.println("执行方法2"); Strategy st=new Strategy(); st.run(m1); st.run(m2); &#125;&#125; 22. 备忘录将数据在对象外部保存，以便恢复到特定状态 1234567891011121314151617181920212223public class Memento &#123; static public class Person&#123; String memory; Integer age=3; &#125; public static void main(String[] args) &#123; Person p=new Person(); p.memory="3岁的记忆"; p.age=3; //备份 Map map=new HashMap(); map.put("age", p.age); map.put("memory", p.memory); //删除 p.memory=""; p.age=null; //恢复 p.memory=(String) map.get("memory"); p.age=(Integer) map.get("age"); &#125;&#125; 23. 迭代器 定义：提供一种方法顺序访问一个聚合对象中各个元素，而又不需暴露该对象的内部表示。 模式个人理解代理VS装饰器 从语意上讲，代理模式是为控制对被代理对象的访问，而装饰模式是为了增加被装饰对象的功能 代理类所能代理的类完全由代理类确定，装饰类装饰的对象需要根据实际使用时客户端的组合来确定 被代理对象由代理对象创建，客户端甚至不需要知道被代理类的存在；被装饰对象由客户端创建并传给装饰对象 策略VS状态VS桥接VS责任链VS命令VS观察者考虑以下场景 123456789101112public class A &#123; private List bs; public void prepare(B b) &#123; bs.add(b) &#125; public void run(C c) &#123; for(B impl:list) &#123; b.invoke(c) &#125; &#125;&#125; 有一个主业务类A，它执行run方法之前，会传进来1个或几个B，我们能确定的是客户端在调用run方法前会先调用prepare方法。至于如何调用，调用方式，不同场景会有不同 123456#按顺序a.prepare(b1)；a.prepare(b2)a.prepare(b3)；a.run(c1)；a.run(c2);#间隔a.prepare(b1);a.run(c1);a.prepare(b2);a.run(c2);#不确定a.prepare(b1);a.run(c1);a.prepare(b2);a.prepare(b3);a.run(c2); 编码是通常考虑的是： A里存的B是1个还是多个 B的个数是固定的，还是可以任意添加删除 B内部是否要保存状态 不同B的实现类之间需要互相知道彼此吗 不同B之间是否有优先级 参数c是否要在各个b之间传递 是否需要通过调用返回值判断是否继续下一个调用 换成设计模式的语言就是这样的: st=>start: 开始 cond=>condition: B在A中有多个 cond-1=>condition: B由客户端指定 end0=>end: 状态模式 cond0=>condition: B间通信 op0=>operation: B自己确定下个B op=>operation: B是A的一部分 cond2=>condition: B是简单算法 end1=>end: 策略模式 end2=>end: 桥接 op3=>通常由C主导任务 cond3=>condition: run后移除B end3=>end: 命令模式 cond4=>condition: B相互独立 end4=>end: 观察者 op5=>operation: C在B间传递 end5=>end: 责任链 st->cond cond(no,right)->cond-1 cond-1(no,right)->op0->end0 cond-1(yes)->cond2 cond2(yes,right)->end1 cond2(no)->op->end2 cond(yes)->cond3 cond3(yes,right)->end3 cond3(no)->cond4 cond4(yes,right)->end4 cond4(no)->op5 op5->end5{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);]]></content>
      <categories>
        <category>design</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小问题]]></title>
    <url>%2Fblog%2Fcode%2Fops%2F%E5%B0%8F%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[记录一些日常开发遇到的问题，每次上网搜索处理完后，就到这里记录一下，免得忘记了，又得搜 eclipsemaven install ok,项目报错alt+f5 alt+/(获取提示)出错 点开content assisit 去掉 java proposals (code Recommenders) webstorm修改文件类型]]></content>
      <categories>
        <category>code</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[eclipse初始化]]></title>
    <url>%2Fblog%2F%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7%2Feclipse%2Ftools%2Feclipse%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Eclipse安装完后，根据个人的一些习惯，有些默认配置需要做一些更改，包括Jdk、错误提示、maven、系统编码等等 将安装的jre路径改为jdk位置window-&gt;preferences-&gt;jre 选择jdk所在目录 修改错误提示window-&gt;preferences-&gt;err unused import serialVersionUID generic types Maven配置创建setting文件设置本地库路径 localRepository和镜像仓库 123456789101112131415161718192021222324252627282930313233343536&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;settings xmlns="http://maven.apache.org/SETTINGS/1.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd"&gt; &lt;!--指定本地仓库存储路径。默认值为~/.m2/repository 即 $&#123;user.home&#125;/.m2/repository。 --&gt; &lt;localRepository&gt;E:/opt/config/maven/.m2/repository&lt;/localRepository&gt; &lt;!-- 指定镜像列表，用于从远程仓库下载资源,如果你想覆盖中央仓库的默认地址，那么这里我们就会使用的镜像了 --&gt; &lt;mirrors&gt; &lt;!-- 指定仓库的镜像站点，代替一个给定的库。该镜像藏库有一个ID相匹配的mirrorOf元素。 ID是用于继承和直接查找目的，必须是唯一的。 --&gt; &lt;mirror&gt; &lt;!--该镜像的唯一标识符。id用来区分不同的mirror元素。 --&gt; &lt;id&gt;mirrorId&lt;/id&gt; &lt;!--被镜像的服务器的id，比如：central，不能和id匹配。 --&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;aliyun mirror&lt;/name &lt;!--镜像地址--&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; &lt;!--将jdk版本设置为1.8--&gt; &lt;profile&gt; &lt;id&gt;jdk-1.8&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/settings&gt; 配置文件路径 设置后 常用模板位置 window-&gt;preferences-&gt;java templates logger1234import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class xxx &#123; public static final Logger log = LoggerFactory.getLogger(xxx.class); 设置 Name 快捷键 Pattern 模板内容 1$&#123;:import(org.slf4j.Logger,org.slf4j.LoggerFactory)&#125;public static final Logger log = LoggerFactory.getLogger($&#123;enclosing_type&#125;.class); 注意: ​ 用public是因为当log没被用到的时候不出现warring提示 ​ import和代码如果不在同一行,生成的代码会多一个回车 修改默认编码为UTF-8 lockmoc安装将 lombok.jar 放在eclipse安装目录下，和 eclipse.ini 文件平级的 java -jar lombok.jar 常用标签 @Setter @Getter @Data=getter、setter、equals、canEqual、hashCode、toString @Log(这是一个泛型注解，具体有很多种形式) @AllArgsConstructor @NoArgsConstructor @EqualsAndHashCode @NonNull @Cleanup @Cleanup清理的方法为close @ToString @RequiredArgsConstructor @Value @SneakyThrows @Synchronized]]></content>
      <categories>
        <category>开发工具</category>
        <category>eclipse</category>
      </categories>
      <tags>
        <tag>eclipse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java数据结构]]></title>
    <url>%2Fblog%2Fcode%2Fjava%2Fdevelop%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[java.util包下经常使用到的类，先写个目录，后续补充 CollectionList LinkedList ArrayList Vector Set HashSet TreeSet LinkedHashSet MapHashMap内部维护一个数组，将key通过hash算法计算出索引位置。该位置上保存的是一个链表， 死锁是在扩容链表的时候发生，链表内部出现循环了 jdk1.8之后不会出现死锁了,但线程冲突的时候可能出现数据丢失的问题 LinkedHashMapHashMap+LinkedList ，实现同HashMap，内部维护了一个LinkedList 保证插入顺序 TreeMap红黑树实现 HashtableQueueAbstractQueue DelayQueue BlockingQueueput： 阻塞等待 offer：满了返回false add：满了直接抛错 poll: 若队列为空，返回null。 remove:若队列为空，抛出NoSuchElementException异常。 take:若队列为空，发生阻塞，等待有元素。 LinkedBlockingDeque ArrayBlockingQueue Deque双向队列 LinkedList ConcurrentLinkedDeque]]></content>
      <categories>
        <category>code</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
</search>
